- name: "Implement CppInterOp API exposing memory, ownership and thread safety information "
  description: |
    Incremental compilation pipelines process code chunk-by-chunk by building
    an ever-growing translation unit. Code is then lowered into the LLVM IR
    and subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration
    and makes the C++ language more user friendly. The incremental compilation
    mode is used by the interactive C++ interpreter, Cling, initially developed
    to enable interactive high-energy physics analysis in a C++ environment.

    Clang and LLVM provide access to C++ from other programming languages,
    but currently only exposes the declared public interfaces of such C++
    code even when it has parsed implementation details directly. Both the
    high-level and the low-level program representation has enough information
    to capture and expose more of such details to improve language
    interoperability. Examples include details of memory management, ownership
    transfer, thread safety, externalized side-effects, etc. For example, if
    memory is allocated and returned, the caller needs to take ownership; if a
    function is pure, it can be elided; if a call provides access to a data member,
    it can be reduced to an address lookup.
    
    The goal of this project is to develop API for CppInterOp which are capable of
    extracting and exposing such information AST or from JIT-ed code and use it in
    cppyy (Python-C++ language bindings) as an exemplar. If time permits, extend
    the work to persistify this information across translation units and use it on
    code compiled with Clang.

  tasks: |
    * Collect and categorize possible exposed interop information kinds
    * Write one or more facilities to extract necessary implementation details
    * Design a language-independent interface to expose this information
    * Integrate the work in clang-repl and Cling
    * Implement and demonstrate its use in cppyy as an exemplar
    * Present the work at the relevant meetings and conferences.

- name: "Implement and improve an efficient, layered tape with prefetching capabilities"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the  method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library can differentiate
    non-trivial functions, to find a partial derivative for trivial cases and has
    good unit test coverage.

    The most heavily used entity in AD is a stack-like data structure called a
    tape. For example, the first-in last-out access pattern, which naturally
    occurs in the storage of intermediate values for reverse mode AD, lends
    itself towards asynchronous storage. Asynchronous prefetching of values
    during the reverse pass allows checkpoints deeper in the stack to be stored
    furthest away in the memory hierarchy. Checkpointing provides a mechanism to
    parallelize segments of a function that can be executed on independent cores.
    Inserting checkpoints in these segments using separate tapes enables keeping
    the memory local and not sharing memory between cores. We will research
    techniques for local parallelization of the gradient reverse pass, and extend
    it to achieve better scalability and/or lower constant overheads on CPUs and
    potentially accelerators. We will evaluate techniques for efficient memory
    use, such as multi-level checkpointing support. Combining already developed
    techniques will allow executing gradient segments across different cores or
    in heterogeneous computing systems. These techniques must be robust and
    user-friendly, and minimize required application code and build system changes.

    This project aims to improve the efficiency of the clad tape and generalize
    it into a tool-agnostic facility that could be used outside of clad as well.

  tasks: |
    * Optimize the current tape by avoiding re-allocating on resize in favor of using connected slabs of array
    * Enhance existing benchmarks demonstrating the efficiency of the new tape
    * Add the tape thread safety
    * Implement multilayer tape being stored in memory and on disk
    * [Stretch goal] Support cpu-gpu transfer of the tape
    * [Stretch goal] Add infrastructure to enable checkpointing offload to the new tape
    * [Stretch goal] Performance benchmarks
    
    
    
- name: "Enabling CUDA compilation on Cppyy-Numba generated IR"
  description: |
    Cppyy is an automatic, run-time, Python-C++ bindings generator, for calling
    C++ from Python and Python from C++. Initial support has been added that
    allows Cppyy to hook into the high-performance Python compiler,
    Numba which compiles looped code containing C++ objects/methods/functions
    defined via Cppyy into fast machine code. Since Numba compiles the code in
    loops into machine code it crosses the language barrier just once and avoids
    large slowdowns accumulating from repeated calls between the two languages.
    Numba uses its own lightweight version of the LLVM compiler toolkit (llvmlite) 
    that generates an intermediate code representation (LLVM IR) which is also
    supported by the Clang compiler capable of compiling CUDA C++ code.
    
    The project aims to demonstrate Cppyy's capability to provide CUDA paradigms to
    Python users without any compromise in performance. Upon successful completion
    a possible proof-of-concept can be expected in the below code snippet -

    ```python
    import cppyy
    import cppyy.numba_ext
    
    cppyy.cppdef('''
    __global__ void MatrixMul(float* A, float* B, float* out) {
        // kernel logic for matrix multiplication
    }
    ''')

    @numba.njit
    def run_cuda_mul(A, B, out):
        # Allocate memory for input and output arrays on GPU
        # Define grid and block dimensions
        # Launch the kernel
        MatrixMul[griddim, blockdim](d_A, d_B, d_out)	
    ```
  tasks: |
    * Add support for declaration and parsing of Cppyy-defined CUDA code on
    the Numba extension.
    * Design and develop a CUDA compilation and execution mechanism.
    * Prepare proper tests and documentation.

- name: "Cppyy STL/Eigen - Automatic conversion and plugins for Python based ML-backends"
  description: |
    Cppyy is an automatic, run-time, Python-C++ bindings generator, for calling 
    C++ from Python and Python from C++. Cppyy uses pythonized wrappers of useful
    classes from libraries like STL and Eigen that allow the user to utilize them
    on the Python side. Current support follows container types in STL like
    std::vector, std::map, and std::tuple and the Matrix-based classes in
    Eigen/Dense. These cppyy objects can be plugged into idiomatic expressions
    that expect Python builtin-types. This behaviour is achieved by growing
    pythonistic methods like `__len__` while also retaining its C++ methods
    like `size`.

    Efficient and automatic conversion between C++ and Python is essential
    towards high-performance cross-language support. This approach eliminates
    overheads arising from iterative initialization such as comma insertion in
    Eigen. This opens up new avenues for the utilization of Cppyy’s bindings in
    tools that perform numerical operations for transformations, or optimization.

    The on-demand C++ infrastructure wrapped by idiomatic Python enables new
    techniques in ML tools like JAX/CUTLASS. This project allows the C++
    infrastructure to be plugged into at service to the users seeking
    high-performance library primitives that are unavailable in Python.
    
  tasks: |
    * Extend STL support for std::vectors of arbitrary dimensions
    * Improve the initialization approach for Eigen classes
    * Develop a streamlined interconversion mechanism between Python
    builtin-types, numpy.ndarray, and STL/Eigen data structures
    * Implement experimental plugins that perform basic computational  
    operations in frameworks like JAX
    * Work on integrating these plugins with toolkits like CUTLASS that
    utilise the bindings to provide a Python API

- name: "Enable cross-talk between Python and C++ kernels in xeus-clang-REPL by using Cppyy"
  description: |
    xeus-clang-REPL is a C++ kernel for Jupyter notebooks using clang-REPL as
    its C++ Interpreter. Cppyy is an automatic, run-time, Python-C++ bindings
    generator, for calling C++ from Python and Python from C++.

    Allowing C++ and Python to talk between themselves in a Jupyter notebook
    will allow users to switch between Python and C++ at will. This means
    that data analysts can set up their analysis in Python while running the
    actual analysis in C++. Thus reducing the time to write and debug their
    analysis pipeline.

    Initial support of cross talk between the two kernels has been implemented
    but this only supports passing primitive data types. This project aims to
    use Cppyy to extend this to support classes and functions.
  tasks: |
    * Automate creation of equivalent Cppyy objects in the Python kernel when
      objects are created in the C++ kernel
    * Automate the creation of equivalent C++ objects in the xeus-clang-REPL
      kernel when Python objects are created
    * Add documentation
  status: ongoing
  responsible: Aaron Jomy, Smit Shah

- name: "Extend the Cppyy support in Numba"
  description: |
    Numba is a JIT compiler that translates a subset of Python and NumPy code
    into fast machine code. Cppyy is an automatic, run-time, Python-C++
    bindings generator, for calling C++ from Python and Python from C++. 

    Cppyy has to pay a time penalty each time it needs to switch between
    languages which can multiply into large slowdowns when using loops with
    cppyy objects. This is where Numba can help. Since Numba compiles the
    code in loops into machine code it only has to cross the language barrier
    once and the loops thus run faster.

    Initial support for Cppyy objects in Numba enabled the use of builtin
    types and classes (see
    [cppyy docs](https://cppyy.readthedocs.io/en/latest/numba.html)),
    but some essential C++ features, such as references and STL classes,
    are not yet supported.
  tasks: |
    There are several foreseen tasks:
      * Add support for C++ reference types in Numba through Cppyy
      * Add general support for C++ templates in Numba through Cppyy
      * Add tests and documentation
  status: completed
  responsible: Aaron Jomy
    
- name: "Explore advanced activity-analysis and optimizations in reverse-mode automatic differentiation"
  description: |
    Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++
    source code of a mathematical function, it can automatically generate C++
    code for computing derivatives of the function. Clad has found uses in
    statistical analysis and uncertainty assessment applications.

    Automatic differentiation techniques involve computing partial derivatives
    of each intermediate variable encountered while automatically
    differentiating a function. Users are generally interested in the
    derivatives of a subset of the output variables with respect to a subset
    of the input variables. In this case, partial derivatives of many
    intermediate variables may not contribute to final derivatives and
    therefore can be ignored and not computed. Activity analysis finds
    intermediate variables whose partial derivatives contribute to the final
    required derivatives. It allows the AD tool to only compute the set of
    partial derivatives that are required. By not computing partial
    derivatives for such intermediate variables, both the memory requirement
    and the run time of the generated program can be reduced.
  tasks: |
    There are several foreseen tasks:
      * Research about automatic differentiation activity analysis techniques.
        Prepare an activity analysis model report with an initial strategy to
        follow. This may involve brainstorming and the need for innovative
        solutions.
      * Implement the proposed activity analysis mode.
      * Add tests and documentation.
  status: ongoing 
  responsible: Petro Zarytskyi

- name: "Improve automatic differentiation of object-oriented paradigms using Clad"
  description: |
    Clad is an automatic differentiation (AD) clang plugin for C++. Given a
    C++ source code of a mathematical function, it can automatically generate
    C++ code for computing derivatives of the function. Clad has found uses
    in statistical analysis and uncertainty assessment applications.

    Object oriented paradigms (OOP) provide a structured approach for complex
    use cases, allowing for modular components that can be reused & extended.
    OOP also allows for abstraction which makes code easier to reason about &
    maintain. Gaining full OOP support is an open research area for automatic
    differentiation codes.

    This project focuses on improving support for differentiating
    object-oriented constructs in Clad. This will allow users to seamlessly
    compute derivatives to the algorithms in their projects which use an
    object-oriented model. C++ object-oriented constructs include but are
    not limited to: classes, inheritance, polymorphism, and related features
    such as operator overloading.
  tasks: |
    There are several foreseen tasks:
      * Study the current object-oriented differentiable programming support
        in Clad. Prepare a report of missing constructs that should be added to
        support the automatic differentiation of object-oriented paradigms in
        both the forward mode AD and the reverse mode AD.
        Some of the missing constructs are: differentiation of constructors,
        limited support for differentiation of operator overloads, reference
        class members, and no way of specifying custom derivatives for
        constructors.
      * Add support for the missing constructs.
      * Add proper tests and documentation.

- name: "Enable reverse-mode automatic differentiation of (CUDA) GPU kernels using Clad"
  description: |
    Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++
    source code of a mathematical function, it can automatically generate C++
    code for computing derivatives of the function. Clad has found uses in
    statistical analysis and uncertainty assessment applications. In
    scientific computing and machine learning, GPU multiprocessing can
    provide a significant boost in performance and scalability. This project
    focuses on enabling the automatic differentiation of CUDA GPU kernels using
    Clad. This will allow users to take advantage of the power of GPUs while
    benefiting from the accuracy and speed of automatic differentiation.
  tasks: |
    There are several foreseen tasks:
      * Research about automatic differentiation of code involving CUDA GPU
        kernels. Prepare a report and an initial strategy to follow.This may
        involve brainstorming and the need for innovative solutions. 
      * Enable reverse-mode automatic differentiation of CUDA GPU kernels and
        calls to CUDA GPU kernels from the host code.
      * Add proper tests and documentation.

- name: "Design and Develop a CUDA engine working along with C/C++ mode in clang-repl"
  description: |
    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims to
    generalize the `IncrementalCUDADeviceCompiler` of cling and add this
    functionality in clang-repl.
  tasks: |
    There are several foreseen tasks:
      * Write a detailed request for comment (RFC) document on the design choices
        and gather feedback from the LLVM community.
      * Implement the necessary functionality to support existing test cases
        available [here](https://github.com/root-project/cling/tree/master/test/CUDADeviceCode).
      * Develop clang-repl-based tutorials for the CUDA backend.
      * Investigate the requirements for supporting a HIP backend.
      * Demonstrate a CUDA-executed gradient computed by the Clad automatic
        differentiation plugin.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Anubhab Ghosh

- name: "Tutorial development with clang-repl"
  description: |
    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims
    implementing tutorials demonstrating the capabilities of the project and
    investigating adoption of clang-repl in xeus-cling.
  tasks: |
    There are several foreseen tasks:
      * Write several tutorials demostrating the current capabilities of
        clang-repl.
      * Investigate the requirements for adding clang-repl as a backend to
        xeus-cling.
      * Implement the xeus kernel protocol for clang-repl.
      * Complete a blog post about clang-repl and possibly Jupyter.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Krishna Narayanan

- name: "Implement autocompletion in clang-repl"
  description: |
    The Clang compiler is part of the LLVM compiler infrastructure and supports
    various languages such as C, C++, ObjC and ObjC++. The design of LLVM and
    Clang enables them to be used as libraries, and has led to the creation of
    an entire compiler-assisted ecosystem of tools. The relatively friendly
    codebase of Clang and advancements in the JIT infrastructure in LLVM further
    enable research into different methods for processing C++ by blurring the
    boundary between compile time and runtime. Challenges include incremental
    compilation and fitting compile/link time optimizations into a more dynamic
    environment.

    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims at the
    design and implementation of robust autocompletion when users type C++ at
    the prompt of clang-repl. For example:
    ```cpp
    [clang-repl] class MyLongClassName {};
    [clang-repl] My<tab>
    // list of suggestions.
    ```
  tasks: |
    There are several foreseen tasks:
      * Research the current approaches for autocompletion in clang such as
        `clang -code-completion-at=file:col1:col2`.
      * Implement a version of the autocompletion support using the partial
        translation unit infrastructure in clang's `libInterpreter`.
      * Investigate the requirements for semantic autocompletion which takes into
        account the exact grammar position and semantics of the code. Eg:
        ```cpp
        [clang-repl] struct S {S* operator+(S&) { return nullptr;}};
        [clang-repl] S a, b;
        [clang-repl] v = a + <tab> // shows b as the only acceptable choice here.
        ```
      * Present the work at the relevant meetings and conferences
  status: completed
  responsible: Yuquan (Fred) Fu

- name: "Implement vector mode in forward mode automatic differentiation in Clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage.

    Vector mode support will facilitate the computation of gradients using the
    forward mode AD in a single pass and thus without explicitly performing
    differentiation n times for n function arguments. The major benefit of using
    vector mode is that computationally expensive operations do not need to be
    recomputed n times for n function arguments.

    For example, if we want to compute `df/dx` and `df/dy` of a function
    `f(x, y)` using the forward mode AD in Clad, then currently we need to
    explicitly differentiate `f` two times. Vector mode will allow the
    generation of `f_d(x, y)` such that we will be able to get partial
    derivatives with respect to all the function arguments (gradient) in a
    single call.

    After successful completion of the project the code snippet should work
    as expected:
    ```cpp
    #include <clad/Differentiator/Differentiator.h>
    #include <iostream>

    double someComputationalIntensiveFn();

    double fn(double x, double y) {
      double t = someComputationalIntensiveFn(); // should be computed only once
                                                 // in the derived function.
      double res = 2 * t * x + 3 * t * x * y;
      return t;
    }

    int main() {
      auto d_fn = clad::differentiate(fn, "arr");
      double d_x = 0, d_y = 0;
      d_fn.execute(3, 5, &d_x, &d_y);
      std::cout << "Derivative of fn wrt d_x: " << d_x << "\n";
      std::cout << "Derivative of fn wrt d_y: " << d_y << "\n";
    }
    ```
  tasks: |
    The project consists of the following tasks:
      * Extend and generalize our ForwardModeVisitor to produce a single
        function with the directional derivatives.
      * Add a new mode to the top-level clad interface `clad::differentiate` for
        vector mode.
      * Extend the unit test coverage.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Vaibhav Thakkar

- name: "Add support for differentiating with respect to multidimensional arrays
         (or pointers) in Clad."
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage.

    Clad currently only supports differentiation with respect to
    single-dimensional arrays. Support for differentiation with respect to
    pointers is limited as well. This project aims to add support for
    multi-dimensional arrays (and pointers) in Clad.

    After successful completion of the project the code snippet should work
    as expected:
    ```cpp
    #include <iostream>
    #include "clad/Differentiator/Differentiator.h"

    double fn(double arr[5][5]) {
      double res = 1 * arr[0][0] + 2 * arr[1][1] + 4 * arr[2][2];
      return res * 2;
    }

    int main() {
      auto d_fn = clad::gradient(fn);
      double arr[5][5] = {{1, 2, 3, 4, 5},
                          {6, 7, 8, 9, 10},
                          {11, 12, 13, 14, 15},
                          {16, 17, 18, 19, 20},
                          {21, 22, 23, 24, 25}};
      double d_arr[5][5] = {};
      d_fn.execute(arr, d_arr);
      std::cout << "Derivative of d_fn wrt arr[0][0]: " << d_arr[0][0] << "\n"; // 2
      std::cout << "Derivative of d_fn wrt arr[1][1]: " << d_arr[1][1] << "\n"; // 4
      return 0;
    }
    ```
  tasks: |
    The project consists of the following tasks:
      * Add support for differentiation with respect to multidimensional arrays
        (and pointers) in the reverse mode.
      * Add support for differentiation with respect to multidimensional arrays
        (and pointers) in the forward mode.
      * Extend the unit test coverage.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.
  status: ongoing
  responsible: Vaibhav Thakkar

- name: "Broaden the Scope for the Floating-Point Error Estimation Framework in Clad"

  description: |
      In mathematics and computer algebra, automatic differentiation (AD) is
      a set of techniques to numerically evaluate the derivative of a function 
      specified by a computer program. Automatic differentiation is an alternative 
      technique to Symbolic differentiation and Numerical differentiation (the 
      method of finite differences). Clad is based on Clang which provides the 
      necessary facilities for code transformation. The AD library can differentiate 
      non-trivial functions, to find a partial derivative for trivial cases and has 
      good unit test coverage.

      Clad also possesses the capabilities of annotating given source code with 
      floating-point error estimation code. This allows Clad to compute any 
      floating-point related errors in the given function on the fly. This allows 
      Clad to reason about the numerical stability of the given 
      function and also analyze the sensitivity of the variables involved.

      The idea behind this project is to develop benchmarks and improve the 
      floating-point error estimation framework as necessary. Moreover, find 
      compelling real-world use-cases of the tool and investigate the possibility 
      of performing lossy compression with it.

      On successful completion of the project, the framework should have a 
      sufficiently large set of benchmarks and example usages. Moreover, 
      the framework should be able to run the following code as expected:
      ```cpp
      #include <iostream>
      #include "clad/Differentiator/Differentiator.h"

      // Some complicated function made up of doubles.
      double someFunc(double F1[], double F2[], double V3[], double COUP1, double COUP2)
      {
        double cI = 1;
        double TMP3;
        double TMP4;
        TMP3 = (F1[2] * (F2[4] * (V3[2] + V3[5]) + F2[5] * (V3[3] + cI * (V3[4]))) +
        F1[3] * (F2[4] * (V3[3] - cI * (V3[4])) + F2[5] * (V3[2] - V3[5])));
        TMP4 = (F1[4] * (F2[2] * (V3[2] - V3[5]) - F2[3] * (V3[3] + cI * (V3[4]))) +
        F1[5] * (F2[2] * (-V3[3] + cI * (V3[4])) + F2[3] * (V3[2] + V3[5])));
        return (-1.) * (COUP2 * (+cI * (TMP3) + 2. * cI * (TMP4)) + cI * (TMP3 *
        COUP1));
      }

      int main() {
        auto df = clad::estimate_error(someFunc);
        // This call should generate a report to decide
        // which variables can be downcast to a float.
        df.execute(args...);
      }
      ```
  tasks: |
    The project consists of the following tasks:
      * Add at least 5 benchmarks and compare the framework's correctness and 
        performance against them.
      * Compile at least 3 real-world examples that are complex enough to demonstrate 
        the capabilities of the framework.
      * Solve any general-purpose issues that come up with Clad during the process.
      * Prepare demos and carry out development needed for lossy compression. 

- name: "Improve robustness of dictionary to module lookups in ROOT"
  description: |
    The LHC smashes groups of protons together at close to the speed of light:
    40 million times per second and with seven times the energy of the most
    powerful accelerators built up to now. Many of these will just be glancing
    blows but some will be head on collisions and very energetic. When this
    happens some of the energy of the collision is turned into mass and
    previously unobserved, short-lived particles – which could give clues
    about how Nature behaves at a fundamental level - fly out and into the
    detector. Our work includes the experimental discovery of the Higgs boson,
    which leads to the award of a Nobel prize for the underlying theory that
    predicted the Higgs boson as an important piece of the standard model
    theory of particle physics.

    CMS is a particle detector that is designed to see a wide range of
    particles and phenomena produced in high-energy collisions in the LHC.
    Like a cylindrical onion, different layers of detectors measure the
    different particles, and use this key data to build up a picture of events
    at the heart of the collision. The
    [CMSSW](https://github.com/cms-sw/cmssw/) is a collection of software for
    the CMS experiment. It is responsible for the collection and processing of
    information about the particle collisions at the detector. CMSSW uses
    the [ROOT](root.cern/) framework to provide support for data storage and
    processing. ROOT relies on Cling, Clang, LLVM for building automatically
    efficient I/O representation of the necessary C++ objects. The I/O
    properties of each object is described in a compileable C++ file called
    a /dictionary/. ROOT's I/O dictionary system
    [relies on C++ modules](https://github.com/root-project/root/blob/master/README/README.CXXMODULES.md)
    to improve the overall memory footprint when being used.

    The few run time failures in the modules integration builds of CMSSW are
    due to dictionaries that can not be found in the modules system. These
    dictionaries are present as the mainstream system is able to find them
    using a broader search. The modules setup in ROOT needs to be extended to
    include a dictionary extension to track dictionary<->module mappings for
    C++ entities that introduce synonyms rather than declarations
    (`using std::vector<A<B>> = MyVector` where the dictionaries of A, B are
    elsewhere)
  tasks: |
    The project consists of the following tasks:
      * If an alias declaration of kind `using std::vector<A<B>> = MyVector`, we
        should store the ODRHash of it in the respective dictionary file as a
        number attached to a special variable which can be retrieved at symbol
        scanning time.
      * Track down the test failures of CMSSW and check if the proposed
        implementation works.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.

- name: "Optimize ROOT use of modules for large codebases (eg, CMSSW)"
  description: |
    The LHC smashes groups of protons together at close to the speed of light:
    40 million times per second and with seven times the energy of the most
    powerful accelerators built up to now. Many of these will just be glancing
    blows but some will be head on collisions and very energetic. When this
    happens some of the energy of the collision is turned into mass and
    previously unobserved, short-lived particles – which could give clues
    about how Nature behaves at a fundamental level - fly out and into the
    detector. Our work includes the experimental discovery of the Higgs boson,
    which leads to the award of a Nobel prize for the underlying theory that
    predicted the Higgs boson as an important piece of the standard model
    theory of particle physics.

    CMS is a particle detector that is designed to see a wide range of
    particles and phenomena produced in high-energy collisions in the LHC.
    Like a cylindrical onion, different layers of detectors measure the
    different particles, and use this key data to build up a picture of events
    at the heart of the collision. The
    [CMSSW](https://github.com/cms-sw/cmssw/) is a collection of software for
    the CMS experiment. It is responsible for the collection and processing of
    information about the particle collisions at the detector. CMSSW uses
    the [ROOT](root.cern/) framework to provide support for data storage and
    processing. ROOT relies on Cling, Clang, LLVM for building automatically
    efficient I/O representation of the necessary C++ objects. The I/O
    properties of each object is described in a compileable C++ file called
    a /dictionary/. ROOT's I/O dictionary system
    [relies on C++ modules](https://github.com/root-project/root/blob/master/README/README.CXXMODULES.md)
    to improve the overall memory footprint when being used.

    One source of performance loss is the need for symbol lookups across the
    very large set of CMSSW modules. ROOT needs to be improved to optimize this
    lookup so that it does not pull all modules defining namespace `edm` on
    `edm::X` lookups.
  tasks: |
    The project consists of the following tasks:
      * Develop an extension to the `GlobalModuleIndex` infrastructure in clang
        which keeps track of the `DeclKind` of the identifiers so that we can
        later ignore the identifiers that declare a namespace.
      * Track down the test failures of CMSSW and check if the proposed
        implementation works.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Jun Zhang

- name: "Enhance the incremental compilation error recovery in clang and clang-repl"
  description: |
    The Clang compiler is part of the LLVM compiler infrastructure and supports
    various languages such as C, C++, ObjC and ObjC++. The design of LLVM and
    Clang enables them to be used as libraries, and has led to the creation of
    an entire compiler-assisted ecosystem of tools. The relatively friendly
    codebase of Clang and advancements in the JIT infrastructure in LLVM further
    enable research into different methods for processing C++ by blurring the
    boundary between compile time and runtime. Challenges include incremental
    compilation and fitting compile/link time optimizations into a more dynamic
    environment.

    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims at
    enhancing the error recovery when users type C++ at the prompt of clang-repl.
  tasks: |
    There are several tasks to improve the current rudimentary state of the
    error recovery:
      * Extend the test coverage for error recovery
      * Find and fix cases where there are bugs
      * Implement template instantiation error recovery support
      * Implement argument-dependent lookup (ADL) recovery support

- name: "Add initial integration of Clad with Enzyme"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage. Enzyme is a prominent autodiff framework which
    works on LLVM IR.

    Clad and Enzyme can be considered as a C++ frontend and a backend automatic
    differentiation framework. In many cases, when clad needs to fall back to
    numeric differentiation it can try configuring and using Enzyme to perform
    the automatic differentiation on lower level.
  tasks: |
    Understand how both systems work. Define the Enzyme configuration
    requirements and enable Clad to communicate efficiently with Enzyme. That
    may require several steps: start building and using the optimization pass of
    Enzyme as part of the Clad toolchain; use Enzyme for cross-validation
    derivative results; etc.
  status: completed
  responsible: Manish Kausik H

- name: "Add numerical differentiation support in clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage. In a number of cases, due different
    limitations, it is either inefficient or impossible to differentiate a
    function.

    Currently, clad cannot differentiate declared-but-not-defined functions.
    In that case it issues an error. Instead, clad should fall back to its future
    numerical differentiation facilities.
  tasks: |
    Implement numerical differentiation support in clad. It should be available
    through a dedicated interface (for example `clad::num_differentiate`).
    The new functionality should be connected to the forward mode automatic
    differentiation. If time permits, a prototype of configurable error
    estimation for the numerical differentiation should be implemented.
  status: completed
  responsible: Garima Singh

- name: "Add support for functor objects in clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage.

    Many computations are modelled using functor objects. Usually, a functor
    object is a lightweight C++ object which has state stored as members and has
    overridden call operator (`operator()`). For example:

    ```cpp
    struct Functor {
      double x;
      double operator()() { return x * x ;}
    };

    int main () {
      Functor Fn;
      Fn.x = 2;
      double pow2 = Fn();
      auto dpow2_dx = clad::differentiate(Fn, /*wrt*/ 0); // unsupported
      return pow2;
    }
    ```
    The goal of this project is to modify Clad to handle such cases.
  tasks: |
    Implement functor object differentiation in both forward and reverse mode.
    The candidate should be ready to investigate performance bottlenecks, add
    test and benchmarking coverage and improve documentation for various parts
    of clad not only limited to the functor object differentiation support.
  status: completed
  responsible: Parth Aurora

- name: "Utilize second order derivatives from Clad in ROOT"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation.

    ROOT is a framework for data processing, born at CERN, at the heart of the
    research on high-energy physics. Every day, thousands of physicists use ROOT
    applications to analyze their data or to perform simulations. ROOT has a
    clang-based C++ interpreter Cling and integrates with Clad to enable flexible
    automatic differentiation facility.
  tasks: |
    TFormula is a ROOT class which bridges compiled and interpreted code. Teach
    TFormula to use second order derivatives (using `clad::hessian`). The
    implementation should be very similar to what was done in
    [this pull request](https://github.com/root-project/root/pull/2745).
    The produced code should be well tested and documented. If time permits, we
    should pursue converting the C++ gradient function to CUDA device kernels.
    The integration of that feature should be comparable in terms of complexity to
    integrating `clad::hessians`.
  status: completed
  responsible: Baidyanath Kundu

- name: "Improve Cling's Development Lifecycle"
  description: |
    Cling is an interactive C++ interpreter, built on top of Clang and LLVM
    compiler infrastructure. Cling realizes the read-eval-print loop (REPL)
    concept, in order to leverage rapid application development. Implemented as
    a small extension to LLVM and Clang, the interpreter reuses their strengths
    such as the praised concise and expressive compiler diagnostics.
  tasks: |
    The project foresees to enhance the Github Actions infrastructure by adding
    development process automation tools:
      * Code Coverage information (`codecov`)
      * Static code analysis (`clang-tidy`)
      * Coding conventions checks (`clang-format`)
      * Release binary upload automation

- name: "Allow redefinition of CUDA functions in Cling"
  description: |
    Cling is an interactive C++ interpreter, built on top of Clang and LLVM
    compiler infrastructure. Cling realizes the read-eval-print loop (REPL)
    concept, in order to leverage rapid application development. Implemented as
    a small extension to LLVM and Clang, the interpreter reuses their strengths
    such as the praised concise and expressive compiler diagnostics.

    Since the development of Cling started, it got some new features to enable
    new workflows. One of the features is CUDA mode, which allows you to
    interactively develop and run CUDA code on Nvidia GPUs. Another feature is
    the redefinition of functions, variable classes and more, bypassing the
    one-definition rule of C++. This feature enables comfortable rapid
    prototyping in C++. Currently, the two features cannot be used together
    because parsing and executing CUDA code behaves differently compared to
    pure C++.
  tasks: |
    The task is to adapt the redefinitions feature of the pure C++ mode for the
    CUDA mode. To do this, the student must develop solutions to known and
    unknown problems that parsing and executing CUDA code causes.

- name: "Improving Cling Reflection for Scripting Languages"
  description: |
    Cling has basic facilities to make queries about the C++ code that it has
    seen/collected so far. These lookups assume, however, that the caller knows
    what it is looking for and the information returned, although exact, usually
    only makes sense within C++ and is thus often too specific to be used as-is.

    A scripting language, such as Python, that wants to make use of such lookups
    by name, is forced to loop over all possible entities (classes, functions,
    templates, enums, ...) to find a match. This is inefficient. Furthermore,
    many lookups will be multi-stage: a function, but which overload? A template,
    but which instantiation? A typedef, of what? The current mechanism forces
    the scripting language to provide a type-based match, even where C++ makes
    distinctions (e.g. pointer v.s. reference) that do not exist in the
    scripting language. This, too, makes lookups very inefficient.

    The returned information, once a match is found, is exact, but because of
    its specificity, requires the caller to figure out C++ concepts that have no
    meaning in the scripting language. E.g., there is no reason for Python to
    consider an implicitly instantiated function template different from an
    explicitly instantiated one.
  tasks: |
    The project should start with a design C++ entities grouping that make sense
    for scripting languages and design a query API on top of these. Special
    consideration should be given to the various name aliasing mechanisms in C++
    (e.g., `using` and `typedef`), especially as relates to C++ access rules.
    This design can likely start from the existing Cling wrapper API from Cppyy
    and modify it to improve consistency, remove redundancy, and enable usage
    patterns that minimize lookups into Cling.

    Next is a redesign of Cling's lookup facilities to support this new API
    efficiently, with particular care to use cases that require multiple,
    consecutive/related, lookups, such as finding a specific function template
    instantiation, or step-wise resolution of a typedef.

    This design is then to be implemented, using test-driven development. As a
    stretch goal, the cppyy-backend should be modified to use the new API.
  status: completed
  responsible: Baidyanath Kundu

- name: "Developing C++ modules support in CMSSW and Boost"
  description: |
    The LHC smashes groups of protons together at close to the speed of light:
    40 million times per second and with seven times the energy of the most
    powerful accelerators built up to now. Many of these will just be glancing
    blows but some will be head on collisions and very energetic. When this
    happens some of the energy of the collision is turned into mass and
    previously unobserved, short-lived particles – which could give clues about
    how Nature behaves at a fundamental level - fly out and into the detector.
    Our work includes the experimental discovery of the Higgs boson, which leads
    to the award of a Nobel prize for the underlying theory that predicted the
    Higgs boson as an important piece of the standard model theory of particle
    physics.

    CMS is a particle detector that is designed to see a wide range of particles
    and phenomena produced in high-energy collisions in the LHC. Like a
    cylindrical onion, different layers of detectors measure the different
    particles, and use this key data to build up a picture of events at the
    heart of the collision.

    Last year, thanks to [Lucas Calmolezi and GSoC](https://summerofcode.withgoogle.com/archive/2020/projects/5397144158076928/),
    the usage of boost in CMSSW was modernized. It improved the C++ modules
    support of local boost fork.
  tasks: |
    Many of the accumulated local patches add missing includes to the relevant
    boost header files. The candidate should start by proposing the existing
    patches to the boost community. Try to compile more boost-specific modules
    which is mostly a mechanical task. The student should be ready to work
    towards making the C++ module files more efficient containing less
    duplications. The student should be prepared to write a progress report and
    present the results.

- name: "Implement a shared-memory based JITLinkMemoryManager for out-of-process JITting"
  description: |
    LLVM’s JIT uses the JITLinkMemoryManager interface to allocate both working
    memory (where the JIT fixes up the relocatable objects produced by the
    compiler) and target memory (where the JIT’d code will reside in the target).
    JITLinkMemoryManager instances are also responsible for transporting
    fixed-up code from working memory to target memory. LLVM has an existing
    cross-process allocator that uses remote procedure calls (RPC) to allocate and
    copy bytes to the target process, however a more attractive solution (when
    the JIT and target process share the same physical memory) would be to use
    shared memory pages to avoid copies between processes.
  tasks: |
    Implement a shared-memory based JITLinkMemoryManager:
      * Write generic LLVM APIs for shared memory allocation.
      * Write a JITLinkMemoryManager that uses these generic APIs to allocate
        shared working-and-target memory.
      * Make an extensive performance study of the approach.
  status: completed
  responsible: Anubhab Ghosh

- name: 'Modernize the LLVM "Building A JIT" tutorial series'
  description: |
    The LLVM BuildingAJIT tutorial series teaches readers to build their own JIT
    class from scratch using LLVM’s ORC APIs, however the tutorial chapters have
    not kept pace with recent API improvements. Bring the existing tutorial
    chapters up to speed, write up a new chapter on lazy compilation (chapter
    code already available) or write a new chapter from scratch.
  tasks: |
    * Update chapter text for Chapters 1-3 -- Easy, but offers a chance to get
      up-to-speed on the APIs.
    * Write chapter text for Chapter 4 -- Chapter code is already available, but
      no chapter text exists yet.
    * Write a new chapter from scratch -- E.g. How to write an out-of-process
      JIT, or how to directly manipulate the JIT'd instruction stream using the
      ObjectLinkingLayer::Plugin API.

- name: "Write JITLink support for a new format/architecture"
  description: |
    JITLink is LLVM’s new JIT linker API -- the low-level API that transforms
    compiler output (relocatable object files) into ready-to-execute bytes in
    memory. To do this JITLink’s generic linker algorithm needs to be
    specialized to support the target object format (COFF, ELF, MachO), and
    architecture (arm, arm64, i386, x86-64). LLVM already has mature
    implementations of JITLink for MachO/arm64 and MachO/x86-64, and a
    relatively new implementation for ELF/x86-64. Write a JITLink implementation
    for a missing target that interests you. If you choose to implement support
    for a new architecture using the ELF or MachO formats then you will be able
    to re-use the existing generic code for these formats. If you want to
    implement support for a new target using the COFF format then you will need
    to write both the generic COFF support code and the architecture support
    code for your chosen architecture.
  tasks: |
    Write a JITLink specialization for a not-yet-supported format/architecture.
  status: completed
  responsible: Various Contributors

- name: "Extend clang AST to provide information for the type as written in template instantiations"
  description: |
    When instantiating a template, the template arguments are canonicalized
    before being substituted into the template pattern. Clang does not preserve
    type sugar when subsequently accessing members of the instantiation.

    ```cpp
    std::vector<std::string> vs;
    int n = vs.front(); // bad diagnostic: [...] aka 'std::basic_string<char>' [...]

     template<typename T> struct Id { typedef T type; };
     Id<size_t>::type // just 'unsigned long', 'size_t' sugar has been lost
    ```
    Clang should "re-sugar" the type when performing member access on a class
    template specialization, based on the type sugar of the accessed
    specialization. The type of vs.front() should be std::string, not
    std::basic_string<char, [...]>.

    Suggested design approach: add a new type node to represent template
    argument sugar, and implicitly create an instance of this node whenever a
    member of a class template specialization is accessed. When performing a
    single-step desugar of this node, lazily create the desugared representation
    by propagating the sugared template arguments onto inner type nodes (and in
    particular, replacing Subst*Parm nodes with the corresponding sugar). When
    printing the type for diagnostic purposes, use the annotated type sugar to
    print the type as originally written.

    For good results, template argument deduction will also need to be able to
    deduce type sugar (and reconcile cases where the same type is deduced twice
    with different sugar).
  tasks: |
    Diagnostics preserve type sugar even when accessing members of a template
    specialization. `T<unsigned long>` and `T<size_t>` are still the same type
    and the same template instantiation, but `T<unsigned long>::type` single-step
    desugars to 'unsigned long' and `T<size_t>::type` single-step desugars to
    'size_t'.
  status: completed
  responsible: Matheus Izvekov

- name: "Infrastructure: Improve Cling's packaging system cpt"
  description: |
    Cling has a flexible tool which can build and package binaries. It is
    implemented in python.
  tasks: |
    There are several improvements that can be made to cpt:
    * Fix deb package creation
    * Rewrite parts of cpt
      * Use a `if __name__ == "__main__"` block as program execution starting
        point
      * No mutating global variables
      * Minimize use of `subprocess`
      * Making cpt flake8 compliant (flexible error/violation codes)
      * Revamp argument parser (Examine possibility of dependent arguments)
  status: completed
  responsible: Surya Somayyajula

