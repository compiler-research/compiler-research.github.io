- name: "ROOT Superbuilds"
  description: |
    [ROOT](https://root.cern/) is a framework for data processing,
    born at CERN, at the heart of the research on high-energy physics.
    Every day, thousands of physicists use ROOT applications to analyze their
    data or to perform simulations. The ROOT software framework is
    foundational for the HEP ecosystem, providing capabilities such
    as IO, a C++ interpreter, GUI, and math libraries. It uses
    object-oriented concepts and build-time modules to layer between
    components. We believe additional layering formalisms will benefit
    ROOT and its users.

    Currently, ROOT is built as all-in-one package. We are working to create
    a modular version of ROOT that provides a minimal base install of core
    features, then later add functionality via incremental builds. This
    requires introducing new layering mechanisms and extending the functionality
    of the existing ROOT package manager prototype.
  
  tasks: |
    * Enhance the existing CMake build system rules to enable lazy building of packages
    * Bootstrap “RootBase”
    * Demonstrate “layered” lazy builds
  status: ongoing
  responsible: Pavlo Svirin


- name: "Improving performance of BioDynaMo using ROOT C++ Modules"
  description: |
    [ROOT](https://root.cern/) is a framework for data processing,
    born at CERN, at the heart of the research on high-energy physics.
    Every day, thousands of physicists use ROOT applications to analyze their
    data or to perform simulations. The ROOT software framework is
    foundational for the HEP ecosystem, providing capabilities such
    as IO, a C++ interpreter, GUI, and math libraries. It uses
    object-oriented concepts and build-time modules to layer between
    components. We believe additional layering formalisms will benefit
    ROOT and its users.

    BioDynaMo is an agent-based simulation platform that enables users
    to perform simulations of previously unachievable scale and complexity,
    making it possible to tackle challenging scientific research questions.
    The project has a wide range of applications in cancer research,
    epidemiology, and social sciences.

    BioDynaMo incorporates ROOT for several crucial functionalities such
    as statistical analysis, random number generation, C++-based Jupyter
    notebooks, and IO. Some features rely on efficient reflection
    information about BioDynaMo’s and user-defined C++ classes. This project
    is about improving the performance of the reflection system by upgrading
    to C++ modules.
  tasks: |
    * Rework the cmake rules to incorporate efficiently ROOT via `FetchContent`
    * Replace invocations of `genreflex` in favor of `rootcling`
    * Enable C++ modules in `rootcling`
    * Produce a comparison report
  status: ongoing
  responsible: Isaac Morales Santana

- name: "Using ROOT in the field of genome sequencing"
  description: |
    [ROOT](https://root.cern/) is a framework for data processing,
    born at CERN, at the heart of the research on high-energy physics.
    Every day, thousands of physicists use ROOT applications to analyze their
    data or to perform simulations. The ROOT software framework is
    foundational for the HEP ecosystem, providing capabilities such
    as IO, a C++ interpreter, GUI, and math libraries. It uses
    object-oriented concepts and build-time modules to layer between
    components. We believe additional layering formalisms will benefit
    ROOT and its users.

    ROOT has broader scientific uses than the field of high energy
    physics. Several studies have shown promising applications of
    the ROOT I/O system in the field of genome sequencing. This
    project is about extending the developed capability in
    [GeneROOT](https://github.com/GeneROOT) and understanding better
    the requirements of the field.

  tasks: |
    * Reproduce the results from previous comparisons against the ROOT master
    * Investigate changing the compression strategies
    * Investigate different ROOT file splitting techniques
    * Produce a comparison report
    
- name: "Implement Differentiating of the Kokkos Framework"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is
    a set of techniques to numerically evaluate the derivative of a function
    specified by a computer program. Automatic differentiation is an
    alternative technique to Symbolic differentiation and Numerical
    differentiation (the method of finite differences). Clad is based on
    Clang which provides the necessary facilities for code transformation.
    The AD library can differentiate non-trivial functions, to find a partial
    derivative for trivial cases and has good unit test coverage.

    The Kokkos C++ Performance Portability Ecosystem is a production level
    solution for writing modern C++ applications in a hardware agnostic way.
    It is part of the US Department of Energies Exascale Project – the leading
    effort in the US to prepare the HPC community for the next generation of
    super computing platforms. The Ecosystem consists of multiple libraries
    addressing the primary concerns for developing and maintaining applications
    in a portable way. The three main components are the Kokkos Core Programming
    Model, the Kokkos Kernels Math Libraries and the Kokkos Profiling and
    Debugging Tools.

    The Kokkos framework is used in several domains including climate modeling
    where gradients are important part of the simulation process. This project
    aims at teaching Clad to differentiate Kokkos entities in a performance
    portable way

  tasks: |
    * Implement common test cases for Kokkos in Clad
    * Add support for Kokkos functors
    * Add support for Kokkos lambdas
    * Incorporate the changes from the [initial Kokkos PR](https://github.com/vgvassilev/clad/pull/783)
    * Enhance existing benchmarks demonstrating effectiveness of Clad for Kokkos
    * [Stretch goal] Performance benchmarks

  status: ongoing
  responsible: Atell Yehor Krasnopolski


- name: "Integrate a Large Language Model with the xeus-cpp Jupyter kernel"
  description: |
    xeus-cpp is a Jupyter kernel for cpp based on the native implementation
    of the Jupyter protocol xeus. This enables users to write and execute
    C++ code interactively, seeing the results immediately. This REPL
    (read-eval-print-loop) nature allows rapid prototyping and iterations
    without the overhead of compiling and running separate C++ programs.
    This also achieves C++ and Python integration within a single Jupyter
    environment.

    This project aims to integrate a large language model, such as Bard/Gemini,
    with the xeus-cpp Jupyter kernel. This integration will enable users to
    interactively generate and execute code in C++ leveraging the assistance
    of the language model. Upon successful integration, users will have access
    to features such as code autocompletion, syntax checking, semantic
    understanding, and even code generation based on natural language prompts.

  tasks: |
    * Design and implement mechanisms to interface the large language model with the xeus-cpp kernel. Jupyter-AI might be used as a motivating example
    * Develop functionalities within the kernel to utilize the language model for code generation based on natural language descriptions and suggestions for autocompletion.
    * Comprehensive documentation and thorough testing/CI additions to ensure reliability.
    * [Stretch Goal] After achieving the previous milestones, the student can work on specializing the model for enhanced syntax and semantic understanding capabilities by using xeus notebooks as datasets.

  status: ongoing
  responsible: Tharun Anandh

- name: "Implementing missing features in xeus-cpp"
  description: |
    xeus-cpp is a Jupyter kernel for cpp based on the native implementation
    of the Jupyter protocol xeus. This enables users to write and execute
    C++ code interactively, seeing the results immediately. This REPL
    (read-eval-print-loop) nature allows rapid prototyping and iterations
    without the overhead of compiling and running separate C++ programs.
    This also achieves C++ and Python integration within a single Jupyter
    environment.

    The xeus-cpp is a successor of xeus-clang-repl and xeus-cling. The project
    goal is to advance the project feature support to the extent of what’s
    supported in xeus-clang-repl and xeus-cling.

  tasks: |
    * Fix occasional bugs in clang-repl directly in llvm upstream
    * Implement the value printing logic
    * Advance the wasm infrastructure
    * Write tutorials and demonstrators
    * Complete the transition of xeus-clang-repl to xeus-cpp


- name: "Adoption of CppInterOp in ROOT"
  description: |
    Incremental compilation pipelines process code chunk-by-chunk by building
    an ever-growing translation unit. Code is then lowered into the LLVM IR
    and subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration
    and makes the C++ language more user friendly. The incremental compilation
    mode is used by the interactive C++ interpreter, Cling, initially developed
    to enable interactive high-energy physics analysis in a C++ environment.
    The CppInterOp library provides a minimalist approach for other languages
    to identify C++ entities (variables, classes, etc.). This enables
    interoperability with C++ code, bringing the speed and efficiency of C++
    to simpler, more interactive languages like Python. CppInterOp provides
    primitives that are good for providing reflection information.

    The ROOT is an open-source data analysis framework used by high energy
    physics and others to analyze petabytes of data, scientifically. The
    framework provides support for data storage and processing by relying
    on Cling, Clang, LLVM for building automatically efficient I/O
    representation of the necessary C++ objects. The I/O properties of each
    object is described in a compilable C++ file called a /dictionary/.
    ROOT’s I/O dictionary system relies on reflection information provided
    by Cling and Clang. However, the reflection information system has grown
    organically and now ROOT’s core/metacling system has been hard to maintain
    and integrate.

    The goal of this project is to integrate CppInterOp in ROOT where possible.

  tasks: |
    * To achieve this goal we expect several infrastructure items to be completed such as Windows support, WASM support
    * Make reusable github actions across multiple repositories
    * Sync the state of the dynamic library manager with the one in ROOT
    * Sync the state of callfunc/jitcall with the one in ROOT
    * Prepare the infrastructure for upstreaming to llvm
    * Propose an RFC and make a presentation to the ROOT development team


- name: "Implement CppInterOp API exposing memory, ownership and thread safety information "
  description: |
    Incremental compilation pipelines process code chunk-by-chunk by building
    an ever-growing translation unit. Code is then lowered into the LLVM IR
    and subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration
    and makes the C++ language more user friendly. The incremental compilation
    mode is used by the interactive C++ interpreter, Cling, initially developed
    to enable interactive high-energy physics analysis in a C++ environment.

    Clang and LLVM provide access to C++ from other programming languages,
    but currently only exposes the declared public interfaces of such C++
    code even when it has parsed implementation details directly. Both the
    high-level and the low-level program representation has enough information
    to capture and expose more of such details to improve language
    interoperability. Examples include details of memory management, ownership
    transfer, thread safety, externalized side-effects, etc. For example, if
    memory is allocated and returned, the caller needs to take ownership; if a
    function is pure, it can be elided; if a call provides access to a data member,
    it can be reduced to an address lookup.
    
    The goal of this project is to develop API for CppInterOp which are capable of
    extracting and exposing such information AST or from JIT-ed code and use it in
    cppyy (Python-C++ language bindings) as an exemplar. If time permits, extend
    the work to persistify this information across translation units and use it on
    code compiled with Clang.

  tasks: |
    * Collect and categorize possible exposed interop information kinds
    * Write one or more facilities to extract necessary implementation details
    * Design a language-independent interface to expose this information
    * Integrate the work in clang-repl and Cling
    * Implement and demonstrate its use in cppyy as an exemplar
    * Present the work at the relevant meetings and conferences.

- name: "Implement and improve an efficient, layered tape with prefetching capabilities"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the  method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library can differentiate
    non-trivial functions, to find a partial derivative for trivial cases and has
    good unit test coverage.

    The most heavily used entity in AD is a stack-like data structure called a
    tape. For example, the first-in last-out access pattern, which naturally
    occurs in the storage of intermediate values for reverse mode AD, lends
    itself towards asynchronous storage. Asynchronous prefetching of values
    during the reverse pass allows checkpoints deeper in the stack to be stored
    furthest away in the memory hierarchy. Checkpointing provides a mechanism to
    parallelize segments of a function that can be executed on independent cores.
    Inserting checkpoints in these segments using separate tapes enables keeping
    the memory local and not sharing memory between cores. We will research
    techniques for local parallelization of the gradient reverse pass, and extend
    it to achieve better scalability and/or lower constant overheads on CPUs and
    potentially accelerators. We will evaluate techniques for efficient memory
    use, such as multi-level checkpointing support. Combining already developed
    techniques will allow executing gradient segments across different cores or
    in heterogeneous computing systems. These techniques must be robust and
    user-friendly, and minimize required application code and build system changes.

    This project aims to improve the efficiency of the clad tape and generalize
    it into a tool-agnostic facility that could be used outside of clad as well.

  tasks: |
    * Optimize the current tape by avoiding re-allocating on resize in favor of using connected slabs of array
    * Enhance existing benchmarks demonstrating the efficiency of the new tape
    * Add the tape thread safety
    * Implement multilayer tape being stored in memory and on disk
    * [Stretch goal] Support cpu-gpu transfer of the tape
    * [Stretch goal] Add infrastructure to enable checkpointing offload to the new tape
    * [Stretch goal] Performance benchmarks

- name: "Enabling CUDA compilation on Cppyy-Numba generated IR"
  description: |
    Cppyy is an automatic, run-time, Python-C++ bindings generator, for calling
    C++ from Python and Python from C++. Initial support has been added that
    allows Cppyy to hook into the high-performance Python compiler,
    Numba which compiles looped code containing C++ objects/methods/functions
    defined via Cppyy into fast machine code. Since Numba compiles the code in
    loops into machine code it crosses the language barrier just once and avoids
    large slowdowns accumulating from repeated calls between the two languages.
    Numba uses its own lightweight version of the LLVM compiler toolkit ([llvmlite](https://github.com/numba/llvmlite)) 
    that generates an intermediate code representation (LLVM IR) which is also
    supported by the Clang compiler capable of compiling CUDA C++ code.
    
    The project aims to demonstrate Cppyy's capability to provide CUDA paradigms to
    Python users without any compromise in performance. Upon successful completion
    a possible proof-of-concept can be expected in the below code snippet -

    ```python
    import cppyy
    import cppyy.numba_ext
    
    cppyy.cppdef('''
    __global__ void MatrixMul(float* A, float* B, float* out) {
        // kernel logic for matrix multiplication
    }
    ''')

    @numba.njit
    def run_cuda_mul(A, B, out):
        # Allocate memory for input and output arrays on GPU
        # Define grid and block dimensions
        # Launch the kernel
        MatrixMul[griddim, blockdim](d_A, d_B, d_out)	
    ```
  tasks: |
    * Add support for declaration and parsing of Cppyy-defined CUDA code on
    the Numba extension.
    * Design and develop a CUDA compilation and execution mechanism.
    * Prepare proper tests and documentation.

  status: ongoing
  responsible: Riya Bisht


- name: "Cppyy STL/Eigen - Automatic conversion and plugins for Python based ML-backends"
  description: |
    Cppyy is an automatic, run-time, Python-C++ bindings generator, for calling 
    C++ from Python and Python from C++. Cppyy uses pythonized wrappers of useful
    classes from libraries like STL and Eigen that allow the user to utilize them
    on the Python side. Current support follows container types in STL like
    std::vector, std::map, and std::tuple and the Matrix-based classes in
    Eigen/Dense. These cppyy objects can be plugged into idiomatic expressions
    that expect Python builtin-types. This behaviour is achieved by growing
    pythonistic methods like `__len__` while also retaining its C++ methods
    like `size`.

    Efficient and automatic conversion between C++ and Python is essential
    towards high-performance cross-language support. This approach eliminates
    overheads arising from iterative initialization such as comma insertion in
    Eigen. This opens up new avenues for the utilization of Cppyy’s bindings in
    tools that perform numerical operations for transformations, or optimization.

    The on-demand C++ infrastructure wrapped by idiomatic Python enables new
    techniques in ML tools like JAX/CUTLASS. This project allows the C++
    infrastructure to be plugged into at service to the users seeking
    high-performance library primitives that are unavailable in Python.
    
  tasks: |
    * Extend STL support for std::vectors of arbitrary dimensions
    * Improve the initialization approach for Eigen classes
    * Develop a streamlined interconversion mechanism between Python
    builtin-types, numpy.ndarray, and STL/Eigen data structures
    * Implement experimental plugins that perform basic computational  
    operations in frameworks like JAX
    * Work on integrating these plugins with toolkits like CUTLASS that
    utilise the bindings to provide a Python API

  status: ongoing
  responsible: Khushiyant

- name: "Improve the LLVM.org Website Look and Feel"
  description: |
    The llvm.org website serves as the central hub for information about the
    LLVM project, encompassing project details, current events, and relevant
    resources. Over time, the website has evolved organically, prompting the
    need for a redesign to enhance its modernity, structure, and ease of
    maintenance.
    
    The goal of this project is to create a contemporary and coherent static
    website that reflects the essence of LLVM.org. This redesign aims to improve
    navigation, taxonomy, content discoverability, and overall usability. Given
    the critical role of the website in the community, efforts will be made to
    engage with community members, seeking consensus on the proposed changes.

    LLVM's [current website](https://llvm.org) is a complicated mesh of uncoordinated pages with
    inconsistent, static links pointing to both internal and external sources.
    The website has grown substantially and haphazardly since its inception. 

    It requires a major UI and UX overhaul to be able to better serve the LLVM
    community. 

    Based on a preliminary site audit, following are some of the problem areas
    that need to be addressed.

    **Sub-Sites**: Many of the sections/sub-sites have a completely different UI/UX
    (e.g., [main](https://llvm.org), [clang](https://clang.llvm.org),
    [lists](https://lists.llvm.org/cgi-bin/mailman/listinfo),
    [foundation](https://foundation.llvm.org),
    [circt](https://circt.llvm.org/docs/GettingStarted/),
    [lnt](http://lnt.llvm.org), and [docs](https://llvm.org/docs)).
    Sub-sites are divided into 8 separate repos and use different technologies
    including [Hugo](https://github.com/llvm/circt-www/blob/main/website/config.toml),
    [Jekyll](https://github.com/llvm/clangd-www/blob/main/_config.yml), etc.

    **Navigation**: On-page navigation is inconsistent and confusing. Cross-sub-site
    navigation is inconsistent, unintuitive, and sometimes non-existent. Important
    subsections often depend on static links within (seemingly random) pages.
    Multi-word menu items are center-aligned and flow out of margins.
    
    **Pages**: Many [large write-ups](https://clang.llvm.org/docs/UsersManual.html)
    lack pagination, section boundaries, etc., making
    them seem more intimidating than they really are. Several placeholder pages
    re-route to [3rd party services](https://llvm.swoogo.com/2023devmtg),
    adding bloat and inconsistency.

    **Search**: Search options are placed in unintuitive locations, like the bottom
    of the side panel, or from [static links](https://llvm.org/docs/) to
    [redundant pages](https://llvm.org/docs/search.html). Some pages have
    no search options at all. With multiple sections of the website hosted in
    separate projects/repos, cross-sub-site search doesn't seem possible.
        
    **Expected results**: A modern, coherent-looking website that attracts new
    prospect users and empowers the existing community with better navigation,
    taxonomy, content discoverability, and overall usability. It should also
    include a more descriptive Contribution Guide ([example](https://kitian616.github.io/jekyll-TeXt-theme/docs/en/layouts)) to help novice
    contributors, as well as to help maintain a coherent site structure.

    Since the website is a critical infrastructure and most of the community
    will have an opinion this project should try to engage with the community
    building community consensus on the steps being taken. 

  tasks: |
    * Conduct a comprehensive content audit of the existing website.
    * Select appropriate technologies, preferably static site generators like
    Hugo or Jekyll.
    * Advocate for a separation of data and visualization, utilizing formats such
    as YAML and Markdown to facilitate content management without direct HTML
    coding.
    * Present three design mockups for the new website, fostering open discussions
    and allowing time for alternative proposals from interested parties.
    * Implement the chosen design, incorporating valuable feedback from the
    community.
    * Collaborate with content creators to integrate or update content as needed.
    
    The successful candidate should commit to regular participation in weekly
    meetings, deliver presentations, and contribute blog posts as requested.
    Additionally, they should demonstrate the ability to navigate the community
    process with patience and understanding.

  status: ongoing
  responsible: Chaitanya Shahare

- name: "On Demand Parsing in Clang"
  description: |
    Clang, like any C++ compiler, parses a sequence of characters as they appear,
    linearly. The linear character sequence is then turned into tokens and AST
    before lowering to machine code. In many cases the end-user code uses a small
    portion of the C++ entities from the entire translation unit but the user
    still pays the price for compiling all of the redundancies.

    This project proposes to process the heavy compiling C++ entities upon using
    them rather than eagerly. This approach is already adopted in Clang’s CodeGen
    where it allows Clang to produce code only for what is being used. On demand
    compilation is expected to significantly reduce the compilation peak memory
    and improve the compile time for translation units which sparsely use their
    contents. In addition, that would have a significant impact on interactive
    C++ where header inclusion essentially becomes a no-op and entities will be
    only parsed on demand.

    The Cling interpreter implements a very naive but efficient cross-translation
    unit lazy compilation optimization which scales across hundreds of libraries
    in the field of high-energy physics.

      ```cpp
      // A.h
      #include <string>
      #include <vector>
      template <class T, class U = int> struct AStruct {
        void doIt() { /*...*/ }
        const char* data;
        // ...
      };

      template<class T, class U = AStruct<T>>
      inline void freeFunction() { /* ... */ }
      inline void doit(unsigned N = 1) { /* ... */ }

      // Main.cpp
      #include "A.h"
      int main() {
        doit();
        return 0;
      }
      ```

      This pathological example expands to 37253 lines of code to process. Cling
      builds an index (it calls it an autoloading map) where it contains only
      forward declarations of these C++ entities. Their size is 3000 lines of code.
      
      The index looks like:

      ```cpp
      // A.h.index
      namespace std{inline namespace __1{template <class _Tp, class _Allocator> class __attribute__((annotate("$clingAutoload$vector")))  __attribute__((annotate("$clingAutoload$A.h")))  __vector_base;
        }}
      ...
      template <class T, class U = int> struct __attribute__((annotate("$clingAutoload$A.h"))) AStruct;
      ```

      Upon requiring the complete type of an entity, Cling includes the relevant
      header file to get it. There are several trivial workarounds to deal with
      default arguments and default template arguments as they now appear on the
      forward declaration and then the definition. You can read more [here](https://github.com/root-project/root/blob/master/README/README.CXXMODULES.md#header-parsing-in-root). 

      Although the implementation could not be called a reference implementation,
      it shows that the Parser and the Preprocessor of Clang are relatively stateless
      and can be used to process character sequences which are not linear in their
      nature. In particular namespace-scope definitions are relatively easy to handle
      and it is not very difficult to return to namespace-scope when we lazily parse
      something. For other contexts such as local classes we will have lost some
      essential information such as name lookup tables for local entities. However,
      these cases are probably not very interesting as the lazy parsing granularity
      is probably worth doing only for top-level entities.

      Such implementation can help with already existing issues in the standard such
      as CWG2335, under which the delayed portions of classes get parsed immediately
      when they're first needed, if that first usage precedes the end of the class.
      That should give good motivation to upstream all the operations needed to
      return to an enclosing scope and parse something.

      **Implementation approach**:

      Upon seeing a tag definition during parsing we could create a forward declaration,
      record the token sequence and mark it as a lazy definition. Later upon complete
      type request, we could re-position the parser to parse the definition body.
      We already skip some of the template specializations in a similar way [[commit](https://github.com/llvm/llvm-project/commit/b9fa99649bc99), [commit](https://github.com/llvm/llvm-project/commit/0f192e89405ce)].

      Another approach is every lazy parsed entity to record its token stream and change
      the Toks stored on LateParsedDeclarations to optionally refer to a subsequence of
      the externally-stored token sequence instead of storing its own sequence
      (or maybe change CachedTokens so it can do that transparently). One of the
      challenges would be that we currently modify the cached tokens list to append
      an "eof" token, but it should be possible to handle that in a different way.

      In some cases, a class definition can affect its surrounding context in a few
      ways you'll need to be careful about here:

      1) `struct X` appearing inside the class can introduce the name `X` into the enclosing context.

      2) `static inline` declarations can introduce global variables with non-constant initializers
      that may have arbitrary side-effects.

      For point (2), there's a more general problem: parsing any expression can trigger
      a template instantiation of a class template that has a static data member with
      an initializer that has side-effects. Unlike the above two cases, I don't think
      there's any way we can correctly detect and handle such cases by some simple analysis
      of the token stream; actual semantic analysis is required to detect such cases. But
      perhaps if they happen only in code that is itself unused, it wouldn't be terrible
      for Clang to have a language mode that doesn't guarantee that such instantiations
      actually happen.

      Alternative and more efficient implementation could be to make the lookup tables
      range based but we do not have even a prototype proving this could be a feasible
      approach.   

  tasks: |
    * Design and implementation of on-demand compilation for non-templated functions
    * Support non-templated structs and classes
    * Run performance benchmarks on relevant codebases and prepare report
    * Prepare a community RFC document
    * [Stretch goal] Support templates

    The successful candidate should commit to regular participation in weekly
    meetings, deliver presentations, and contribute blog posts as requested.
    Additionally, they should demonstrate the ability to navigate the
    community process with patience and understanding.

- name: "Enable cross-talk between Python and C++ kernels in xeus-clang-REPL by using Cppyy"
  description: |
    xeus-clang-REPL is a C++ kernel for Jupyter notebooks using clang-REPL as
    its C++ Interpreter. Cppyy is an automatic, run-time, Python-C++ bindings
    generator, for calling C++ from Python and Python from C++.

    Allowing C++ and Python to talk between themselves in a Jupyter notebook
    will allow users to switch between Python and C++ at will. This means
    that data analysts can set up their analysis in Python while running the
    actual analysis in C++. Thus reducing the time to write and debug their
    analysis pipeline.

    Initial support of cross talk between the two kernels has been implemented
    but this only supports passing primitive data types. This project aims to
    use Cppyy to extend this to support classes and functions.
  tasks: |
    * Automate creation of equivalent Cppyy objects in the Python kernel when
      objects are created in the C++ kernel
    * Automate the creation of equivalent C++ objects in the xeus-clang-REPL
      kernel when Python objects are created
    * Add documentation
  status: ongoing
  responsible: Aaron Jomy, Smit Shah

- name: "Extend the Cppyy support in Numba"
  description: |
    Numba is a JIT compiler that translates a subset of Python and NumPy code
    into fast machine code. Cppyy is an automatic, run-time, Python-C++
    bindings generator, for calling C++ from Python and Python from C++. 

    Cppyy has to pay a time penalty each time it needs to switch between
    languages which can multiply into large slowdowns when using loops with
    cppyy objects. This is where Numba can help. Since Numba compiles the
    code in loops into machine code it only has to cross the language barrier
    once and the loops thus run faster.

    Initial support for Cppyy objects in Numba enabled the use of builtin
    types and classes (see
    [cppyy docs](https://cppyy.readthedocs.io/en/latest/numba.html)),
    but some essential C++ features, such as references and STL classes,
    are not yet supported.
  tasks: |
    There are several foreseen tasks:
      * Add support for C++ reference types in Numba through Cppyy
      * Add general support for C++ templates in Numba through Cppyy
      * Add tests and documentation
  status: completed
  responsible: Aaron Jomy
    
- name: "Explore advanced activity-analysis and optimizations in reverse-mode automatic differentiation"
  description: |
    Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++
    source code of a mathematical function, it can automatically generate C++
    code for computing derivatives of the function. Clad has found uses in
    statistical analysis and uncertainty assessment applications.

    Automatic differentiation techniques involve computing partial derivatives
    of each intermediate variable encountered while automatically
    differentiating a function. Users are generally interested in the
    derivatives of a subset of the output variables with respect to a subset
    of the input variables. In this case, partial derivatives of many
    intermediate variables may not contribute to final derivatives and
    therefore can be ignored and not computed. Activity analysis finds
    intermediate variables whose partial derivatives contribute to the final
    required derivatives. It allows the AD tool to only compute the set of
    partial derivatives that are required. By not computing partial
    derivatives for such intermediate variables, both the memory requirement
    and the run time of the generated program can be reduced.
  tasks: |
    There are several foreseen tasks:
      * Research about automatic differentiation activity analysis techniques.
        Prepare an activity analysis model report with an initial strategy to
        follow. This may involve brainstorming and the need for innovative
        solutions.
      * Implement the proposed activity analysis mode.
      * Add tests and documentation.
  status: ongoing
  responsible: Petro Zarytskyi

- name: "Improve automatic differentiation of object-oriented paradigms using Clad"
  description: |
    Clad is an automatic differentiation (AD) clang plugin for C++. Given a
    C++ source code of a mathematical function, it can automatically generate
    C++ code for computing derivatives of the function. Clad has found uses
    in statistical analysis and uncertainty assessment applications.

    Object oriented paradigms (OOP) provide a structured approach for complex
    use cases, allowing for modular components that can be reused & extended.
    OOP also allows for abstraction which makes code easier to reason about &
    maintain. Gaining full OOP support is an open research area for automatic
    differentiation codes.

    This project focuses on improving support for differentiating
    object-oriented constructs in Clad. This will allow users to seamlessly
    compute derivatives to the algorithms in their projects which use an
    object-oriented model. C++ object-oriented constructs include but are
    not limited to: classes, inheritance, polymorphism, and related features
    such as operator overloading.
  tasks: |
    There are several foreseen tasks:
      * Study the current object-oriented differentiable programming support
        in Clad. Prepare a report of missing constructs that should be added to
        support the automatic differentiation of object-oriented paradigms in
        both the forward mode AD and the reverse mode AD.
        Some of the missing constructs are: differentiation of constructors,
        limited support for differentiation of operator overloads, reference
        class members, and no way of specifying custom derivatives for
        constructors.
      * Add support for the missing constructs.
      * Add proper tests and documentation.

- name: "Enable reverse-mode automatic differentiation of (CUDA) GPU kernels using Clad"
  description: |
    Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++
    source code of a mathematical function, it can automatically generate C++
    code for computing derivatives of the function. Clad has found uses in
    statistical analysis and uncertainty assessment applications. In
    scientific computing and machine learning, GPU multiprocessing can
    provide a significant boost in performance and scalability. This project
    focuses on enabling the automatic differentiation of CUDA GPU kernels using
    Clad. This will allow users to take advantage of the power of GPUs while
    benefiting from the accuracy and speed of automatic differentiation.
  tasks: |
    There are several foreseen tasks:
      * Research about automatic differentiation of code involving CUDA GPU
        kernels. Prepare a report and an initial strategy to follow.This may
        involve brainstorming and the need for innovative solutions. 
      * Enable reverse-mode automatic differentiation of CUDA GPU kernels and
        calls to CUDA GPU kernels from the host code.
      * Add proper tests and documentation.
  status: ongoing
  responsible: Christina Koutsou

- name: "Design and Develop a CUDA engine working along with C/C++ mode in clang-repl"
  description: |
    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims to
    generalize the `IncrementalCUDADeviceCompiler` of cling and add this
    functionality in clang-repl.
  tasks: |
    There are several foreseen tasks:
      * Write a detailed request for comment (RFC) document on the design choices
        and gather feedback from the LLVM community.
      * Implement the necessary functionality to support existing test cases
        available [here](https://github.com/root-project/cling/tree/master/test/CUDADeviceCode).
      * Develop clang-repl-based tutorials for the CUDA backend.
      * Investigate the requirements for supporting a HIP backend.
      * Demonstrate a CUDA-executed gradient computed by the Clad automatic
        differentiation plugin.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Anubhab Ghosh

- name: "Tutorial development with clang-repl"
  description: |
    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims
    implementing tutorials demonstrating the capabilities of the project and
    investigating adoption of clang-repl in xeus-cling.
  tasks: |
    There are several foreseen tasks:
      * Write several tutorials demostrating the current capabilities of
        clang-repl.
      * Investigate the requirements for adding clang-repl as a backend to
        xeus-cling.
      * Implement the xeus kernel protocol for clang-repl.
      * Complete a blog post about clang-repl and possibly Jupyter.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Krishna Narayanan

- name: "Implement autocompletion in clang-repl"
  description: |
    The Clang compiler is part of the LLVM compiler infrastructure and supports
    various languages such as C, C++, ObjC and ObjC++. The design of LLVM and
    Clang enables them to be used as libraries, and has led to the creation of
    an entire compiler-assisted ecosystem of tools. The relatively friendly
    codebase of Clang and advancements in the JIT infrastructure in LLVM further
    enable research into different methods for processing C++ by blurring the
    boundary between compile time and runtime. Challenges include incremental
    compilation and fitting compile/link time optimizations into a more dynamic
    environment.

    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims at the
    design and implementation of robust autocompletion when users type C++ at
    the prompt of clang-repl. For example:
    ```cpp
    [clang-repl] class MyLongClassName {};
    [clang-repl] My<tab>
    // list of suggestions.
    ```
  tasks: |
    There are several foreseen tasks:
      * Research the current approaches for autocompletion in clang such as
        `clang -code-completion-at=file:col1:col2`.
      * Implement a version of the autocompletion support using the partial
        translation unit infrastructure in clang's `libInterpreter`.
      * Investigate the requirements for semantic autocompletion which takes into
        account the exact grammar position and semantics of the code. Eg:
        ```cpp
        [clang-repl] struct S {S* operator+(S&) { return nullptr;}};
        [clang-repl] S a, b;
        [clang-repl] v = a + <tab> // shows b as the only acceptable choice here.
        ```
      * Present the work at the relevant meetings and conferences
  status: completed
  responsible: Yuquan (Fred) Fu

- name: "Implement vector mode in forward mode automatic differentiation in Clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage.

    Vector mode support will facilitate the computation of gradients using the
    forward mode AD in a single pass and thus without explicitly performing
    differentiation n times for n function arguments. The major benefit of using
    vector mode is that computationally expensive operations do not need to be
    recomputed n times for n function arguments.

    For example, if we want to compute `df/dx` and `df/dy` of a function
    `f(x, y)` using the forward mode AD in Clad, then currently we need to
    explicitly differentiate `f` two times. Vector mode will allow the
    generation of `f_d(x, y)` such that we will be able to get partial
    derivatives with respect to all the function arguments (gradient) in a
    single call.

    After successful completion of the project the code snippet should work
    as expected:
    ```cpp
    #include <clad/Differentiator/Differentiator.h>
    #include <iostream>

    double someComputationalIntensiveFn();

    double fn(double x, double y) {
      double t = someComputationalIntensiveFn(); // should be computed only once
                                                 // in the derived function.
      double res = 2 * t * x + 3 * t * x * y;
      return t;
    }

    int main() {
      auto d_fn = clad::differentiate(fn, "arr");
      double d_x = 0, d_y = 0;
      d_fn.execute(3, 5, &d_x, &d_y);
      std::cout << "Derivative of fn wrt d_x: " << d_x << "\n";
      std::cout << "Derivative of fn wrt d_y: " << d_y << "\n";
    }
    ```
  tasks: |
    The project consists of the following tasks:
      * Extend and generalize our ForwardModeVisitor to produce a single
        function with the directional derivatives.
      * Add a new mode to the top-level clad interface `clad::differentiate` for
        vector mode.
      * Extend the unit test coverage.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Vaibhav Thakkar

- name: "Add support for differentiating with respect to multidimensional arrays
         (or pointers) in Clad."
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage.

    Clad currently only supports differentiation with respect to
    single-dimensional arrays. Support for differentiation with respect to
    pointers is limited as well. This project aims to add support for
    multi-dimensional arrays (and pointers) in Clad.

    After successful completion of the project the code snippet should work
    as expected:
    ```cpp
    #include <iostream>
    #include "clad/Differentiator/Differentiator.h"

    double fn(double arr[5][5]) {
      double res = 1 * arr[0][0] + 2 * arr[1][1] + 4 * arr[2][2];
      return res * 2;
    }

    int main() {
      auto d_fn = clad::gradient(fn);
      double arr[5][5] = {{1, 2, 3, 4, 5},
                          {6, 7, 8, 9, 10},
                          {11, 12, 13, 14, 15},
                          {16, 17, 18, 19, 20},
                          {21, 22, 23, 24, 25}};
      double d_arr[5][5] = {};
      d_fn.execute(arr, d_arr);
      std::cout << "Derivative of d_fn wrt arr[0][0]: " << d_arr[0][0] << "\n"; // 2
      std::cout << "Derivative of d_fn wrt arr[1][1]: " << d_arr[1][1] << "\n"; // 4
      return 0;
    }
    ```
  tasks: |
    The project consists of the following tasks:
      * Add support for differentiation with respect to multidimensional arrays
        (and pointers) in the reverse mode.
      * Add support for differentiation with respect to multidimensional arrays
        (and pointers) in the forward mode.
      * Extend the unit test coverage.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.
  status: ongoing
  responsible: Vaibhav Thakkar

- name: "Broaden the Scope for the Floating-Point Error Estimation Framework in Clad"

  description: |
      In mathematics and computer algebra, automatic differentiation (AD) is
      a set of techniques to numerically evaluate the derivative of a function 
      specified by a computer program. Automatic differentiation is an alternative 
      technique to Symbolic differentiation and Numerical differentiation (the 
      method of finite differences). Clad is based on Clang which provides the 
      necessary facilities for code transformation. The AD library can differentiate 
      non-trivial functions, to find a partial derivative for trivial cases and has 
      good unit test coverage.

      Clad also possesses the capabilities of annotating given source code with 
      floating-point error estimation code. This allows Clad to compute any 
      floating-point related errors in the given function on the fly. This allows 
      Clad to reason about the numerical stability of the given 
      function and also analyze the sensitivity of the variables involved.

      The idea behind this project is to develop benchmarks and improve the 
      floating-point error estimation framework as necessary. Moreover, find 
      compelling real-world use-cases of the tool and investigate the possibility 
      of performing lossy compression with it.

      On successful completion of the project, the framework should have a 
      sufficiently large set of benchmarks and example usages. Moreover, 
      the framework should be able to run the following code as expected:
      ```cpp
      #include <iostream>
      #include "clad/Differentiator/Differentiator.h"

      // Some complicated function made up of doubles.
      double someFunc(double F1[], double F2[], double V3[], double COUP1, double COUP2)
      {
        double cI = 1;
        double TMP3;
        double TMP4;
        TMP3 = (F1[2] * (F2[4] * (V3[2] + V3[5]) + F2[5] * (V3[3] + cI * (V3[4]))) +
        F1[3] * (F2[4] * (V3[3] - cI * (V3[4])) + F2[5] * (V3[2] - V3[5])));
        TMP4 = (F1[4] * (F2[2] * (V3[2] - V3[5]) - F2[3] * (V3[3] + cI * (V3[4]))) +
        F1[5] * (F2[2] * (-V3[3] + cI * (V3[4])) + F2[3] * (V3[2] + V3[5])));
        return (-1.) * (COUP2 * (+cI * (TMP3) + 2. * cI * (TMP4)) + cI * (TMP3 *
        COUP1));
      }

      int main() {
        auto df = clad::estimate_error(someFunc);
        // This call should generate a report to decide
        // which variables can be downcast to a float.
        df.execute(args...);
      }
      ```
  tasks: |
    The project consists of the following tasks:
      * Add at least 5 benchmarks and compare the framework's correctness and 
        performance against them.
      * Compile at least 3 real-world examples that are complex enough to demonstrate 
        the capabilities of the framework.
      * Solve any general-purpose issues that come up with Clad during the process.
      * Prepare demos and carry out development needed for lossy compression. 

- name: "Add support for consteval and constexpr functions in clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is
    a set of techniques to numerically evaluate the derivative of a function
    specified by a computer program. Automatic differentiation is an alternative
    technique to Symbolic differentiation and Numerical differentiation (the
    method of finite differences). Clad is based on Clang which provides the
    necessary facilities for code transformation. The AD library can differentiate
    non-trivial functions, to find a partial derivative for trivial cases and has
    good unit test coverage.

    C++ provides the specifiers consteval and constexpr to allow compile time evaluation
    of functions. `constexpr` declares a possibility, i.e the function will be
    evaluated at compile time if possible, else at runtime; whereas `consteval` makes it
    mandatory, i.e every call to the function must produce a compile-time constant.

    The aim of this project is to ensure that same semantics are followed by the generated
    derivative function, i.e if the primal function is evaluated at compile time
    (because of constexpr or consteval specifier), then the generated derivative code
    should also have the same specifier to be evaluatable at compile time.

    This will enable clad to demonstrate the benefits of doing automatic differentiation
    directly on C++ frontend to utilize the benefits of clang's infrastructure.

    After successful completion of the project the code snippet should work
    as expected:
    ```cpp
    #include <cstdio>
    #include "clad/Differentiator/Differentiator.h"
    
    constexpr double sq(double x) { return x*x; }

    consteval double fn(double x, double y, double z) {
      double res = sq(x) + sq(y) + sq(z);
      return res;
    }

    int main() {
      auto d_fn = clad::gradient(fn);
      double dx = 0, dy = 0, dz = 0;
      d_fn.execute(3, 4, 5, &dx, &dy, &dz);
      printf("Gradient vector: [%.2f, %.2f, %.2f]", dx, dy, dz);
      return 0;
    }
    ```
  tasks: |
    The project consists of the following tasks:
      * Add support for differentiation with respect to consteval and constexpr
        functions in the forward mode.
      * Add support for differentiation with respect to consteval and constexpr
        functions in the reverse mode.
      * Extend the unit test coverage.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.
  status: ongoing
  responsible: Mihail Mihov

- name: "Improve robustness of dictionary to module lookups in ROOT"
  description: |
    The LHC smashes groups of protons together at close to the speed of light:
    40 million times per second and with seven times the energy of the most
    powerful accelerators built up to now. Many of these will just be glancing
    blows but some will be head on collisions and very energetic. When this
    happens some of the energy of the collision is turned into mass and
    previously unobserved, short-lived particles – which could give clues
    about how Nature behaves at a fundamental level - fly out and into the
    detector. Our work includes the experimental discovery of the Higgs boson,
    which leads to the award of a Nobel prize for the underlying theory that
    predicted the Higgs boson as an important piece of the standard model
    theory of particle physics.

    CMS is a particle detector that is designed to see a wide range of
    particles and phenomena produced in high-energy collisions in the LHC.
    Like a cylindrical onion, different layers of detectors measure the
    different particles, and use this key data to build up a picture of events
    at the heart of the collision. The
    [CMSSW](https://github.com/cms-sw/cmssw/) is a collection of software for
    the CMS experiment. It is responsible for the collection and processing of
    information about the particle collisions at the detector. CMSSW uses
    the [ROOT](root.cern/) framework to provide support for data storage and
    processing. ROOT relies on Cling, Clang, LLVM for building automatically
    efficient I/O representation of the necessary C++ objects. The I/O
    properties of each object is described in a compileable C++ file called
    a /dictionary/. ROOT's I/O dictionary system
    [relies on C++ modules](https://github.com/root-project/root/blob/master/README/README.CXXMODULES.md)
    to improve the overall memory footprint when being used.

    The few run time failures in the modules integration builds of CMSSW are
    due to dictionaries that can not be found in the modules system. These
    dictionaries are present as the mainstream system is able to find them
    using a broader search. The modules setup in ROOT needs to be extended to
    include a dictionary extension to track dictionary<->module mappings for
    C++ entities that introduce synonyms rather than declarations
    (`using std::vector<A<B>> = MyVector` where the dictionaries of A, B are
    elsewhere)
  tasks: |
    The project consists of the following tasks:
      * If an alias declaration of kind `using std::vector<A<B>> = MyVector`, we
        should store the ODRHash of it in the respective dictionary file as a
        number attached to a special variable which can be retrieved at symbol
        scanning time.
      * Track down the test failures of CMSSW and check if the proposed
        implementation works.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.

- name: "Optimize ROOT use of modules for large codebases (eg, CMSSW)"
  description: |
    The LHC smashes groups of protons together at close to the speed of light:
    40 million times per second and with seven times the energy of the most
    powerful accelerators built up to now. Many of these will just be glancing
    blows but some will be head on collisions and very energetic. When this
    happens some of the energy of the collision is turned into mass and
    previously unobserved, short-lived particles – which could give clues
    about how Nature behaves at a fundamental level - fly out and into the
    detector. Our work includes the experimental discovery of the Higgs boson,
    which leads to the award of a Nobel prize for the underlying theory that
    predicted the Higgs boson as an important piece of the standard model
    theory of particle physics.

    CMS is a particle detector that is designed to see a wide range of
    particles and phenomena produced in high-energy collisions in the LHC.
    Like a cylindrical onion, different layers of detectors measure the
    different particles, and use this key data to build up a picture of events
    at the heart of the collision. The
    [CMSSW](https://github.com/cms-sw/cmssw/) is a collection of software for
    the CMS experiment. It is responsible for the collection and processing of
    information about the particle collisions at the detector. CMSSW uses
    the [ROOT](root.cern/) framework to provide support for data storage and
    processing. ROOT relies on Cling, Clang, LLVM for building automatically
    efficient I/O representation of the necessary C++ objects. The I/O
    properties of each object is described in a compileable C++ file called
    a /dictionary/. ROOT's I/O dictionary system
    [relies on C++ modules](https://github.com/root-project/root/blob/master/README/README.CXXMODULES.md)
    to improve the overall memory footprint when being used.

    One source of performance loss is the need for symbol lookups across the
    very large set of CMSSW modules. ROOT needs to be improved to optimize this
    lookup so that it does not pull all modules defining namespace `edm` on
    `edm::X` lookups.
  tasks: |
    The project consists of the following tasks:
      * Develop an extension to the `GlobalModuleIndex` infrastructure in clang
        which keeps track of the `DeclKind` of the identifiers so that we can
        later ignore the identifiers that declare a namespace.
      * Track down the test failures of CMSSW and check if the proposed
        implementation works.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Jun Zhang

- name: "Enhance the incremental compilation error recovery in clang and clang-repl"
  description: |
    The Clang compiler is part of the LLVM compiler infrastructure and supports
    various languages such as C, C++, ObjC and ObjC++. The design of LLVM and
    Clang enables them to be used as libraries, and has led to the creation of
    an entire compiler-assisted ecosystem of tools. The relatively friendly
    codebase of Clang and advancements in the JIT infrastructure in LLVM further
    enable research into different methods for processing C++ by blurring the
    boundary between compile time and runtime. Challenges include incremental
    compilation and fitting compile/link time optimizations into a more dynamic
    environment.

    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims at
    enhancing the error recovery when users type C++ at the prompt of clang-repl.
  tasks: |
    There are several tasks to improve the current rudimentary state of the
    error recovery:
      * Extend the test coverage for error recovery
      * Find and fix cases where there are bugs
      * Implement template instantiation error recovery support
      * Implement argument-dependent lookup (ADL) recovery support

- name: "Add initial integration of Clad with Enzyme"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage. Enzyme is a prominent autodiff framework which
    works on LLVM IR.

    Clad and Enzyme can be considered as a C++ frontend and a backend automatic
    differentiation framework. In many cases, when clad needs to fall back to
    numeric differentiation it can try configuring and using Enzyme to perform
    the automatic differentiation on lower level.
  tasks: |
    Understand how both systems work. Define the Enzyme configuration
    requirements and enable Clad to communicate efficiently with Enzyme. That
    may require several steps: start building and using the optimization pass of
    Enzyme as part of the Clad toolchain; use Enzyme for cross-validation
    derivative results; etc.
  status: completed
  responsible: Manish Kausik H

- name: "Add numerical differentiation support in clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage. In a number of cases, due different
    limitations, it is either inefficient or impossible to differentiate a
    function.

    Currently, clad cannot differentiate declared-but-not-defined functions.
    In that case it issues an error. Instead, clad should fall back to its future
    numerical differentiation facilities.
  tasks: |
    Implement numerical differentiation support in clad. It should be available
    through a dedicated interface (for example `clad::num_differentiate`).
    The new functionality should be connected to the forward mode automatic
    differentiation. If time permits, a prototype of configurable error
    estimation for the numerical differentiation should be implemented.
  status: completed
  responsible: Garima Singh

- name: "Add support for functor objects in clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage.

    Many computations are modelled using functor objects. Usually, a functor
    object is a lightweight C++ object which has state stored as members and has
    overridden call operator (`operator()`). For example:

    ```cpp
    struct Functor {
      double x;
      double operator()() { return x * x ;}
    };

    int main () {
      Functor Fn;
      Fn.x = 2;
      double pow2 = Fn();
      auto dpow2_dx = clad::differentiate(Fn, /*wrt*/ 0); // unsupported
      return pow2;
    }
    ```
    The goal of this project is to modify Clad to handle such cases.
  tasks: |
    Implement functor object differentiation in both forward and reverse mode.
    The candidate should be ready to investigate performance bottlenecks, add
    test and benchmarking coverage and improve documentation for various parts
    of clad not only limited to the functor object differentiation support.
  status: completed
  responsible: Parth Aurora

- name: "Utilize second order derivatives from Clad in ROOT"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation.

    ROOT is a framework for data processing, born at CERN, at the heart of the
    research on high-energy physics. Every day, thousands of physicists use ROOT
    applications to analyze their data or to perform simulations. ROOT has a
    clang-based C++ interpreter Cling and integrates with Clad to enable flexible
    automatic differentiation facility.
  tasks: |
    TFormula is a ROOT class which bridges compiled and interpreted code. Teach
    TFormula to use second order derivatives (using `clad::hessian`). The
    implementation should be very similar to what was done in
    [this pull request](https://github.com/root-project/root/pull/2745).
    The produced code should be well tested and documented. If time permits, we
    should pursue converting the C++ gradient function to CUDA device kernels.
    The integration of that feature should be comparable in terms of complexity to
    integrating `clad::hessians`.
  status: completed
  responsible: Baidyanath Kundu

- name: "Improve Cling's Development Lifecycle"
  description: |
    Cling is an interactive C++ interpreter, built on top of Clang and LLVM
    compiler infrastructure. Cling realizes the read-eval-print loop (REPL)
    concept, in order to leverage rapid application development. Implemented as
    a small extension to LLVM and Clang, the interpreter reuses their strengths
    such as the praised concise and expressive compiler diagnostics.
  tasks: |
    The project foresees to enhance the Github Actions infrastructure by adding
    development process automation tools:
      * Code Coverage information (`codecov`)
      * Static code analysis (`clang-tidy`)
      * Coding conventions checks (`clang-format`)
      * Release binary upload automation

- name: "Allow redefinition of CUDA functions in Cling"
  description: |
    Cling is an interactive C++ interpreter, built on top of Clang and LLVM
    compiler infrastructure. Cling realizes the read-eval-print loop (REPL)
    concept, in order to leverage rapid application development. Implemented as
    a small extension to LLVM and Clang, the interpreter reuses their strengths
    such as the praised concise and expressive compiler diagnostics.

    Since the development of Cling started, it got some new features to enable
    new workflows. One of the features is CUDA mode, which allows you to
    interactively develop and run CUDA code on Nvidia GPUs. Another feature is
    the redefinition of functions, variable classes and more, bypassing the
    one-definition rule of C++. This feature enables comfortable rapid
    prototyping in C++. Currently, the two features cannot be used together
    because parsing and executing CUDA code behaves differently compared to
    pure C++.
  tasks: |
    The task is to adapt the redefinitions feature of the pure C++ mode for the
    CUDA mode. To do this, the student must develop solutions to known and
    unknown problems that parsing and executing CUDA code causes.

- name: "Improving Cling Reflection for Scripting Languages"
  description: |
    Cling has basic facilities to make queries about the C++ code that it has
    seen/collected so far. These lookups assume, however, that the caller knows
    what it is looking for and the information returned, although exact, usually
    only makes sense within C++ and is thus often too specific to be used as-is.

    A scripting language, such as Python, that wants to make use of such lookups
    by name, is forced to loop over all possible entities (classes, functions,
    templates, enums, ...) to find a match. This is inefficient. Furthermore,
    many lookups will be multi-stage: a function, but which overload? A template,
    but which instantiation? A typedef, of what? The current mechanism forces
    the scripting language to provide a type-based match, even where C++ makes
    distinctions (e.g. pointer v.s. reference) that do not exist in the
    scripting language. This, too, makes lookups very inefficient.

    The returned information, once a match is found, is exact, but because of
    its specificity, requires the caller to figure out C++ concepts that have no
    meaning in the scripting language. E.g., there is no reason for Python to
    consider an implicitly instantiated function template different from an
    explicitly instantiated one.
  tasks: |
    The project should start with a design C++ entities grouping that make sense
    for scripting languages and design a query API on top of these. Special
    consideration should be given to the various name aliasing mechanisms in C++
    (e.g., `using` and `typedef`), especially as relates to C++ access rules.
    This design can likely start from the existing Cling wrapper API from Cppyy
    and modify it to improve consistency, remove redundancy, and enable usage
    patterns that minimize lookups into Cling.

    Next is a redesign of Cling's lookup facilities to support this new API
    efficiently, with particular care to use cases that require multiple,
    consecutive/related, lookups, such as finding a specific function template
    instantiation, or step-wise resolution of a typedef.

    This design is then to be implemented, using test-driven development. As a
    stretch goal, the cppyy-backend should be modified to use the new API.
  status: completed
  responsible: Baidyanath Kundu

- name: "Developing C++ modules support in CMSSW and Boost"
  description: |
    The LHC smashes groups of protons together at close to the speed of light:
    40 million times per second and with seven times the energy of the most
    powerful accelerators built up to now. Many of these will just be glancing
    blows but some will be head on collisions and very energetic. When this
    happens some of the energy of the collision is turned into mass and
    previously unobserved, short-lived particles – which could give clues about
    how Nature behaves at a fundamental level - fly out and into the detector.
    Our work includes the experimental discovery of the Higgs boson, which leads
    to the award of a Nobel prize for the underlying theory that predicted the
    Higgs boson as an important piece of the standard model theory of particle
    physics.

    CMS is a particle detector that is designed to see a wide range of particles
    and phenomena produced in high-energy collisions in the LHC. Like a
    cylindrical onion, different layers of detectors measure the different
    particles, and use this key data to build up a picture of events at the
    heart of the collision.

    Last year, thanks to [Lucas Calmolezi and GSoC](https://summerofcode.withgoogle.com/archive/2020/projects/5397144158076928/),
    the usage of boost in CMSSW was modernized. It improved the C++ modules
    support of local boost fork.
  tasks: |
    Many of the accumulated local patches add missing includes to the relevant
    boost header files. The candidate should start by proposing the existing
    patches to the boost community. Try to compile more boost-specific modules
    which is mostly a mechanical task. The student should be ready to work
    towards making the C++ module files more efficient containing less
    duplications. The student should be prepared to write a progress report and
    present the results.

- name: "Implement a shared-memory based JITLinkMemoryManager for out-of-process JITting"
  description: |
    LLVM’s JIT uses the JITLinkMemoryManager interface to allocate both working
    memory (where the JIT fixes up the relocatable objects produced by the
    compiler) and target memory (where the JIT’d code will reside in the target).
    JITLinkMemoryManager instances are also responsible for transporting
    fixed-up code from working memory to target memory. LLVM has an existing
    cross-process allocator that uses remote procedure calls (RPC) to allocate and
    copy bytes to the target process, however a more attractive solution (when
    the JIT and target process share the same physical memory) would be to use
    shared memory pages to avoid copies between processes.
  tasks: |
    Implement a shared-memory based JITLinkMemoryManager:
      * Write generic LLVM APIs for shared memory allocation.
      * Write a JITLinkMemoryManager that uses these generic APIs to allocate
        shared working-and-target memory.
      * Make an extensive performance study of the approach.
  status: completed
  responsible: Anubhab Ghosh

- name: 'Modernize the LLVM "Building A JIT" tutorial series'
  description: |
    The LLVM BuildingAJIT tutorial series teaches readers to build their own JIT
    class from scratch using LLVM’s ORC APIs, however the tutorial chapters have
    not kept pace with recent API improvements. Bring the existing tutorial
    chapters up to speed, write up a new chapter on lazy compilation (chapter
    code already available) or write a new chapter from scratch.
  tasks: |
    * Update chapter text for Chapters 1-3 -- Easy, but offers a chance to get
      up-to-speed on the APIs.
    * Write chapter text for Chapter 4 -- Chapter code is already available, but
      no chapter text exists yet.
    * Write a new chapter from scratch -- E.g. How to write an out-of-process
      JIT, or how to directly manipulate the JIT'd instruction stream using the
      ObjectLinkingLayer::Plugin API.

- name: "Write JITLink support for a new format/architecture"
  description: |
    JITLink is LLVM’s new JIT linker API -- the low-level API that transforms
    compiler output (relocatable object files) into ready-to-execute bytes in
    memory. To do this JITLink’s generic linker algorithm needs to be
    specialized to support the target object format (COFF, ELF, MachO), and
    architecture (arm, arm64, i386, x86-64). LLVM already has mature
    implementations of JITLink for MachO/arm64 and MachO/x86-64, and a
    relatively new implementation for ELF/x86-64. Write a JITLink implementation
    for a missing target that interests you. If you choose to implement support
    for a new architecture using the ELF or MachO formats then you will be able
    to re-use the existing generic code for these formats. If you want to
    implement support for a new target using the COFF format then you will need
    to write both the generic COFF support code and the architecture support
    code for your chosen architecture.
  tasks: |
    Write a JITLink specialization for a not-yet-supported format/architecture.
  status: completed
  responsible: Various Contributors

- name: "Extend clang AST to provide information for the type as written in template instantiations"
  description: |
    When instantiating a template, the template arguments are canonicalized
    before being substituted into the template pattern. Clang does not preserve
    type sugar when subsequently accessing members of the instantiation.

    ```cpp
    std::vector<std::string> vs;
    int n = vs.front(); // bad diagnostic: [...] aka 'std::basic_string<char>' [...]

     template<typename T> struct Id { typedef T type; };
     Id<size_t>::type // just 'unsigned long', 'size_t' sugar has been lost
    ```
    Clang should "re-sugar" the type when performing member access on a class
    template specialization, based on the type sugar of the accessed
    specialization. The type of vs.front() should be std::string, not
    std::basic_string<char, [...]>.

    Suggested design approach: add a new type node to represent template
    argument sugar, and implicitly create an instance of this node whenever a
    member of a class template specialization is accessed. When performing a
    single-step desugar of this node, lazily create the desugared representation
    by propagating the sugared template arguments onto inner type nodes (and in
    particular, replacing Subst*Parm nodes with the corresponding sugar). When
    printing the type for diagnostic purposes, use the annotated type sugar to
    print the type as originally written.

    For good results, template argument deduction will also need to be able to
    deduce type sugar (and reconcile cases where the same type is deduced twice
    with different sugar).
  tasks: |
    Diagnostics preserve type sugar even when accessing members of a template
    specialization. `T<unsigned long>` and `T<size_t>` are still the same type
    and the same template instantiation, but `T<unsigned long>::type` single-step
    desugars to 'unsigned long' and `T<size_t>::type` single-step desugars to
    'size_t'.
  status: completed
  responsible: Matheus Izvekov

- name: "Infrastructure: Improve Cling's packaging system cpt"
  description: |
    Cling has a flexible tool which can build and package binaries. It is
    implemented in python.
  tasks: |
    There are several improvements that can be made to cpt:
    * Fix deb package creation
    * Rewrite parts of cpt
      * Use a `if __name__ == "__main__"` block as program execution starting
        point
      * No mutating global variables
      * Minimize use of `subprocess`
      * Making cpt flake8 compliant (flexible error/violation codes)
      * Revamp argument parser (Examine possibility of dependent arguments)
  status: completed
  responsible: Surya Somayyajula

