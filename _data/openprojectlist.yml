- name: "Design and Develop a CUDA engine working along with C/C++ mode in clang-repl"
  description: |
    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims to
    generalize the `IncrementalCUDADeviceCompiler` of cling and add this
    functionality in clang-repl.
  tasks: |
    There are several forseen tasks:
      * Write a detailed request for comment (RFC) document on the design choices
        and gather feedback from the LLVM community.
      * Implement the necessary functionality to support existing test cases
        available [here](https://github.com/root-project/cling/tree/master/test/CUDADeviceCode).
      * Develop clang-repl-based tutorials for the CUDA backend.
      * Investigate the requirements for supporting a HIP backend.
      * Demonstrate a CUDA-executed gradient computed by the Clad automatic
        differentiation plugin.
      * Present the work at the relevant meetings and conferences.

- name: "Tutorial development with clang-repl"
  description: |
    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims
    implementing tutorials demonstrating the capabilities of the project and
    investigating adoption of clang-repl in xeus-cling.
  tasks: |
    There are several forseen tasks:
      * Write several tutorials demostrating the current capabilities of
        clang-repl.
      * Investigate the requirements for adding clang-repl as a backend to
        xeus-cling.
      * Implement the xeus kernel protocol for clang-repl.
      * Complete a blog post about clang-repl and possibly Jupyter.
      * Present the work at the relevant meetings and conferences.

- name: "Implement autocompletion in clang-repl"
  description: |
    The Clang compiler is part of the LLVM compiler infrastructure and supports
    various languages such as C, C++, ObjC and ObjC++. The design of LLVM and
    Clang enables them to be used as libraries, and has led to the creation of
    an entire compiler-assisted ecosystem of tools. The relatively friendly
    codebase of Clang and advancements in the JIT infrastructure in LLVM further
    enable research into different methods for processing C++ by blurring the
    boundary between compile time and runtime. Challenges include incremental
    compilation and fitting compile/link time optimizations into a more dynamic
    environment.

    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims at the
    design and implementation of robust autocompletion when users type C++ at
    the prompt of clang-repl. For example:
    ```cpp
    [clang-repl] class MyLongClassName {};
    [clang-repl] My<tab>
    // list of suggestions.
    ```
  tasks: |
    There are several forseen tasks:
      * Research the current approaches for autocompletion in clang such as
        `clang -code-completion-at=file:col1:col2`.
      * Implement a version of the autocompletion support using the partial
        translation unit infrastructure in clang's `libInterpreter`.
      * Investigate the requirements for semantic autocompletion which takes into
        account the exact grammar position and semantics of the code. Eg:
        ```cpp
        [clang-repl] struct S {S* operator+(S&) { return nullptr;}};
        [clang-repl] S a, b;
        [clang-repl] v = a + <tab> // shows b as the only acceptable choice here.
        ```
      * Present the work at the relevant meetings and conferences

- name: "Implement vector mode in forward mode automatic differentiation in Clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage.

    Vector mode support will facilitate the computation of gradients using the
    forward mode AD in a single pass and thus without explicitly performing
    differentiation n times for n function arguments. The major benefit of using
    vector mode is that computationally expensive operations do not need to be
    recomputed n times for n function arguments.

    For example, if we want to compute `df/dx` and `df/dy` of a function
    `f(x, y)` using the forward mode AD in Clad, then currently we need to
    explicitly differentiate `f` two times. Vector mode will allow the
    generation of `f_d(x, y)` such that we will be able to get partial
    derivatives with respect to all the function arguments (gradient) in a
    single call.

    After successful completion of the project the code snippet should work
    as expected:
    ```cpp
    #include <clad/Differentiator/Differentiator.h>
    #include <iostream>

    double someComputationalIntensiveFn();

    double fn(double x, double y) {
      double t = someComputationalIntensiveFn(); // should be computed only once
                                                 // in the derived function.
      double res = 2 * t * x + 3 * t * x * y;
      return t;
    }

    int main() {
      auto d_fn = clad::differentiate(fn, "arr");
      double d_x = 0, d_y = 0;
      d_fn.execute(3, 5, &d_x, &d_y);
      std::cout << "Derivative of fn wrt d_x: " << d_x << "\n";
      std::cout << "Derivative of fn wrt d_y: " << d_y << "\n";
    }
    ```
  tasks: |
    The project consists of the following tasks:
      * Extend and generalize our ForwardModeVisitor to produce a single
        function with the directional derivatives.
      * Add a new mode to the top-level clad interface `clad::differentiate` for
        vector mode.
      * Extend the unit test coverage.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.

- name: "Add support for differentiating with respect to multidimensional arrays
         (or pointers) in Clad."
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage.

    Clad currently only supports differentiation with respect to
    single-dimensional arrays. Support for differentiation with respect to
    pointers is limited as well. This project aims to add support for
    multi-dimensional arrays (and pointers) in Clad.

    After successful completion of the project the code snippet should work
    as expected:
    ```cpp
    #include <iostream>
    #include "clad/Differentiator/Differentiator.h"

    double fn(double arr[5][5]) {
      double res = 1 * arr[0][0] + 2 * arr[1][1] + 4 * arr[2][2];
      return res * 2;
    }

    int main() {
      auto d_fn = clad::gradient(fn);
      double arr[5][5] = {{1, 2, 3, 4, 5},
                          {6, 7, 8, 9, 10},
                          {11, 12, 13, 14, 15},
                          {16, 17, 18, 19, 20},
                          {21, 22, 23, 24, 25}};
      double d_arr[5][5] = {};
      d_fn.execute(arr, d_arr);
      std::cout << "Derivative of d_fn wrt arr[0][0]: " << d_arr[0][0] << "\n"; // 2
      std::cout << "Derivative of d_fn wrt arr[1][1]: " << d_arr[1][1] << "\n"; // 4
      return 0;
    }
    ```
  tasks: |
    The project consists of the following tasks:
      * Add support for differentiation with respect to multidimensional arrays
        (and pointers) in the reverse mode.
      * Add support for differentiation with respect to multidimensional arrays
        (and pointers) in the forward mode.
      * Extend the unit test coverage.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.

- name: "Broaden the Scope for the Floating-Point Error Estimation Framework in Clad"

  description: |
      In mathematics and computer algebra, automatic differentiation (AD) is
      a set of techniques to numerically evaluate the derivative of a function 
      specified by a computer program. Automatic differentiation is an alternative 
      technique to Symbolic differentiation and Numerical differentiation (the 
      method of finite differences). Clad is based on Clang which provides the 
      necessary facilities for code transformation. The AD library can differentiate 
      non-trivial functions, to find a partial derivative for trivial cases and has 
      good unit test coverage.

      Clad also possesses the capabilities of annotating given source code with 
      floating-point error estimation code. This allows Clad to compute any 
      floating-point related errors in the given function on the fly. This allows 
      Clad to reason about the numerical stability of the given 
      function and also analyze the sensitivity of the variables involved.

      The idea behind this project is to develop benchmarks and improve the 
      floating-point error estimation framework as necessary. Moreover, find 
      compelling real-world use-cases of the tool and investigate the possibility 
      of performing lossy compression with it.

      On successful completion of the project, the framework should have a 
      sufficiently large set of benchmarks and example usages. Moreover, 
      the framework should be able to run the following code as expected:
      ```cpp
      #include <iostream>
      #include "clad/Differentiator/Differentiator.h"

      // Some complicated function made up of doubles.
      double someFunc(double F1[], double F2[], double V3[], double COUP1, double COUP2)
      {
        double cI = 1;
        double TMP3;
        double TMP4;
        TMP3 = (F1[2] * (F2[4] * (V3[2] + V3[5]) + F2[5] * (V3[3] + cI * (V3[4]))) +
        F1[3] * (F2[4] * (V3[3] - cI * (V3[4])) + F2[5] * (V3[2] - V3[5])));
        TMP4 = (F1[4] * (F2[2] * (V3[2] - V3[5]) - F2[3] * (V3[3] + cI * (V3[4]))) +
        F1[5] * (F2[2] * (-V3[3] + cI * (V3[4])) + F2[3] * (V3[2] + V3[5])));
        return (-1.) * (COUP2 * (+cI * (TMP3) + 2. * cI * (TMP4)) + cI * (TMP3 *
        COUP1));
      }

      int main() {
        auto df = clad::estimate_error(someFunc);
        // This call should generate a report to decide
        // which variables can be downcast to a float.
        df.execute(args...);
      }
      ```
  tasks: |
    The project consists of the following tasks:
      * Add at least 5 benchmarks and compare the framework's correctness and 
        performance against them.
      * Compile at least 3 real-world examples that are complex enough to demonstrate 
        the capabilities of the framework.
      * Solve any general-purpose issues that come up with Clad during the process.
      * Prepare demos and carry out development needed for lossy compression. 
      * Present the work at the relevant meetings and conferences.

- name: "Enhance the incremental compilation error recovery in clang and clang-repl"
  description: |
    The Clang compiler is part of the LLVM compiler infrastructure and supports
    various languages such as C, C++, ObjC and ObjC++. The design of LLVM and
    Clang enables them to be used as libraries, and has led to the creation of
    an entire compiler-assisted ecosystem of tools. The relatively friendly
    codebase of Clang and advancements in the JIT infrastructure in LLVM further
    enable research into different methods for processing C++ by blurring the
    boundary between compile time and runtime. Challenges include incremental
    compilation and fitting compile/link time optimizations into a more dynamic
    environment.

    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims at
    enhancing the error recovery when users type C++ at the prompt of clang-repl.
  tasks: |
    There are several tasks to improve the current rudimentary state of the
    error recovery:
      * Extend the test coverage for error recovery
      * Find and fix cases where there are bugs
      * Implement template instantiation error recovery support
      * Implement argument-dependent lookup (ADL) recovery support
  status: ongoing
  responsible: Purva Chaudhari

- name: "Add initial integration of Clad with Enzyme"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage. Enzyme is a prominent autodiff framework which
    works on LLVM IR.

    Clad and Enzyme can be considered as a C++ frontend and a backend automatic
    differentiation framework. In many cases, when clad needs to fall back to
    numeric differentiation it can try configuring and using Enzyme to perform
    the automatic differentiation on lower level.
  tasks: |
    Understand how both systems work. Define the Enzyme configuration
    requirements and enable Clad to communicate efficiently with Enzyme. That
    may require several steps: start building and using the optimization pass of
    Enzyme as part of the Clad toolchain; use Enzyme for cross-validation
    derivative results; etc.

- name: "Add numerical differentiation support in clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage. In a number of cases, due different
    limitations, it is either inefficient or impossible to differentiate a
    function.

    Currently, clad cannot differentiate declared-but-not-defined functions.
    In that case it issues an error. Instead, clad should fall back to its future
    numerical differentiation facilities.
  tasks: |
    Implement numerical differentiation support in clad. It should be available
    through a dedicated interface (for example `clad::num_differentiate`).
    The new functionality should be connected to the forward mode automatic
    differentiation. If time permits, a prototype of configurable error
    estimation for the numerical differentiation should be implemented.
  status: completed
  responsible: Garima Singh

- name: "Add support for functor objects in clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage.

    Many computations are modelled using functor objects. Usually, a functor
    object is a lightweight C++ object which has state stored as members and has
    overridden call operator (`operator()`). For example:

    ```cpp
    struct Functor {
      double x;
      double operator()() { return x * x ;}
    };

    int main () {
      Functor Fn;
      Fn.x = 2;
      double pow2 = Fn();
      auto dpow2_dx = clad::differentiate(Fn, /*wrt*/ 0); // unsupported
      return pow2;
    }
    ```
    The goal of this project is to modify Clad to handle such cases.
  tasks: |
    Implement functor object differentiation in both forward and reverse mode.
    The candidate should be ready to investigate performance bottlenecks, add
    test and benchmarking coverage and improve documentation for various parts
    of clad not only limited to the functor object differentiation support.
  status: completed
  responsible: Parth Aurora

- name: "Utilize second order derivatives from Clad in ROOT"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation.

    ROOT is a framework for data processing, born at CERN, at the heart of the
    research on high-energy physics. Every day, thousands of physicists use ROOT
    applications to analyze their data or to perform simulations. ROOT has a
    clang-based C++ interpreter Cling and integrates with Clad to enable flexible
    automatic differentiation facility.
  tasks: |
    TFormula is a ROOT class which bridges compiled and interpreted code. Teach
    TFormula to use second order derivatives (using `clad::hessian`). The
    implementation should be very similar to what was done in
    [this pull request](https://github.com/root-project/root/pull/2745).
    The produced code should be well tested and documented. If time permits, we
    should pursue converting the C++ gradient function to CUDA device kernels.
    The integration of that feature should be comparable in terms of complexity to
    integrating `clad::hessians`.
  status: completed
  responsible: Baidyanath Kundu

- name: "Improve Cling's Development Lifecycle"
  description: |
    Cling is an interactive C++ interpreter, built on top of Clang and LLVM
    compiler infrastructure. Cling realizes the read-eval-print loop (REPL)
    concept, in order to leverage rapid application development. Implemented as
    a small extension to LLVM and Clang, the interpreter reuses their strengths
    such as the praised concise and expressive compiler diagnostics.
  tasks: |
    The project foresees to enhance the Github Actions infrastructure by adding
    development process automation tools:
      * Code Coverage information (`codecov`)
      * Static code analysis (`clang-tidy`)
      * Coding conventions checks (`clang-format`)
      * Release binary upload automation

- name: "Allow redefinition of CUDA functions in Cling"
  description: |
    Cling is an interactive C++ interpreter, built on top of Clang and LLVM
    compiler infrastructure. Cling realizes the read-eval-print loop (REPL)
    concept, in order to leverage rapid application development. Implemented as
    a small extension to LLVM and Clang, the interpreter reuses their strengths
    such as the praised concise and expressive compiler diagnostics.

    Since the development of Cling started, it got some new features to enable
    new workflows. One of the features is CUDA mode, which allows you to
    interactively develop and run CUDA code on Nvidia GPUs. Another feature is
    the redefinition of functions, variable classes and more, bypassing the
    one-definition rule of C++. This feature enables comfortable rapid
    prototyping in C++. Currently, the two features cannot be used together
    because parsing and executing CUDA code behaves differently compared to
    pure C++.
  tasks: |
    The task is to adapt the redefinitions feature of the pure C++ mode for the
    CUDA mode. To do this, the student must develop solutions to known and
    unknown problems that parsing and executing CUDA code causes.

- name: "Improving Cling Reflection for Scripting Languages"
  description: |
    Cling has basic facilities to make queries about the C++ code that it has
    seen/collected so far. These lookups assume, however, that the caller knows
    what it is looking for and the information returned, although exact, usually
    only makes sense within C++ and is thus often too specific to be used as-is.

    A scripting language, such as Python, that wants to make use of such lookups
    by name, is forced to loop over all possible entities (classes, functions,
    templates, enums, ...) to find a match. This is inefficient. Furthermore,
    many lookups will be multi-stage: a function, but which overload? A template,
    but which instantiation? A typedef, of what? The current mechanism forces
    the scripting language to provide a type-based match, even where C++ makes
    distinctions (e.g. pointer v.s. reference) that do not exist in the
    scripting language. This, too, makes lookups very inefficient.

    The returned information, once a match is found, is exact, but because of
    its specificity, requires the caller to figure out C++ concepts that have no
    meaning in the scripting language. E.g., there is no reason for Python to
    consider an implicitly instantiated function template different from an
    explicitly instantiated one.
  tasks: |
    The project should start with a design C++ entities grouping that make sense
    for scripting languages and design a query API on top of these. Special
    consideration should be given to the various name aliasing mechanisms in C++
    (e.g., `using` and `typedef`), especially as relates to C++ access rules.
    This design can likely start from the existing Cling wrapper API from Cppyy
    and modify it to improve consistency, remove redundancy, and enable usage
    patterns that minimize lookups into Cling.

    Next is a redesign of Cling's lookup facilities to support this new API
    efficiently, with particular care to use cases that require multiple,
    consecutive/related, lookups, such as finding a specific function template
    instantiation, or step-wise resolution of a typedef.

    This design is then to be implemented, using test-driven development. As a
    stretch goal, the cppyy-backend should be modified to use the new API.
  status: ongoing
  responsible: Baidyanath Kundu

- name: "Developing C++ modules support in CMSSW and Boost"
  description: |
    The LHC smashes groups of protons together at close to the speed of light:
    40 million times per second and with seven times the energy of the most
    powerful accelerators built up to now. Many of these will just be glancing
    blows but some will be head on collisions and very energetic. When this
    happens some of the energy of the collision is turned into mass and
    previously unobserved, short-lived particles – which could give clues about
    how Nature behaves at a fundamental level - fly out and into the detector.
    Our work includes the experimental discovery of the Higgs boson, which leads
    to the award of a Nobel prize for the underlying theory that predicted the
    Higgs boson as an important piece of the standard model theory of particle
    physics.

    CMS is a particle detector that is designed to see a wide range of particles
    and phenomena produced in high-energy collisions in the LHC. Like a
    cylindrical onion, different layers of detectors measure the different
    particles, and use this key data to build up a picture of events at the
    heart of the collision.

    Last year, thanks to [Lucas Calmolezi and GSoC](https://summerofcode.withgoogle.com/archive/2020/projects/5397144158076928/),
    the usage of boost in CMSSW was modernized. It improved the C++ modules
    support of local boost fork.
  tasks: |
    Many of the accumulated local patches add missing includes to the relevant
    boost header files. The candidate should start by proposing the existing
    patches to the boost community. Try to compile more boost-specific modules
    which is mostly a mechanical task. The student should be ready to work
    towards making the C++ module files more efficient containing less
    duplications. The student should be prepared to write a progress report and
    present the results.

- name: "Implement a shared-memory based JITLinkMemoryManager for out-of-process JITting"
  description: |
    LLVM’s JIT uses the JITLinkMemoryManager interface to allocate both working
    memory (where the JIT fixes up the relocatable objects produced by the
    compiler) and target memory (where the JIT’d code will reside in the target).
    JITLinkMemoryManager instances are also responsible for transporting
    fixed-up code from working memory to target memory. LLVM has an existing
    cross-process allocator that uses remote procedure calls (RPC) to allocate and
    copy bytes to the target process, however a more attractive solution (when
    the JIT and target process share the same physical memory) would be to use
    shared memory pages to avoid copies between processes.
  tasks: |
    Implement a shared-memory based JITLinkMemoryManager:
      * Write generic LLVM APIs for shared memory allocation.
      * Write a JITLinkMemoryManager that uses these generic APIs to allocate
        shared working-and-target memory.
      * Make an extensive performance study of the approach.

- name: 'Modernize the LLVM "Building A JIT" tutorial series'
  description: |
    The LLVM BuildingAJIT tutorial series teaches readers to build their own JIT
    class from scratch using LLVM’s ORC APIs, however the tutorial chapters have
    not kept pace with recent API improvements. Bring the existing tutorial
    chapters up to speed, write up a new chapter on lazy compilation (chapter
    code already available) or write a new chapter from scratch.
  tasks: |
    * Update chapter text for Chapters 1-3 -- Easy, but offers a chance to get
      up-to-speed on the APIs.
    * Write chapter text for Chapter 4 -- Chapter code is already available, but
      no chapter text exists yet.
    * Write a new chapter from scratch -- E.g. How to write an out-of-process
      JIT, or how to directly manipulate the JIT'd instruction stream using the
      ObjectLinkingLayer::Plugin API.

- name: "Write JITLink support for a new format/architecture"
  description: |
    JITLink is LLVM’s new JIT linker API -- the low-level API that transforms
    compiler output (relocatable object files) into ready-to-execute bytes in
    memory. To do this JITLink’s generic linker algorithm needs to be
    specialized to support the target object format (COFF, ELF, MachO), and
    architecture (arm, arm64, i386, x86-64). LLVM already has mature
    implementations of JITLink for MachO/arm64 and MachO/x86-64, and a
    relatively new implementation for ELF/x86-64. Write a JITLink implementation
    for a missing target that interests you. If you choose to implement support
    for a new architecture using the ELF or MachO formats then you will be able
    to re-use the existing generic code for these formats. If you want to
    implement support for a new target using the COFF format then you will need
    to write both the generic COFF support code and the architecture support
    code for your chosen architecture.
  tasks: |
    Write a JITLink specialization for a not-yet-supported format/architecture.

- name: "Extend clang AST to provide information for the type as written in template instantiations"
  description: |
    When instantiating a template, the template arguments are canonicalized
    before being substituted into the template pattern. Clang does not preserve
    type sugar when subsequently accessing members of the instantiation.

    ```cpp
    std::vector<std::string> vs;
    int n = vs.front(); // bad diagnostic: [...] aka 'std::basic_string<char>' [...]

     template<typename T> struct Id { typedef T type; };
     Id<size_t>::type // just 'unsigned long', 'size_t' sugar has been lost
    ```
    Clang should "re-sugar" the type when performing member access on a class
    template specialization, based on the type sugar of the accessed
    specialization. The type of vs.front() should be std::string, not
    std::basic_string<char, [...]>.

    Suggested design approach: add a new type node to represent template
    argument sugar, and implicitly create an instance of this node whenever a
    member of a class template specialization is accessed. When performing a
    single-step desugar of this node, lazily create the desugared representation
    by propagating the sugared template arguments onto inner type nodes (and in
    particular, replacing Subst*Parm nodes with the corresponding sugar). When
    printing the type for diagnostic purposes, use the annotated type sugar to
    print the type as originally written.

    For good results, template argument deduction will also need to be able to
    deduce type sugar (and reconcile cases where the same type is deduced twice
    with different sugar).
  tasks: |
    Diagnostics preserve type sugar even when accessing members of a template
    specialization. `T<unsigned long>` and `T<size_t>` are still the same type
    and the same template instantiation, but `T<unsigned long>::type` single-step
    desugars to 'unsigned long' and `T<size_t>::type` single-step desugars to
    'size_t'.

- name: "Infrastructure: Improve Cling's packaging system cpt"
  description: |
    Cling has a flexible tool which can build and package binaries. It is
    implemented in python.
  tasks: |
    There are several improvements that can be made to cpt:
    * Fix deb package creation
    * Rewrite parts of cpt
      * Use a `if __name__ == "__main__"` block as program execution starting
        point
      * No mutating global variables
      * Minimize use of `subprocess`
      * Making cpt flake8 compliant (flexible error/violation codes)
      * Revamp argument parser (Examine possibility of dependent arguments)
