- name: "Enable GPU support and Python Interoperability via a Plugin System"
  description: |
    Xeus-Cpp integrates [Clang-Repl](https://clang.llvm.org/docs/ClangRepl.html)
    with the Xeus protocol via CppInterOp, providing a powerful platform for
    C++ development within Jupyter Notebooks.

    This project aims to introduce a plugin system for magic commands
    (cell, line, etc.), enabling a more modular and maintainable approach
    to extend Xeus-Cpp. Traditionally, magic commands introduce additional
    code and dependencies directly into the Xeus-Cpp kernel, increasing
    its complexity and maintenance burden. By offloading this functionality
    to a dedicated plugin library, we can keep the core kernel minimal
    while ensuring extensibility. This approach allows new magic commands
    to be developed, packaged, and deployed independently—eliminating the
    need to rebuild and release Xeus-Cpp for each new addition.

    Initial groundwork has already been laid with the Xplugin library,
    and this project will build upon that foundation. The goal is to clearly
    define magic command compatibility across different platforms while
    ensuring seamless integration.
    A key objective is to reimplement existing features, such as the LLM
    cell magic and the in-development Python magic, as plugins. This will
    not only improve modularity within Xeus-Cpp but also enable these
    features to be used in other Jupyter kernels.

    As an extended goal, we aim to develop a new plugin for GPU execution,
    leveraging CUDA or OpenMP to support high-performance computing workflows
    within Jupyter.
  tasks: |
    * Move the currently implemented magics and reframe using xplugin
    * Complete the on-going work on the Python interoperability magic
    * Implement a test suite for the plugins
    * Extended: To be able to execute on GPU using CUDA or OpenMP
    * Optional: Extend the magics for the wasm use case (xeus-cpp-lite)
    * Present the work at the relevant meetings and conferences
  tags: ["xeus", "xeus-cpp", "clang", "clang-repl", "jupyter", "gpu", "cuda", "python", "plugins"]

- name: Consolidate and advance the GPU infrastructure in Clad
  description: |
    Clad is a Clang-based automatic differentiation (AD) plugin for C++. Over
    the past years, several efforts have explored GPU support in Clad, including
    differentiation of CUDA code, partial support for the Thrust API, and
    prototype integrations with larger applications such as XSBench, LULESH, a
    tiny raytracer in the Clad repository, and LLM training examples (including
    work carried out last year). While these efforts demonstrate feasibility,
    they are fragmented across forks and student branches, are inconsistently
    tested, and lack reproducible benchmarking.

    This project aims to consolidate and strengthen Clad's GPU
    infrastructure. The focus is on upstreaming existing work, improving
    correctness and consistency of CUDA and Thrust support, and integrating Clad
    with realistic GPU-intensive codebases. A key goal is to establish reliable
    benchmarks and CI coverage: if current results are already good, they should
    be documented and validated; if not, the implementation should be optimized
    further so that Clad is a practical AD solution for real-world GPU
    applications.
  tasks: |
    * Recover, reproduce, and upstream past Clad+GPU work, including prior
      student projects and LLM training prototypes.
    * Integrate Clad with representative GPU applications such as XSBench,
      LULESH, and the in-tree tiny raytracer, ensuring correct end-to-end
      differentiation.
    * Establish reproducible benchmarks for these codebases and compare results
      with other AD tools (e.g. Enzyme) where feasible.
    * Reduce reliance on atomic operations, improve accumulation strategies,
      and add support for additional GPU primitives and CUDA/Thrust features.
    * Add unit and integration tests and enable GPU-aware CI to catch
      correctness and performance regressions.
    * Improve user-facing documentation and examples for CUDA and Thrust usage.
    * Present intermediate and final results at relevant project meetings and
      conferences.
  tags: ["clad", "gpu", "cuda", "gsoc", "gsoc-26"]

- name: Enable automatic differentiation of OpenMP programs with Clad
  description: |
    Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++
    source code of a mathematical function, it can automatically generate C++
    code for computing derivatives of the function. Clad is useful in powering
    statistical analysis and uncertainty assessment applications. OpenMP (Open
    Multi-Processing) is an application programming interface (API) that
    supports multi-platform shared-memory multiprocessing programming in C, C++,
    and other computing platforms.

    This project aims to develop infrastructure in Clad to support the
    differentiation of programs that contain OpenMP primitives.
  tasks: |
    *  Extend the pragma handling support
    * List the most commonly used OpenMP concurrency primitives and prepare a
      plan for how they should be handled in both forward and reverse
      accumulation in Clad
    * Add support for concurrency primitives in Clad’s forward and reverse mode
      automatic differentiation.
    * Add proper tests and documentation.
    * Present the work at the relevant meetings and conferences.
  tags: ["clad", "openmp", "gsoc", "gsoc-26"]
- name: "Enhancing LLM Training with Clad for efficient differentiation"
  description: |
    This project aims to leverage Clad, an automatic differentiation (AD)
    plugin for Clang, to optimize large language model (LLM) training primarily
    in C++. Automatic differentiation is a crucial component of deep learning
    training, enabling efficient computation of gradients for optimization
    algorithms such as stochastic gradient descent (SGD). While most modern LLM
    frameworks rely on Python-based ecosystems, their heavy reliance on
    interpreted code and dynamic computation graphs can introduce performance
    bottlenecks. By integrating Clad into C++-based deep learning pipelines,
    we can enable high-performance differentiation at the compiler level,
    reducing computational overhead and improving memory efficiency. This will
    allow developers to build more optimized training workflows without
    sacrificing flexibility or precision.

    Beyond performance improvements, integrating Clad with LLM training in C++
    opens new possibilities for deploying AI models in resource-constrained
    environments, such as embedded systems and HPC clusters, where minimizing
    memory footprint and maximizing computational efficiency are critical.
    Additionally, this work will bridge the gap between modern deep learning
    research and traditional scientific computing by providing a more robust
    and scalable AD solution for physics-informed machine learning models. By
    optimizing the differentiation process at the compiler level, this project
    has the potential to enhance both research and production-level AI
    applications, aligning with compiler-research.org's broader goal of
    advancing computational techniques for scientific discovery.
  tasks: |
    * Develop a simplified LLM setup in C++
    * Apply Clad to compute gradients for selected layers and loss functions
    * Enhance clad to support it if necessary, and prepare performance benchmarks
    * Enhance the LLM complexity to cover larger projects such as llama
    * Repeat bugfixing and benchmarks
    * Develop tests to ensure correctness, numerical stability, and efficiency
    * Document the approach, implementation details, and performance gains
    * Present progress and findings at relevant meetings and conferences
  tags: ["clad", "llm", "ai", "machine-learning", "automatic-differentiation", "cpp", "optimization"]

- name: "Integrate Clad in PyTorch and compare the gradient execution times"
  description: |
    PyTorch is a popular machine learning framework that includes its own
    automatic differentiation engine, while Clad is a Clang plugin for
    automatic differentiation that performs source-to-source transformation
    to generate functions capable of computing derivatives at compile time.

    This project aims to integrate Clad-generated functions into PyTorch
    using its C++ API and expose them to a Python workflow. The goal is
    to compare the execution times of gradients computed by Clad with those
    computed by PyTorch's native autograd system. Special attention will be
    given to CUDA-enabled gradient computations, as PyTorch also offers GPU
    acceleration capabilities.
  tasks: |
    * Incorporate Clad's API components (such as `clad::array` and `clad::tape`)
    into PyTorch using its C++ API
    * Pass Clad-generated derivative functions to PyTorch and expose them to Python
    * Perform benchmarks comparing the execution times and performance of Clad-derived
    gradients versus PyTorch's autograd
    * Automate the integration process
    * Document thoroughly the integration process and the benchmark results and identify
    potential bottlenecks in Clad's execution
    * Present the work at the relevant meetings and conferences.
  tags: ["clad", "pytorch", "python", "cuda", "benchmarking", "automatic-differentiation", "gpu"]

- name: "Enable automatic differentiation of C++ STL concurrency primitives in Clad"
  description: |
    Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++ source
    code of a mathematical function, it can automatically generate C++ code for computing
    derivatives of the function. This project focuses on enabling automatic differentiation
    of codes that utilise C++ concurrency features such as `std::thread`, `std::mutex`,
    atomic operations and more. This will allow users to fully utilize their CPU resources.
  tasks: |
    * Explore C++ concurrency primitives and prepare a report detailing the associated challenges
    involved and the features that can be feasibly supported within the given timeframe.
    * Add concurrency primitives support in Clad's forward-mode automatic differentiation.
    * Add concurrency primitives support in Clad's reverse-mode automatic differentiation.
    * Add proper tests and documentation.
    * Present the work at the relevant meetings and conferences.
  tags: ["clad", "cpp", "stl", "concurrency", "multithreading", "automatic-differentiation"]

- name: "Interactive Differential Debugging - Intelligent Auto-Stepping and Tab-Completion"
  description: |
    Differential debugging is a time-consuming task that is not well supported by existing tools.
    Existing state-of-the-art tools do not consider a baseline(working) version while debugging
    regressions in complex systems, often leading to manual efforts by developers to achieve an
    automatable task.

    The differential debugging technique analyzes a regressed system and identifies the cause of
    unexpected behaviors by comparing it to a previous version of the same system. The idd tool
    inspects two versions of the executable - a baseline and a regressed version. The interactive
    debugging session runs both executables side-by-side, allowing the users to inspect and compare
    various internal states.

    This project aims to implement intelligent stepping (debugging) and tab completions of commands.
    IDD should be able to execute until a stack frame or variable diverges between the two versions
    of the system, then drop to the debugger. This may be achieved by introducing new IDD-specific
    commands. IDD should be able to tab complete the underlying GDB/LLDB commands. The contributor
    is also expected to set up the necessary CI infrastructure to automate the testing process of IDD.
  tasks: |
    * Enable stream capture
    * Enable IDD-specific commands to execute until diverging stack or variable value.
    * Enable tab completion of commands.
    * Set up CI infrastructure to automate testing IDD.
    * Present the work at the relevant meetings and conferences.
  tags: ["debugging", "idd", "gdb", "lldb", "regression", "tooling", "ci"]

- name: "Implement CppInterOp API exposing memory, ownership and thread safety information "
  description: |
    Incremental compilation pipelines process code chunk-by-chunk by building
    an ever-growing translation unit. Code is then lowered into the LLVM IR
    and subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration
    and makes the C++ language more user friendly. The incremental compilation
    mode is used by the interactive C++ interpreter, Cling, initially developed
    to enable interactive high-energy physics analysis in a C++ environment.

    Clang and LLVM provide access to C++ from other programming languages,
    but currently only exposes the declared public interfaces of such C++
    code even when it has parsed implementation details directly. Both the
    high-level and the low-level program representation has enough information
    to capture and expose more of such details to improve language
    interoperability. Examples include details of memory management, ownership
    transfer, thread safety, externalized side-effects, etc. For example, if
    memory is allocated and returned, the caller needs to take ownership; if a
    function is pure, it can be elided; if a call provides access to a data member,
    it can be reduced to an address lookup.

    The goal of this project is to develop API for CppInterOp which are capable of
    extracting and exposing such information AST or from JIT-ed code and use it in
    cppyy (Python-C++ language bindings) as an exemplar. If time permits, extend
    the work to persistify this information across translation units and use it on
    code compiled with Clang.
  tasks: |
    * Collect and categorize possible exposed interop information kinds
    * Write one or more facilities to extract necessary implementation details
    * Design a language-independent interface to expose this information
    * Integrate the work in clang-repl and Cling
    * Implement and demonstrate its use in cppyy as an exemplar
    * Present the work at the relevant meetings and conferences.
  tags: ["cppinterop", "cppyy", "clang-repl", "cling", "interoperability", "ast", "jit"]

- name: "Implement and improve an efficient, layered tape with prefetching capabilities"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the  method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library can differentiate
    non-trivial functions, to find a partial derivative for trivial cases and has
    good unit test coverage.

    The most heavily used entity in AD is a stack-like data structure called a
    tape. For example, the first-in last-out access pattern, which naturally
    occurs in the storage of intermediate values for reverse mode AD, lends
    itself towards asynchronous storage. Asynchronous prefetching of values
    during the reverse pass allows checkpoints deeper in the stack to be stored
    furthest away in the memory hierarchy. Checkpointing provides a mechanism to
    parallelize segments of a function that can be executed on independent cores.
    Inserting checkpoints in these segments using separate tapes enables keeping
    the memory local and not sharing memory between cores. We will research
    techniques for local parallelization of the gradient reverse pass, and extend
    it to achieve better scalability and/or lower constant overheads on CPUs and
    potentially accelerators. We will evaluate techniques for efficient memory
    use, such as multi-level checkpointing support. Combining already developed
    techniques will allow executing gradient segments across different cores or
    in heterogeneous computing systems. These techniques must be robust and
    user-friendly, and minimize required application code and build system changes.

    This project aims to improve the efficiency of the clad tape and generalize
    it into a tool-agnostic facility that could be used outside of clad as well.
  tasks: |
    * Optimize the current tape by avoiding re-allocating on resize in favor of using connected slabs of array
    * Enhance existing benchmarks demonstrating the efficiency of the new tape
    * Add the tape thread safety
    * Implement multilayer tape being stored in memory and on disk
    * [Stretch goal] Support cpu-gpu transfer of the tape
    * [Stretch goal] Add infrastructure to enable checkpointing offload to the new tape
    * [Stretch goal] Performance benchmarks
  tags: ["clad", "data-structures", "performance", "memory-management", "gpu", "hpc"]

- name: "Enabling CUDA compilation on Cppyy-Numba generated IR"
  description: |
    Cppyy is an automatic, run-time, Python-C++ bindings generator, for calling
    C++ from Python and Python from C++. Initial support has been added that
    allows Cppyy to hook into the high-performance Python compiler,
    Numba which compiles looped code containing C++ objects/methods/functions
    defined via Cppyy into fast machine code. Since Numba compiles the code in
    loops into machine code it crosses the language barrier just once and avoids
    large slowdowns accumulating from repeated calls between the two languages.
    Numba uses its own lightweight version of the LLVM compiler toolkit ([llvmlite](https://github.com/numba/llvmlite))
    that generates an intermediate code representation (LLVM IR) which is also
    supported by the Clang compiler capable of compiling CUDA C++ code.

    The project aims to demonstrate Cppyy's capability to provide CUDA paradigms to
    Python users without any compromise in performance. Upon successful completion
    a possible proof-of-concept can be expected in the below code snippet -

    ```python
    import cppyy
    import cppyy.numba_ext

    cppyy.cppdef('''
    __global__ void MatrixMul(float* A, float* B, float* out) {
        // kernel logic for matrix multiplication
    }
    ''')

    @numba.njit
    def run_cuda_mul(A, B, out):
        # Allocate memory for input and output arrays on GPU
        # Define grid and block dimensions
        # Launch the kernel
        MatrixMul[griddim, blockdim](d_A, d_B, d_out)
    ```
  tasks: |
    * Add support for declaration and parsing of Cppyy-defined CUDA code on
    the Numba extension.
    * Design and develop a CUDA compilation and execution mechanism.
    * Prepare proper tests and documentation.
  tags: ["cppyy", "numba", "cuda", "llvm", "ir", "gpu", "python"]

- name: "Cppyy STL/Eigen - Automatic conversion and plugins for Python based ML-backends"
  description: |
    Cppyy is an automatic, run-time, Python-C++ bindings generator, for calling
    C++ from Python and Python from C++. Cppyy uses pythonized wrappers of useful
    classes from libraries like STL and Eigen that allow the user to utilize them
    on the Python side. Current support follows container types in STL like
    std::vector, std::map, and std::tuple and the Matrix-based classes in
    Eigen/Dense. These cppyy objects can be plugged into idiomatic expressions
    that expect Python builtin-types. This behaviour is achieved by growing
    pythonistic methods like `__len__` while also retaining its C++ methods
    like `size`.

    Efficient and automatic conversion between C++ and Python is essential
    towards high-performance cross-language support. This approach eliminates
    overheads arising from iterative initialization such as comma insertion in
    Eigen. This opens up new avenues for the utilization of Cppyy’s bindings in
    tools that perform numerical operations for transformations, or optimization.

    The on-demand C++ infrastructure wrapped by idiomatic Python enables new
    techniques in ML tools like JAX/CUTLASS. This project allows the C++
    infrastructure to be plugged into at service to the users seeking
    high-performance library primitives that are unavailable in Python.
  tasks: |
    * Extend STL support for std::vectors of arbitrary dimensions
    * Improve the initialization approach for Eigen classes
    * Develop a streamlined interconversion mechanism between Python
    builtin-types, numpy.ndarray, and STL/Eigen data structures
    * Implement experimental plugins that perform basic computational
    operations in frameworks like JAX
    * Work on integrating these plugins with toolkits like CUTLASS that
    utilise the bindings to provide a Python API
  tags: ["cppyy", "stl", "eigen", "jax", "cutlass", "numpy", "machine-learning"]

- name: "Broaden the Scope for the Floating-Point Error Estimation Framework in Clad"
  description: |
      In mathematics and computer algebra, automatic differentiation (AD) is
      a set of techniques to numerically evaluate the derivative of a function
      specified by a computer program. Automatic differentiation is an alternative
      technique to Symbolic differentiation and Numerical differentiation (the
      method of finite differences). Clad is based on Clang which provides the
      necessary facilities for code transformation. The AD library can differentiate
      non-trivial functions, to find a partial derivative for trivial cases and has
      good unit test coverage.

      Clad also possesses the capabilities of annotating given source code with
      floating-point error estimation code. This allows Clad to compute any
      floating-point related errors in the given function on the fly. This allows
      Clad to reason about the numerical stability of the given
      function and also analyze the sensitivity of the variables involved.

      The idea behind this project is to develop benchmarks and improve the
      floating-point error estimation framework as necessary. Moreover, find
      compelling real-world use-cases of the tool and investigate the possibility
      of performing lossy compression with it.

      On successful completion of the project, the framework should have a
      sufficiently large set of benchmarks and example usages. Moreover,
      the framework should be able to run the following code as expected:
      ```cpp
      #include <iostream>
      #include "clad/Differentiator/Differentiator.h"

      // Some complicated function made up of doubles.
      double someFunc(double F1[], double F2[], double V3[], double COUP1, double COUP2)
      {
        double cI = 1;
        double TMP3;
        double TMP4;
        TMP3 = (F1[2] * (F2[4] * (V3[2] + V3[5]) + F2[5] * (V3[3] + cI * (V3[4]))) +
        F1[3] * (F2[4] * (V3[3] - cI * (V3[4])) + F2[5] * (V3[2] - V3[5])));
        TMP4 = (F1[4] * (F2[2] * (V3[2] - V3[5]) - F2[3] * (V3[3] + cI * (V3[4]))) +
        F1[5] * (F2[2] * (-V3[3] + cI * (V3[4])) + F2[3] * (V3[2] + V3[5])));
        return (-1.) * (COUP2 * (+cI * (TMP3) + 2. * cI * (TMP4)) + cI * (TMP3 *
        COUP1));
      }

      int main() {
        auto df = clad::estimate_error(someFunc);
        // This call should generate a report to decide
        // which variables can be downcast to a float.
        df.execute(args...);
      }
      ```
  tasks: |
    The project consists of the following tasks:
      * Add at least 5 benchmarks and compare the framework's correctness and
        performance against them.
      * Compile at least 3 real-world examples that are complex enough to demonstrate
        the capabilities of the framework.
      * Solve any general-purpose issues that come up with Clad during the process.
      * Prepare demos and carry out development needed for lossy compression.
  tags: ["clad", "floating-point", "numerical-stability", "benchmarking", "error-estimation"]

- name: "Improve robustness of dictionary to module lookups in ROOT"
  description: |
    The LHC smashes groups of protons together at close to the speed of light:
    40 million times per second and with seven times the energy of the most
    powerful accelerators built up to now. Many of these will just be glancing
    blows but some will be head on collisions and very energetic. When this
    happens some of the energy of the collision is turned into mass and
    previously unobserved, short-lived particles – which could give clues
    about how Nature behaves at a fundamental level - fly out and into the
    detector. Our work includes the experimental discovery of the Higgs boson,
    which leads to the award of a Nobel prize for the underlying theory that
    predicted the Higgs boson as an important piece of the standard model
    theory of particle physics.

    CMS is a particle detector that is designed to see a wide range of
    particles and phenomena produced in high-energy collisions in the LHC.
    Like a cylindrical onion, different layers of detectors measure the
    different particles, and use this key data to build up a picture of events
    at the heart of the collision. The
    [CMSSW](https://github.com/cms-sw/cmssw/) is a collection of software for
    the CMS experiment. It is responsible for the collection and processing of
    information about the particle collisions at the detector. CMSSW uses
    the [ROOT](root.cern/) framework to provide support for data storage and
    processing. ROOT relies on Cling, Clang, LLVM for building automatically
    efficient I/O representation of the necessary C++ objects. The I/O
    properties of each object is described in a compileable C++ file called
    a /dictionary/. ROOT's I/O dictionary system
    [relies on C++ modules](https://github.com/root-project/root/blob/master/README/README.CXXMODULES.md)
    to improve the overall memory footprint when being used.

    The few run time failures in the modules integration builds of CMSSW are
    due to dictionaries that can not be found in the modules system. These
    dictionaries are present as the mainstream system is able to find them
    using a broader search. The modules setup in ROOT needs to be extended to
    include a dictionary extension to track dictionary<->module mappings for
    C++ entities that introduce synonyms rather than declarations
    (`using std::vector<A<B>> = MyVector` where the dictionaries of A, B are
    elsewhere)
  tasks: |
    The project consists of the following tasks:
      * If an alias declaration of kind `using std::vector<A<B>> = MyVector`, we
        should store the ODRHash of it in the respective dictionary file as a
        number attached to a special variable which can be retrieved at symbol
        scanning time.
      * Track down the test failures of CMSSW and check if the proposed
        implementation works.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.
  tags: ["root", "cern", "cpp-modules", "cmssw", "dictionary", "io"]

- name: "Enhance the incremental compilation error recovery in clang and clang-repl"
  description: |
    The Clang compiler is part of the LLVM compiler infrastructure and supports
    various languages such as C, C++, ObjC and ObjC++. The design of LLVM and
    Clang enables them to be used as libraries, and has led to the creation of
    an entire compiler-assisted ecosystem of tools. The relatively friendly
    codebase of Clang and advancements in the JIT infrastructure in LLVM further
    enable research into different methods for processing C++ by blurring the
    boundary between compile time and runtime. Challenges include incremental
    compilation and fitting compile/link time optimizations into a more dynamic
    environment.

    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims at
    enhancing the error recovery when users type C++ at the prompt of clang-repl.
  tasks: |
    There are several tasks to improve the current rudimentary state of the
    error recovery:
      * Extend the test coverage for error recovery
      * Find and fix cases where there are bugs
      * Implement template instantiation error recovery support
      * Implement argument-dependent lookup (ADL) recovery support
  tags: ["clang", "clang-repl", "incremental-compilation", "error-recovery", "jit"]

################################################################################
#                            CppAlliance Fellowships                           #
################################################################################
- name: "Implement missing C++26 features in Clang"
  description: |
    This project proposes a candidate-driven program to complete Clang’s support
    for selected C++26-era language papers and closely related C proposals. The
    project provides a vehicle for applicants to propose a standards paper that
    is not yet implemented in Clang (or to pick from a short curated list) and
    then implement that paper within the scope of the project. Work may touch
    parsing, semantic analysis, diagnostics, preprocessing, or code generation;
    when appropriate, a clang-tidy/clang-sa prototype will be offered first so
    behavior can be validated opt-in before moving into the default compiler.

    Candidates are encouraged to propose compact, well-scoped papers (syntax
    sugar, diagnostics, small semantic clarifications, preprocessing or
    embedding features) that have clear testability and low ABI risk. If a
    candidate does not have their own paper, the following example papers are
    suggested starting points: *Introduce storage-class specifiers for compound
    literals* (C23 example). *`if` declarations for C (C2y)* (based on C++
    practice). *`#embed` / binary resource inclusion (P1967)* (C++ proposal that
    maps to a C-style inclusion concept). *"Preprocessing is never undefined" /
    better preprocessing diagnostics* (P2843 — diagnostics-focused).

    Care must be taken to avoid breaking existing code, destabilizing
    diagnostics that downstream users depend on, or adding noisy warnings by
    default. All changes will be incremental, conservative by default, and
    backed by targeted regression tests and example-driven validation. Where a
    change could be noisy or controversial, an opt-in clang-tidy/clang-sa
    prototype or command-line flag will be used initially.

  tasks: |
    * A concise intake form and selection rubric for candidate papers (paper
      skeleton \+ required example test cases).
    * A prioritized backlog of selected papers to implement in this cycle.
    * For each accepted paper: an implementation plan (scoped tasks),
      incremental PRs, and a mentor assigned from the Clang team.
    * Reference Clang implementations for selected papers (parser \+ Sema \+
      diagnostics \+ CodeGen as needed), or clang-tidy/clang-sa prototypes when
      opt-in behavior is preferred.
    * Regression test suites (lit tests, compile-and-run where applicable) and
      CI integration proving correctness and no regressions on existing test
      suites.
    * Upstreamed PRs with review iteration, and a short implementation summary
    per paper (what changed, why, and any remaining limitations or interactions).
    * Onboarding docs for future candidates: the minimal paper skeleton, example
    tests, and a short "how to implement a language paper in Clang" checklist.

    **Success Criteria**
    * Implemented papers match the intent and precise wording of the submitted
      standards text (or a documented, reviewers-approved interpretation).
    * All new tests pass in Clang CI; no regressions on the existing LLVM/Clang
      test suite; no unacceptable performance or memory regressions on
      representative large codebases.
    * At least one implemented paper per funding sprint is accepted upstream as
      a Clang change or as a well-documented clang-tidy prototype with clear
      adoption guidance.
    * New diagnostics (if any) are low-noise in practice; fix-its are safe and
      validated by compile-and-run tests where applicable.
    * Positive reviewer and community feedback indicating the implementations
      are correct, maintainable, and useful.

    **Testing and Verification**

    * Require a minimal reproducer and at least 5 short lit-style test cases
      submitted with each candidate paper (good/bad/borderline/edge cases).
    * Add lit tests to clang/test and clang/CodeGen where codegen is touched;
      add diagnostics tests verifying message text and fix-its when applicable.
    * For changes that affect preprocessing, templates, or macros, include
      macro-heavy test cases and negative tests to avoid false positives.
    * For fixes touching runtime/codegen behaviour, include runtime tests (where
      feasible) to validate observable behavior and ABI stability.
    * For changes that add analysis or dataflow: include microbenchmarks and
      memory checks to ensure no unacceptable compile-time or peak memory regressions.
    * Run the new tests and a selected subset of the LLVM/Clang test suite and
      perfbench on representative OSS projects as part of the PR pipeline.

    **Difficulty:** 4/10; **Expected timeline:** 6 months FTE (program setup
      \+ 2-4 small/medium paper implementations, or equivalent aggregated
      effort; individual paper scope will affect schedule).

  tags: [cppalliance-fellow, cppalliance-fellow-26, clang, c++26, standards,
         parsing, sema, diagnostics, codegen]


- name: "Improve Clang Performance"
  description: |
    This project aims to systematically improve Clang’s performance by
    identifying, understanding, and addressing common compilation bottlenecks
    across real-world codebases. While Clang is highly capable, performance
    regressions and inefficiencies can accumulate over time due to increasing
    language complexity, new features, and evolving usage patterns. These issues
    can impact compile time, peak memory usage, and overall memory pressure,
    especially in large projects.

    The work is divided into two major phases. First, we will benchmark Clang
    across a representative set of open-source projects and compiler releases to
    identify performance hot spots and regressions. This includes analyzing
    trends over time to determine where performance has degraded and correlating
    regressions with specific upstream changes. Second, we will deeply
    investigate identified bottlenecks across the major compilation phases
    lexing, parsing, semantic analysis, and code generation and design targeted
    improvements to address them.

    Care needs to be taken to avoid changes that compromise correctness,
    diagnostic quality, or maintainability. Improvements will be data-driven,
    incremental, and supported by strong evidence from benchmarks and profiling.
    Where appropriate, fixes will prioritize broadly impactful improvements
    rather than narrowly optimized corner cases.

    Improving Clang’s performance reduces build times, lowers resource
    consumption, and improves developer productivity across the ecosystem. By
    identifying root causes of regressions and addressing systemic
    inefficiencies, this project helps ensure Clang scales effectively with
    modern C++ workloads.
  tasks: |
    * A benchmarking framework and methodology for evaluating Clang performance
      across releases.
    * A curated set of real-world open-source benchmarks covering different
      compilation phases.
    * A documented analysis of identified performance bottlenecks and
      regressions.
    * Targeted performance improvements addressing key issues in lexing,
      parsing, semantic analysis, and/or code generation.
    * Memory usage and peak memory pressure optimizations where applicable.
    * A summary report documenting regressions found, fixes implemented, and
      measurable improvements achieved.

    **Success Criteria**

    The project is successful if the identified performance issues are
    reproducible, well-understood, and meaningfully improved without introducing
    correctness regressions. All changes should be validated by benchmarks,
    pass existing and new tests, and be accepted upstream. Measurable
    improvements in compile time and/or memory usage on representative
    codebases, along with positive upstream feedback, indicate success.

    **Testing and Verification**

    We should:
    * Run performance benchmarks across multiple Clang releases to detect
      regressions.
    * Use profiling tools to attribute time and memory usage to specific
      compiler components.
    * Add regression benchmarks or tests where appropriate to prevent future
      slowdowns.
    * Validate improvements on large, real-world codebases.
    * Ensure that compile-time performance gains do not introduce excessive
      memory usage or correctness issues.

    **Difficulty:** 3/10; **Expected timeline:** 6 months FTE
  tags: [cppalliance-fellow, cppalliance-fellow-26, clang, performance,
         benchmarking, profiling, memory-optimization, codegen]


- name: "Process High-Impact clang-tidy and Clang Static Analyzer Requests"
  description: |
    This project proposes to systematically process and resolve the highest-
    impact open requests in clang-tidy and the Clang Static Analyzer. The
    clang-tidy issue tracker contains a large backlog of reports covering false
    positives, false negatives, invalid fix-it hints, performance regressions,
    and requests for new checks. Many of these issues are well-motivated and
    affect real-world adoption, but remain unresolved due to limited maintainer
    time rather than technical difficulty.

    The focus of this project is to triage these requests, identify those with
    the highest user impact, and implement conservative, well-tested fixes or
    improvements. Work will prioritize issues that reduce noise, fix incorrect
    or unsafe fix-its, close obvious coverage gaps, or address performance and
    scalability problems in commonly used checks. Where appropriate, fixes will
    apply both to clang-tidy and to the Clang Static Analyzer, depending on the
    nature of the analysis and the desired default behavior.

    Care must be taken to avoid introducing new false positives, breaking
    existing workflows, or increasing analysis cost. All changes will be driven
    by minimal reproducer test cases, include targeted regression tests, and
    follow existing Clang and LLVM contribution guidelines. Fix-it hints will
    only be added or modified when correctness can be guaranteed.

    By reducing long-standing friction points and improving the reliability of
    existing checks, this work improves trust in Clang-based tooling and
    directly benefits a broad segment of the C and C++ ecosystem without
    requiring users to adopt new tools or configurations.
  tasks: |
    * A triaged and prioritized list of high-impact open clang-tidy and Clang
      Static Analyzer issues.
    * Implementations addressing a selected set of high-impact requests
      (e.g., false positives, false negatives, invalid fix-its, or performance issues).
    * Improved or corrected fix-it hints where safe and appropriate.
    * Targeted regression tests for each resolved issue.
    * Documentation or issue updates explaining the resolution and any remaining
      limitations.
    * A short summary documenting which issues were addressed and why they were
      prioritized.

    **Success Criteria**

    The resolved issues are reproducible, correctly fixed, and accepted
    upstream. The changes reduce real-world false positives or incorrect
    behavior without introducing regressions, pass all existing and new tests,
    and receive positive feedback from users and reviewers indicating improved
    usefulness and reliability of clang-tidy and the Clang Static Analyzer.

    **Testing and Verification**

    We will add minimal reproducer-based regression tests for each issue,
    include negative tests to prevent spurious diagnostics, validate fix-it
    correctness on representative examples, and ensure that analysis performance
    and memory usage do not regress on large codebases.

    **Difficulty:** 4/10; **Expected timeline:** 6 months FTE
  tags: [cppalliance-fellow, cppalliance-fellow-26, clang, clang-tidy,
         static-analyzer, diagnostics, tooling, regression-tests]

- name: "Enhance Clang Diagnostics"
  description: |
    This project proposes to improve the clarity, usefulness, and robustness of
    Clang’s diagnostics so that developers can more easily understand and fix
    errors and warnings in C++ code. Many existing diagnostics are technically
    correct but difficult to interpret, especially for newcomers or when dealing
    with complex language features. This project focuses on refining wording,
    adding contextual information, introducing high-value new diagnostics, and
    providing reliable fix-it hints where safe and appropriate. We will also
    upstream mature clang-tidy checks into Clang itself when they are broadly
    applicable.

    Beyond immediate improvements, this work establishes a foundation for more
    systematic diagnostic quality improvements, such as developing informal
    style guidelines and identifying recurring sources of confusion. Care must
    be taken to avoid false positives, excessive verbosity, or breaking users
    who rely on stable diagnostic output. Changes will therefore be incremental,
    well-tested, and conservative by default.

    Clearer diagnostics reduce debugging time, lower the barrier to entry for
    C++, and improve developer productivity across the ecosystem. By upstreaming
    proven checks and improving default behavior, the benefits reach all Clang
    users without requiring additional tools or configuration.
  tasks: |
    * A curated set of rewritten diagnostics with clearer wording and added
      context.
    * New default diagnostics for subtle or silent semantic issues.
    * Improved and expanded fix-it hints.
    * Migration of selected clang-tidy checks into Clang proper.
    * A list of clang-tidy diagnostics which can be moved to clang including but
      not limited to bugprone-return-const-ref-from-parameter,
      bugprone-raw-memory-call-on-non-trivial-type,
      bugprone-multiple-new-in-one-expression,
      bugprone-multiple-statement-macro. bugprone-use-after-move.
    * Implementation of diagnostics for silent change of semantics during third
      party code changes such as https://godbolt.org/z/E9Me1djP6
    * A short summary documenting which diagnostics were improved and why.

    **Success Criteria**

    The enhanced diagnostics trigger correctly in intended scenarios, introduce
    no significant false positives or regressions, pass all existing and new
    tests, and are accepted upstream with positive feedback indicating improved
    clarity and usefulness.

    **Testing and Verification**

    We should add targeted regression tests for each diagnostic change, validate
    fix-its on representative examples, perform negative testing to prevent
    spurious warnings, and ensure compile-time performance remains stable on
    large codebases.

    **Difficulty:** 5/10; **Expected timeline:** 6 months FTE
  tags: [cppalliance-fellow, cppalliance-fellow-26, clang, diagnostics,
         clang-tidy, fixit, developer-experience]

- name: "On Demand Parsing in Clang"
  description: |
    Clang, like any C++ compiler, parses a sequence of characters as they appear,
    linearly. The linear character sequence is then turned into tokens and AST
    before lowering to machine code. In many cases the end-user code uses a small
    portion of the C++ entities from the entire translation unit but the user
    still pays the price for compiling all of the redundancies.

    This project proposes to process the heavy compiling C++ entities upon using
    them rather than eagerly. This approach is already adopted in Clang’s CodeGen
    where it allows Clang to produce code only for what is being used. On demand
    compilation is expected to significantly reduce the compilation peak memory
    and improve the compile time for translation units which sparsely use their
    contents. In addition, that would have a significant impact on interactive
    C++ where header inclusion essentially becomes a no-op and entities will be
    only parsed on demand.

    The Cling interpreter implements a very naive but efficient cross-translation
    unit lazy compilation optimization which scales across hundreds of libraries
    in the field of high-energy physics.

      ```cpp
      // A.h
      #include <string>
      #include <vector>
      template <class T, class U = int> struct AStruct {
        void doIt() { /*...*/ }
        const char* data;
        // ...
      };

      template<class T, class U = AStruct<T>>
      inline void freeFunction() { /* ... */ }
      inline void doit(unsigned N = 1) { /* ... */ }

      // Main.cpp
      #include "A.h"
      int main() {
        doit();
        return 0;
      }
      ```

      This pathological example expands to 37253 lines of code to process. Cling
      builds an index (it calls it an autoloading map) where it contains only
      forward declarations of these C++ entities. Their size is 3000 lines of code.

      The index looks like:

      ```cpp
      // A.h.index
      namespace std{inline namespace __1{template <class _Tp, class _Allocator> class __attribute__((annotate("$clingAutoload$vector")))  __attribute__((annotate("$clingAutoload$A.h")))  __vector_base;
        }}
      ...
      template <class T, class U = int> struct __attribute__((annotate("$clingAutoload$A.h"))) AStruct;
      ```

      Upon requiring the complete type of an entity, Cling includes the relevant
      header file to get it. There are several trivial workarounds to deal with
      default arguments and default template arguments as they now appear on the
      forward declaration and then the definition. You can read more [here](https://github.com/root-project/root/blob/master/README/README.CXXMODULES.md#header-parsing-in-root).

      Although the implementation could not be called a reference implementation,
      it shows that the Parser and the Preprocessor of Clang are relatively stateless
      and can be used to process character sequences which are not linear in their
      nature. In particular namespace-scope definitions are relatively easy to handle
      and it is not very difficult to return to namespace-scope when we lazily parse
      something. For other contexts such as local classes we will have lost some
      essential information such as name lookup tables for local entities. However,
      these cases are probably not very interesting as the lazy parsing granularity
      is probably worth doing only for top-level entities.

      Such implementation can help with already existing issues in the standard such
      as CWG2335, under which the delayed portions of classes get parsed immediately
      when they're first needed, if that first usage precedes the end of the class.
      That should give good motivation to upstream all the operations needed to
      return to an enclosing scope and parse something.

      **Implementation approach**:

      Upon seeing a tag definition during parsing we could create a forward declaration,
      record the token sequence and mark it as a lazy definition. Later upon complete
      type request, we could re-position the parser to parse the definition body.
      We already skip some of the template specializations in a similar way [[commit](https://github.com/llvm/llvm-project/commit/b9fa99649bc99), [commit](https://github.com/llvm/llvm-project/commit/0f192e89405ce)].

      Another approach is every lazy parsed entity to record its token stream and change
      the Toks stored on LateParsedDeclarations to optionally refer to a subsequence of
      the externally-stored token sequence instead of storing its own sequence
      (or maybe change CachedTokens so it can do that transparently). One of the
      challenges would be that we currently modify the cached tokens list to append
      an "eof" token, but it should be possible to handle that in a different way.

      In some cases, a class definition can affect its surrounding context in a few
      ways you'll need to be careful about here:

      1) `struct X` appearing inside the class can introduce the name `X` into the enclosing context.

      2) `static inline` declarations can introduce global variables with non-constant initializers
      that may have arbitrary side-effects.

      For point (2), there's a more general problem: parsing any expression can trigger
      a template instantiation of a class template that has a static data member with
      an initializer that has side-effects. Unlike the above two cases, I don't think
      there's any way we can correctly detect and handle such cases by some simple analysis
      of the token stream; actual semantic analysis is required to detect such cases. But
      perhaps if they happen only in code that is itself unused, it wouldn't be terrible
      for Clang to have a language mode that doesn't guarantee that such instantiations
      actually happen.

      Alternative and more efficient implementation could be to make the lookup tables
      range based but we do not have even a prototype proving this could be a feasible
      approach.
  tasks: |
    * A prototype deferring parsing of non-templated functions and classes.
    * Initial support for lazy parsing of class and struct definitions.
    * Benchmark results comparing memory usage and compile time.
    * A design document or RFC describing the approach and trade-offs.
    * A stretch prototype extending the mechanism to templates.

    **Success Criteria**

    The prototype shows measurable reductions in memory usage or compile time on
    representative workloads, preserves correct semantics, passes Clang's test
    suite, and receives constructive community feedback through the RFC process.

    **Testing and Verification**

    We should add regression tests covering lazy parsing behavior, validate
    correctness on pathological and real-world examples, benchmark against
    baseline builds, and ensure deferred parsing is triggered correctly when
    entities are referenced.

    **Difficulty:** 10/10; **Expected timeline:** 6 months FTE
  tags: [cppalliance-fellow, cppalliance-fellow-26, clang, parsing,
         lazy-parsing, scalability, memory-optimization, templates, cling]

- name: "Optimize Usage of Source Locations in Clang Modules"
  description: |
    This project proposes to reduce source-location memory pressure in modular
    builds by reusing source-location allocations for duplicated inputs,
    extending the lifetime of Clang’s 32-bit source-location representation. In
    large modular builds, repeated inclusion of the same headers across modules
    can quickly exhaust available offsets.

    Rather than immediately switching to a more invasive 64-bit representation,
    this project explores reusing existing allocations through interval mapping
    and careful coordination with module loading. This approach introduces
    complexity in diagnostics and include-stack reconstruction, so correctness
    and transparency are key concerns.

    If successful, the work avoids a disruptive global change, reduces memory
    usage, and improves Clang’s scalability for modern modular C++ codebases.
  tasks: |
    * An interval-mapping mechanism to detect and reuse source-location slabs.
    * Updates to module loading and deserialization to enable reuse.
    * A prototype demonstrating reduced duplication in multi-module builds.
    * Measurements showing memory savings.
    * Documentation of diagnostic implications and mitigations.

    **Success Criteria**

    Duplicated module inputs no longer cause proportional growth in
    source-location allocations, modular builds complete without exhaustion,
    diagnostics remain correct in tested cases, and the design is accepted or
    constructively reviewed upstream.

    **Testing and Verification**

    We should reproduce known problematic module scenarios, compare allocation
    statistics before and after changes, run regression tests with emphasis on
    diagnostics, and validate behavior across different module load orders.

    **Difficulty:** 6/10; **Expected timeline:** 6 months FTE
  tags: [cppalliance-fellow, cppalliance-fellow-26, clang, modules,
         source-locations, memory-optimization, diagnostics]

- name: "Consistent Error Recovery Infrastructure"
  description: |
    This project proposes to improve Clang’s error recovery, particularly for
    interactive and incremental use cases such as clang-repl. Today, invalid or
    incomplete C++ input can easily leave the compiler in an unrecoverable
    state, limiting its usefulness for exploration, teaching, and rapid
    prototyping.

    This project strengthens recovery across templates, ADL failures, and name
    collisions, while improving performance and crash resilience. Error recovery
    must be powerful without hiding real problems or destabilizing compiler
    state, so improvements will be carefully scoped and heavily tested.

    Better recovery makes interactive C++ tooling more practical, supports
    educational workflows, and provides shared infrastructure for future
    incremental and REPL-based tools built on Clang.
  tasks: |
    * Expanded test coverage for error recovery scenarios.
    * Fixes for known recovery bugs.
    * Recovery support for templates, ADL, and name collisions.
    * Optional bump-allocator support for recovery paths.
    * Improved crash resilience and value printing in clang-repl.

    **Success Criteria**

    The compiler and REPL recover from common errors without crashing, continue
    accepting input after failures, pass all tests, and demonstrate clearly
    improved interactive usability.

    **Testing and Verification**

    We should simulate interactive sessions with invalid input, add targeted
    regression tests for recovery paths, fuzz error cases to detect crashes, and
    ensure normal compilation performance is unaffected. In particular we should
    include a test case in clang, undo it and include it again without any
    errors produced.

    **Difficulty:** 7/10; **Expected timeline:** 6 months FTE
  tags: [cppalliance-fellow, cppalliance-fellow-26, clang, error-recovery, repl,
         interactive, robustness]

################################################################################
#                                     2025                                     #
################################################################################
- name: "Agent-Based Simulation of CAR-T Cell Therapy Using BioDynaMo"
  description: |
    Chimeric Antigen Receptor T-cell (CAR-T) therapy has revolutionized
    cancer treatment by harnessing the immune system to target and
    destroy tumor cells. While CAR-T has demonstrated success in blood
    cancers, its effectiveness in solid tumors remains limited due to
    challenges such as poor tumor infiltration, immune suppression,
    and T-cell exhaustion. To improve therapy outcomes, computational
    modeling is essential for optimizing treatment parameters, predicting
    failures, and testing novel interventions. However, existing models
    of CAR-T behavior are often overly simplistic or computationally expensive,
    making them impractical for large-scale simulations.

    This project aims to develop a scalable agent-based simulation of CAR-T
    therapy using BioDynaMo, an open-source high-performance biological
    simulation platform. By modeling T-cell migration, tumor engagement,
    and microenvironmental factors, we will investigate key treatment variables
    such as dosage, administration timing, and combination therapies. The
    simulation will allow researchers to explore how tumor microenvironment
    suppression (e.g., regulatory T-cells, hypoxia, immunosuppressive cytokines)
    affects CAR-T efficacy and what strategies such as checkpoint inhibitors or
    cytokine support can improve outcomes.

    The final deliverable will be a fully documented, reproducible BioDynaMo
    simulation, along with analysis tools for visualizing treatment dynamics.
    The model will provide insights into the optimal CAR-T cell dosing, tumor
    penetration efficiency, and factors influencing therapy resistance. This
    project will serve as a foundation for in silico testing of immunotherapies,
    reducing the need for costly and time-consuming laboratory experiments while
    accelerating the development of more effective cancer treatments.

  tasks: |
    * Expected plan of work:

    - Phase 1: Initial Setup & Simple T-cell Dynamics
    - Phase 2: Advanced CAR-T Cell Behavior & Tumor Interaction
    - Phase 3: Integration of Immunosuppressive Factors & Data Visualization

    * Expected deliverables

    - A fully documented BioDynaMo simulation of CAR-T therapy.
    - Analysis scripts for visualizing tumor reduction and CAR-T efficacy.
    - Performance benchmarks comparing different treatment strategies.
    - A research-style report summarizing findings.
  status: completed
  responsible: Salvador de la Torre Gonzalez

- name: "Support usage of Thrust API in Clad"
  description: |
    The rise of ML has shed light into the power of GPUs and researchers are looking
    for ways to incorporate them in their projects as a lightweight parallelization
    method. Consequently, General Purpose GPU programming is becoming a very popular
    way to speed up execution time.

    Clad is a clang plugin for automatic differentiation that performs source-to-source
    transformation and produces a function capable of computing the derivatives of a
    given function at compile time. This project aims to enhance Clad by adding support
    for Thrust, a parallel algorithms library designed for GPUs and other accelerators.
    By supporting Thrust, Clad will be able to differentiate algorithms that rely on
    Thrust's parallel computing primitives, unlocking new possibilities for GPU-based
    machine learning, scientific computing, and numerical optimization.

  tasks: |
    * Research and decide on the most valuable Thrust functions to support in Clad
    * Create pushforward and pullback functions for these Thrust functions
    * Write tests that cover the additions
    * Include demos of using Clad on open source code examples that call Thrust functions
    * Write documentation on which Thrust functions are supported in Clad
    * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Abdelrhman Elrawy

- name: "Implementing Debugging Support in Xeus-Cpp"
  description: |
    xeus-cpp is an interactive execution environment for C++ in Jupyter
    notebooks, built on the Clang-Repl C++ interpreter, provided by
    [CppInterOp](https://github.com/compiler-research/CppInterOp/). While
    xeus-cpp enables a seamless workflow for running C++ code interactively,
    the lack of an integrated debugging experience remains a gap, especially
    when dealing with code that is dynamically compiled and executed through
    LLVM's JIT(Just-In-Time) infrastructure.

    Jupyter's debugging system follows the Debug Adapter Protocol (DAP),
    enabling seamless integration of debuggers into interactive kernels.
    Existing Jupyter kernels, such as the IPython & the xeus-python kernel,
    have successfully implemented debugging workflows that support
    breakpoints, variable inspection, and execution control, even in
    dynamically executed environments. These implementations address
    challenges such as symbol resolution and source mapping for dynamically
    generated code, ensuring that debugging within Jupyter remains intuitive
    and user-friendly.

    However, debugging C++ inside an interactive environment presents unique
    challenges, particularly due to Clang-Repl’s use of LLVM’s ORC JIT to
    compile and execute code dynamically. To integrate debugging into xeus-cpp,
    the project will explore existing solutions for DAP implementations like
    `lldb_dap` and debuggers like lldb that can interface with Jupyter while
    effectively supporting the execution model of Clang-Repl.

  tasks: |
    * Seamless debugging integration, establishing reliable interactions
    between xeus-cpp, a Debug Adapter Protocol (DAP) implementation, and
    a debugger.
    * Implement a testing framework through `xeus-zmq` to thoroughly test
    the debugger. This can be inspired by an existing implementation
    in `xeus-python`.
    * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Abhinav Kumar


- name: "Using ROOT in the field of genome sequencing"
  description: |
    [ROOT](https://root.cern/) is a framework for data processing,
    born at CERN, at the heart of the research on high-energy physics.
    Every day, thousands of physicists use ROOT applications to analyze their
    data or to perform simulations. The ROOT software framework is
    foundational for the HEP ecosystem, providing capabilities such
    as IO, a C++ interpreter, GUI, and math libraries. It uses
    object-oriented concepts and build-time modules to layer between
    components. We believe additional layering formalisms will benefit
    ROOT and its users.

    ROOT has broader scientific uses than the field of high energy
    physics. Several studies have shown promising applications of
    the ROOT I/O system in the field of genome sequencing. This
    project is about extending the developed capability in
    [GeneROOT](https://github.com/GeneROOT) and understanding better
    the requirements of the field.

  tasks: |
    * Reproduce the results based on previous comparisons against ROOT master
    * Investigate and compare the latest compression strategies used by [Samtools](https://www.htslib.org/) for conversions to BAM, with RAM(ROOT Alignment Maps).
    * Explore ROOT's [RNTuple](https://root.cern/doc/v622/md_tree_ntuple_v7_doc_README.html) format to efficiently store RAM maps, in place of the previously used `TTree`.
    * Investigate different ROOT file splitting techniques
    * Produce a comparison report
  status: completed
  responsible: Aditya Pandey

- name: "Explore advanced activity-analysis and optimizations in reverse-mode automatic differentiation"
  description: |
    Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++
    source code of a mathematical function, it can automatically generate C++
    code for computing derivatives of the function. Clad has found uses in
    statistical analysis and uncertainty assessment applications.

    Automatic differentiation techniques involve computing partial derivatives
    of each intermediate variable encountered while automatically
    differentiating a function. Users are generally interested in the
    derivatives of a subset of the output variables with respect to a subset
    of the input variables. In this case, partial derivatives of many
    intermediate variables may not contribute to final derivatives and
    therefore can be ignored and not computed. Activity analysis finds
    intermediate variables whose partial derivatives contribute to the final
    required derivatives. It allows the AD tool to only compute the set of
    partial derivatives that are required. By not computing partial
    derivatives for such intermediate variables, both the memory requirement
    and the run time of the generated program can be reduced.
  tasks: |
    There are several foreseen tasks:
      * Research about automatic differentiation activity analysis techniques.
        Prepare an activity analysis model report with an initial strategy to
        follow. This may involve brainstorming and the need for innovative
        solutions.
      * Implement the proposed activity analysis mode.
      * Add tests and documentation.
  status: completed
  responsible: Maksym Andriichuk

- name: "Improve automatic differentiation of object-oriented paradigms using Clad"
  description: |
    Clad is an automatic differentiation (AD) clang plugin for C++. Given a
    C++ source code of a mathematical function, it can automatically generate
    C++ code for computing derivatives of the function. Clad has found uses
    in statistical analysis and uncertainty assessment applications.

    Object oriented paradigms (OOP) provide a structured approach for complex
    use cases, allowing for modular components that can be reused & extended.
    OOP also allows for abstraction which makes code easier to reason about &
    maintain. Gaining full OOP support is an open research area for automatic
    differentiation codes.

    This project focuses on improving support for differentiating
    object-oriented constructs in Clad. This will allow users to seamlessly
    compute derivatives to the algorithms in their projects which use an
    object-oriented model. C++ object-oriented constructs include but are
    not limited to: classes, inheritance, polymorphism, and related features
    such as operator overloading.
  tasks: |
    There are several foreseen tasks:
      * Study the current object-oriented differentiable programming support
        in Clad. Prepare a report of missing constructs that should be added to
        support the automatic differentiation of object-oriented paradigms in
        both the forward mode AD and the reverse mode AD.
        Some of the missing constructs are: differentiation of constructors,
        limited support for differentiation of operator overloads, reference
        class members, and no way of specifying custom derivatives for
        constructors.
      * Add support for the missing constructs.
      * Add proper tests and documentation.
  status: completed
  responsible: Petro Zarytskyi


################################################################################
#                                     2024                                     #
################################################################################
- name: "ROOT Superbuilds"
  description: |
    [ROOT](https://root.cern/) is a framework for data processing,
    born at CERN, at the heart of the research on high-energy physics.
    Every day, thousands of physicists use ROOT applications to analyze their
    data or to perform simulations. The ROOT software framework is
    foundational for the HEP ecosystem, providing capabilities such
    as IO, a C++ interpreter, GUI, and math libraries. It uses
    object-oriented concepts and build-time modules to layer between
    components. We believe additional layering formalisms will benefit
    ROOT and its users.

    Currently, ROOT is built as all-in-one package. We are working to create
    a modular version of ROOT that provides a minimal base install of core
    features, then later add functionality via incremental builds. This
    requires introducing new layering mechanisms and extending the functionality
    of the existing ROOT package manager prototype.

  tasks: |
    * Enhance the existing CMake build system rules to enable lazy building of packages
    * Bootstrap “RootBase”
    * Demonstrate “layered” lazy builds
  status: completed
  responsible: Pavlo Svirin

- name: "Implementing missing features in xeus-cpp"
  description: |
    xeus-cpp is a Jupyter kernel for cpp based on the native implementation
    of the Jupyter protocol xeus. This enables users to write and execute
    C++ code interactively, seeing the results immediately. This REPL
    (read-eval-print-loop) nature allows rapid prototyping and iterations
    without the overhead of compiling and running separate C++ programs.
    This also achieves C++ and Python integration within a single Jupyter
    environment.

    The xeus-cpp is a successor of xeus-clang-repl and xeus-cling. The project
    goal is to advance the project feature support to the extent of what’s
    supported in xeus-clang-repl and xeus-cling.

  tasks: |
    * Fix occasional bugs in clang-repl directly in llvm upstream
    * Implement the value printing logic
    * Advance the wasm infrastructure
    * Write tutorials and demonstrators
    * Complete the transition of xeus-clang-repl to xeus-cpp
  status: completed
  responsible: Anutosh Bhat

- name: "Adoption of CppInterOp in ROOT"
  description: |
    Incremental compilation pipelines process code chunk-by-chunk by building
    an ever-growing translation unit. Code is then lowered into the LLVM IR
    and subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration
    and makes the C++ language more user friendly. The incremental compilation
    mode is used by the interactive C++ interpreter, Cling, initially developed
    to enable interactive high-energy physics analysis in a C++ environment.
    The CppInterOp library provides a minimalist approach for other languages
    to identify C++ entities (variables, classes, etc.). This enables
    interoperability with C++ code, bringing the speed and efficiency of C++
    to simpler, more interactive languages like Python. CppInterOp provides
    primitives that are good for providing reflection information.

    The ROOT is an open-source data analysis framework used by high energy
    physics and others to analyze petabytes of data, scientifically. The
    framework provides support for data storage and processing by relying
    on Cling, Clang, LLVM for building automatically efficient I/O
    representation of the necessary C++ objects. The I/O properties of each
    object is described in a compilable C++ file called a /dictionary/.
    ROOT’s I/O dictionary system relies on reflection information provided
    by Cling and Clang. However, the reflection information system has grown
    organically and now ROOT’s core/metacling system has been hard to maintain
    and integrate.

    The goal of this project is to integrate CppInterOp in ROOT where possible.

  tasks: |
    * To achieve this goal we expect several infrastructure items to be completed such as Windows support, WASM support
    * Make reusable github actions across multiple repositories
    * Sync the state of the dynamic library manager with the one in ROOT
    * Sync the state of callfunc/jitcall with the one in ROOT
    * Prepare the infrastructure for upstreaming to llvm
    * Propose an RFC and make a presentation to the ROOT development team
  status: completed
  responsible: Aaron Jomy, Sahil Patidar


- name: "Add support for differentiating with respect to multidimensional arrays
         (or pointers) in Clad."
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage.

    Clad currently only supports differentiation with respect to
    single-dimensional arrays. Support for differentiation with respect to
    pointers is limited as well. This project aims to add support for
    multi-dimensional arrays (and pointers) in Clad.

    After successful completion of the project the code snippet should work
    as expected:
    ```cpp
    #include <iostream>
    #include "clad/Differentiator/Differentiator.h"

    double fn(double arr[5][5]) {
      double res = 1 * arr[0][0] + 2 * arr[1][1] + 4 * arr[2][2];
      return res * 2;
    }

    int main() {
      auto d_fn = clad::gradient(fn);
      double arr[5][5] = {{1, 2, 3, 4, 5},
                          {6, 7, 8, 9, 10},
                          {11, 12, 13, 14, 15},
                          {16, 17, 18, 19, 20},
                          {21, 22, 23, 24, 25}};
      double d_arr[5][5] = {};
      d_fn.execute(arr, d_arr);
      std::cout << "Derivative of d_fn wrt arr[0][0]: " << d_arr[0][0] << "\n"; // 2
      std::cout << "Derivative of d_fn wrt arr[1][1]: " << d_arr[1][1] << "\n"; // 4
      return 0;
    }
    ```
  tasks: |
    The project consists of the following tasks:
      * Add support for differentiation with respect to multidimensional arrays
        (and pointers) in the reverse mode.
      * Add support for differentiation with respect to multidimensional arrays
        (and pointers) in the forward mode.
      * Extend the unit test coverage.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Vaibhav Thakkar

- name: "Improving performance of BioDynaMo using ROOT C++ Modules"
  description: |
    [ROOT](https://root.cern/) is a framework for data processing,
    born at CERN, at the heart of the research on high-energy physics.
    Every day, thousands of physicists use ROOT applications to analyze their
    data or to perform simulations. The ROOT software framework is
    foundational for the HEP ecosystem, providing capabilities such
    as IO, a C++ interpreter, GUI, and math libraries. It uses
    object-oriented concepts and build-time modules to layer between
    components. We believe additional layering formalisms will benefit
    ROOT and its users.

    BioDynaMo is an agent-based simulation platform that enables users
    to perform simulations of previously unachievable scale and complexity,
    making it possible to tackle challenging scientific research questions.
    The project has a wide range of applications in cancer research,
    epidemiology, and social sciences.

    BioDynaMo incorporates ROOT for several crucial functionalities such
    as statistical analysis, random number generation, C++-based Jupyter
    notebooks, and IO. Some features rely on efficient reflection
    information about BioDynaMo’s and user-defined C++ classes. This project
    is about improving the performance of the reflection system by upgrading
    to C++ modules.
  tasks: |
    * Rework the cmake rules to incorporate efficiently ROOT via `FetchContent`
    * Replace invocations of `genreflex` in favor of `rootcling`
    * Enable C++ modules in `rootcling`
    * Produce a comparison report
  status: completed
  responsible: Isaac Morales Santana


- name: "Implement Differentiating of the Kokkos Framework"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is
    a set of techniques to numerically evaluate the derivative of a function
    specified by a computer program. Automatic differentiation is an
    alternative technique to Symbolic differentiation and Numerical
    differentiation (the method of finite differences). Clad is based on
    Clang which provides the necessary facilities for code transformation.
    The AD library can differentiate non-trivial functions, to find a partial
    derivative for trivial cases and has good unit test coverage.

    The Kokkos C++ Performance Portability Ecosystem is a production level
    solution for writing modern C++ applications in a hardware agnostic way.
    It is part of the US Department of Energies Exascale Project – the leading
    effort in the US to prepare the HPC community for the next generation of
    super computing platforms. The Ecosystem consists of multiple libraries
    addressing the primary concerns for developing and maintaining applications
    in a portable way. The three main components are the Kokkos Core Programming
    Model, the Kokkos Kernels Math Libraries and the Kokkos Profiling and
    Debugging Tools.

    The Kokkos framework is used in several domains including climate modeling
    where gradients are important part of the simulation process. This project
    aims at teaching Clad to differentiate Kokkos entities in a performance
    portable way

  tasks: |
    * Implement common test cases for Kokkos in Clad
    * Add support for Kokkos functors
    * Add support for Kokkos lambdas
    * Incorporate the changes from the [initial Kokkos PR](https://github.com/vgvassilev/clad/pull/783)
    * Enhance existing benchmarks demonstrating effectiveness of Clad for Kokkos
    * [Stretch goal] Performance benchmarks

  status: completed
  responsible: Atell Yehor Krasnopolski

- name: "Integrate a Large Language Model with the xeus-cpp Jupyter kernel"
  description: |
    xeus-cpp is a Jupyter kernel for cpp based on the native implementation
    of the Jupyter protocol xeus. This enables users to write and execute
    C++ code interactively, seeing the results immediately. This REPL
    (read-eval-print-loop) nature allows rapid prototyping and iterations
    without the overhead of compiling and running separate C++ programs.
    This also achieves C++ and Python integration within a single Jupyter
    environment.

    This project aims to integrate a large language model, such as Bard/Gemini,
    with the xeus-cpp Jupyter kernel. This integration will enable users to
    interactively generate and execute code in C++ leveraging the assistance
    of the language model. Upon successful integration, users will have access
    to features such as code autocompletion, syntax checking, semantic
    understanding, and even code generation based on natural language prompts.

  tasks: |
    * Design and implement mechanisms to interface the large language model with the xeus-cpp kernel. Jupyter-AI might be used as a motivating example
    * Develop functionalities within the kernel to utilize the language model for code generation based on natural language descriptions and suggestions for autocompletion.
    * Comprehensive documentation and thorough testing/CI additions to ensure reliability.
    * [Stretch Goal] After achieving the previous milestones, the student can work on specializing the model for enhanced syntax and semantic understanding capabilities by using xeus notebooks as datasets.

  status: completed
  responsible: Tharun Anandh

- name: "Improve the LLVM.org Website Look and Feel"
  description: |
    The llvm.org website serves as the central hub for information about the
    LLVM project, encompassing project details, current events, and relevant
    resources. Over time, the website has evolved organically, prompting the
    need for a redesign to enhance its modernity, structure, and ease of
    maintenance.

    The goal of this project is to create a contemporary and coherent static
    website that reflects the essence of LLVM.org. This redesign aims to improve
    navigation, taxonomy, content discoverability, and overall usability. Given
    the critical role of the website in the community, efforts will be made to
    engage with community members, seeking consensus on the proposed changes.

    LLVM's [current website](https://llvm.org) is a complicated mesh of uncoordinated pages with
    inconsistent, static links pointing to both internal and external sources.
    The website has grown substantially and haphazardly since its inception.

    It requires a major UI and UX overhaul to be able to better serve the LLVM
    community.

    Based on a preliminary site audit, following are some of the problem areas
    that need to be addressed.

    **Sub-Sites**: Many of the sections/sub-sites have a completely different UI/UX
    (e.g., [main](https://llvm.org), [clang](https://clang.llvm.org),
    [lists](https://lists.llvm.org/cgi-bin/mailman/listinfo),
    [foundation](https://foundation.llvm.org),
    [circt](https://circt.llvm.org/docs/GettingStarted/),
    [lnt](http://lnt.llvm.org), and [docs](https://llvm.org/docs)).
    Sub-sites are divided into 8 separate repos and use different technologies
    including [Hugo](https://github.com/llvm/circt-www/blob/main/website/config.toml),
    [Jekyll](https://github.com/llvm/clangd-www/blob/main/_config.yml), etc.

    **Navigation**: On-page navigation is inconsistent and confusing. Cross-sub-site
    navigation is inconsistent, unintuitive, and sometimes non-existent. Important
    subsections often depend on static links within (seemingly random) pages.
    Multi-word menu items are center-aligned and flow out of margins.

    **Pages**: Many [large write-ups](https://clang.llvm.org/docs/UsersManual.html)
    lack pagination, section boundaries, etc., making
    them seem more intimidating than they really are. Several placeholder pages
    re-route to [3rd party services](https://llvm.swoogo.com/2023devmtg),
    adding bloat and inconsistency.

    **Search**: Search options are placed in unintuitive locations, like the bottom
    of the side panel, or from [static links](https://llvm.org/docs/) to
    [redundant pages](https://llvm.org/docs/search.html). Some pages have
    no search options at all. With multiple sections of the website hosted in
    separate projects/repos, cross-sub-site search doesn't seem possible.

    **Expected results**: A modern, coherent-looking website that attracts new
    prospect users and empowers the existing community with better navigation,
    taxonomy, content discoverability, and overall usability. It should also
    include a more descriptive Contribution Guide ([example](https://kitian616.github.io/jekyll-TeXt-theme/docs/en/layouts)) to help novice
    contributors, as well as to help maintain a coherent site structure.

    Since the website is a critical infrastructure and most of the community
    will have an opinion this project should try to engage with the community
    building community consensus on the steps being taken.

  tasks: |
    * Conduct a comprehensive content audit of the existing website.
    * Select appropriate technologies, preferably static site generators like
    Hugo or Jekyll.
    * Advocate for a separation of data and visualization, utilizing formats such
    as YAML and Markdown to facilitate content management without direct HTML
    coding.
    * Present three design mockups for the new website, fostering open discussions
    and allowing time for alternative proposals from interested parties.
    * Implement the chosen design, incorporating valuable feedback from the
    community.
    * Collaborate with content creators to integrate or update content as needed.

    The successful candidate should commit to regular participation in weekly
    meetings, deliver presentations, and contribute blog posts as requested.
    Additionally, they should demonstrate the ability to navigate the community
    process with patience and understanding.

  status: completed
  responsible: Chaitanya Shahare


- name: "Enable reverse-mode automatic differentiation of (CUDA) GPU kernels using Clad"
  description: |
    Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++
    source code of a mathematical function, it can automatically generate C++
    code for computing derivatives of the function. Clad has found uses in
    statistical analysis and uncertainty assessment applications. In
    scientific computing and machine learning, GPU multiprocessing can
    provide a significant boost in performance and scalability. This project
    focuses on enabling the automatic differentiation of CUDA GPU kernels using
    Clad. This will allow users to take advantage of the power of GPUs while
    benefiting from the accuracy and speed of automatic differentiation.
  tasks: |
    There are several foreseen tasks:
      * Research about automatic differentiation of code involving CUDA GPU
        kernels. Prepare a report and an initial strategy to follow.This may
        involve brainstorming and the need for innovative solutions.
      * Enable reverse-mode automatic differentiation of CUDA GPU kernels and
        calls to CUDA GPU kernels from the host code.
      * Add proper tests and documentation.
  status: completed
  responsible: Christina Koutsou

- name: "Add support for consteval and constexpr functions in clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is
    a set of techniques to numerically evaluate the derivative of a function
    specified by a computer program. Automatic differentiation is an alternative
    technique to Symbolic differentiation and Numerical differentiation (the
    method of finite differences). Clad is based on Clang which provides the
    necessary facilities for code transformation. The AD library can differentiate
    non-trivial functions, to find a partial derivative for trivial cases and has
    good unit test coverage.

    C++ provides the specifiers consteval and constexpr to allow compile time evaluation
    of functions. `constexpr` declares a possibility, i.e the function will be
    evaluated at compile time if possible, else at runtime; whereas `consteval` makes it
    mandatory, i.e every call to the function must produce a compile-time constant.

    The aim of this project is to ensure that same semantics are followed by the generated
    derivative function, i.e if the primal function is evaluated at compile time
    (because of constexpr or consteval specifier), then the generated derivative code
    should also have the same specifier to be evaluatable at compile time.

    This will enable clad to demonstrate the benefits of doing automatic differentiation
    directly on C++ frontend to utilize the benefits of clang's infrastructure.

    After successful completion of the project the code snippet should work
    as expected:
    ```cpp
    #include <cstdio>
    #include "clad/Differentiator/Differentiator.h"

    constexpr double sq(double x) { return x*x; }

    consteval double fn(double x, double y, double z) {
      double res = sq(x) + sq(y) + sq(z);
      return res;
    }

    int main() {
      auto d_fn = clad::gradient(fn);
      double dx = 0, dy = 0, dz = 0;
      d_fn.execute(3, 4, 5, &dx, &dy, &dz);
      printf("Gradient vector: [%.2f, %.2f, %.2f]", dx, dy, dz);
      return 0;
    }
    ```
  tasks: |
    The project consists of the following tasks:
      * Add support for differentiation with respect to consteval and constexpr
        functions in the forward mode.
      * Add support for differentiation with respect to consteval and constexpr
        functions in the reverse mode.
      * Extend the unit test coverage.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Mihail Mihov


################################################################################
#                                     2023                                     #
################################################################################

- name: "Enable cross-talk between Python and C++ kernels in xeus-clang-REPL by using Cppyy"
  description: |
    xeus-clang-REPL is a C++ kernel for Jupyter notebooks using clang-REPL as
    its C++ Interpreter. Cppyy is an automatic, run-time, Python-C++ bindings
    generator, for calling C++ from Python and Python from C++.

    Allowing C++ and Python to talk between themselves in a Jupyter notebook
    will allow users to switch between Python and C++ at will. This means
    that data analysts can set up their analysis in Python while running the
    actual analysis in C++. Thus reducing the time to write and debug their
    analysis pipeline.

    Initial support of cross talk between the two kernels has been implemented
    but this only supports passing primitive data types. This project aims to
    use Cppyy to extend this to support classes and functions.
  tasks: |
    * Automate creation of equivalent Cppyy objects in the Python kernel when
      objects are created in the C++ kernel
    * Automate the creation of equivalent C++ objects in the xeus-clang-REPL
      kernel when Python objects are created
    * Add documentation
  status: completed
  responsible: Aaron Jomy, Smit Shah

- name: "Extend the Cppyy support in Numba"
  description: |
    Numba is a JIT compiler that translates a subset of Python and NumPy code
    into fast machine code. Cppyy is an automatic, run-time, Python-C++
    bindings generator, for calling C++ from Python and Python from C++.

    Cppyy has to pay a time penalty each time it needs to switch between
    languages which can multiply into large slowdowns when using loops with
    cppyy objects. This is where Numba can help. Since Numba compiles the
    code in loops into machine code it only has to cross the language barrier
    once and the loops thus run faster.

    Initial support for Cppyy objects in Numba enabled the use of builtin
    types and classes (see
    [cppyy docs](https://cppyy.readthedocs.io/en/latest/numba.html)),
    but some essential C++ features, such as references and STL classes,
    are not yet supported.
  tasks: |
    There are several foreseen tasks:
      * Add support for C++ reference types in Numba through Cppyy
      * Add general support for C++ templates in Numba through Cppyy
      * Add tests and documentation
  status: completed
  responsible: Aaron Jomy

- name: "Implement vector mode in forward mode automatic differentiation in Clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage.

    Vector mode support will facilitate the computation of gradients using the
    forward mode AD in a single pass and thus without explicitly performing
    differentiation n times for n function arguments. The major benefit of using
    vector mode is that computationally expensive operations do not need to be
    recomputed n times for n function arguments.

    For example, if we want to compute `df/dx` and `df/dy` of a function
    `f(x, y)` using the forward mode AD in Clad, then currently we need to
    explicitly differentiate `f` two times. Vector mode will allow the
    generation of `f_d(x, y)` such that we will be able to get partial
    derivatives with respect to all the function arguments (gradient) in a
    single call.

    After successful completion of the project the code snippet should work
    as expected:
    ```cpp
    #include <clad/Differentiator/Differentiator.h>
    #include <iostream>

    double someComputationalIntensiveFn();

    double fn(double x, double y) {
      double t = someComputationalIntensiveFn(); // should be computed only once
                                                 // in the derived function.
      double res = 2 * t * x + 3 * t * x * y;
      return t;
    }

    int main() {
      auto d_fn = clad::differentiate(fn, "arr");
      double d_x = 0, d_y = 0;
      d_fn.execute(3, 5, &d_x, &d_y);
      std::cout << "Derivative of fn wrt d_x: " << d_x << "\n";
      std::cout << "Derivative of fn wrt d_y: " << d_y << "\n";
    }
    ```
  tasks: |
    The project consists of the following tasks:
      * Extend and generalize our ForwardModeVisitor to produce a single
        function with the directional derivatives.
      * Add a new mode to the top-level clad interface `clad::differentiate` for
        vector mode.
      * Extend the unit test coverage.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Vaibhav Thakkar

- name: "Improving Cling Reflection for Scripting Languages"
  description: |
    Cling has basic facilities to make queries about the C++ code that it has
    seen/collected so far. These lookups assume, however, that the caller knows
    what it is looking for and the information returned, although exact, usually
    only makes sense within C++ and is thus often too specific to be used as-is.

    A scripting language, such as Python, that wants to make use of such lookups
    by name, is forced to loop over all possible entities (classes, functions,
    templates, enums, ...) to find a match. This is inefficient. Furthermore,
    many lookups will be multi-stage: a function, but which overload? A template,
    but which instantiation? A typedef, of what? The current mechanism forces
    the scripting language to provide a type-based match, even where C++ makes
    distinctions (e.g. pointer v.s. reference) that do not exist in the
    scripting language. This, too, makes lookups very inefficient.

    The returned information, once a match is found, is exact, but because of
    its specificity, requires the caller to figure out C++ concepts that have no
    meaning in the scripting language. E.g., there is no reason for Python to
    consider an implicitly instantiated function template different from an
    explicitly instantiated one.
  tasks: |
    The project should start with a design C++ entities grouping that make sense
    for scripting languages and design a query API on top of these. Special
    consideration should be given to the various name aliasing mechanisms in C++
    (e.g., `using` and `typedef`), especially as relates to C++ access rules.
    This design can likely start from the existing Cling wrapper API from Cppyy
    and modify it to improve consistency, remove redundancy, and enable usage
    patterns that minimize lookups into Cling.

    Next is a redesign of Cling's lookup facilities to support this new API
    efficiently, with particular care to use cases that require multiple,
    consecutive/related, lookups, such as finding a specific function template
    instantiation, or step-wise resolution of a typedef.

    This design is then to be implemented, using test-driven development. As a
    stretch goal, the cppyy-backend should be modified to use the new API.
  status: completed
  responsible: Baidyanath Kundu


- name: "Write JITLink support for a new format/architecture"
  description: |
    JITLink is LLVM’s new JIT linker API -- the low-level API that transforms
    compiler output (relocatable object files) into ready-to-execute bytes in
    memory. To do this JITLink’s generic linker algorithm needs to be
    specialized to support the target object format (COFF, ELF, MachO), and
    architecture (arm, arm64, i386, x86-64). LLVM already has mature
    implementations of JITLink for MachO/arm64 and MachO/x86-64, and a
    relatively new implementation for ELF/x86-64. Write a JITLink implementation
    for a missing target that interests you. If you choose to implement support
    for a new architecture using the ELF or MachO formats then you will be able
    to re-use the existing generic code for these formats. If you want to
    implement support for a new target using the COFF format then you will need
    to write both the generic COFF support code and the architecture support
    code for your chosen architecture.
  tasks: |
    Write a JITLink specialization for a not-yet-supported format/architecture.
  status: completed
  responsible: Various Contributors

################################################################################
#                                     2022                                     #
################################################################################
- name: "Design and Develop a CUDA engine working along with C/C++ mode in clang-repl"
  description: |
    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims to
    generalize the `IncrementalCUDADeviceCompiler` of cling and add this
    functionality in clang-repl.
  tasks: |
    There are several foreseen tasks:
      * Write a detailed request for comment (RFC) document on the design choices
        and gather feedback from the LLVM community.
      * Implement the necessary functionality to support existing test cases
        available [here](https://github.com/root-project/cling/tree/master/test/CUDADeviceCode).
      * Develop clang-repl-based tutorials for the CUDA backend.
      * Investigate the requirements for supporting a HIP backend.
      * Demonstrate a CUDA-executed gradient computed by the Clad automatic
        differentiation plugin.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Anubhab Ghosh

- name: "Tutorial development with clang-repl"
  description: |
    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims
    implementing tutorials demonstrating the capabilities of the project and
    investigating adoption of clang-repl in xeus-cling.
  tasks: |
    There are several foreseen tasks:
      * Write several tutorials demostrating the current capabilities of
        clang-repl.
      * Investigate the requirements for adding clang-repl as a backend to
        xeus-cling.
      * Implement the xeus kernel protocol for clang-repl.
      * Complete a blog post about clang-repl and possibly Jupyter.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Krishna Narayanan

- name: "Optimize ROOT use of modules for large codebases (eg, CMSSW)"
  description: |
    The LHC smashes groups of protons together at close to the speed of light:
    40 million times per second and with seven times the energy of the most
    powerful accelerators built up to now. Many of these will just be glancing
    blows but some will be head on collisions and very energetic. When this
    happens some of the energy of the collision is turned into mass and
    previously unobserved, short-lived particles – which could give clues
    about how Nature behaves at a fundamental level - fly out and into the
    detector. Our work includes the experimental discovery of the Higgs boson,
    which leads to the award of a Nobel prize for the underlying theory that
    predicted the Higgs boson as an important piece of the standard model
    theory of particle physics.

    CMS is a particle detector that is designed to see a wide range of
    particles and phenomena produced in high-energy collisions in the LHC.
    Like a cylindrical onion, different layers of detectors measure the
    different particles, and use this key data to build up a picture of events
    at the heart of the collision. The
    [CMSSW](https://github.com/cms-sw/cmssw/) is a collection of software for
    the CMS experiment. It is responsible for the collection and processing of
    information about the particle collisions at the detector. CMSSW uses
    the [ROOT](root.cern/) framework to provide support for data storage and
    processing. ROOT relies on Cling, Clang, LLVM for building automatically
    efficient I/O representation of the necessary C++ objects. The I/O
    properties of each object is described in a compileable C++ file called
    a /dictionary/. ROOT's I/O dictionary system
    [relies on C++ modules](https://github.com/root-project/root/blob/master/README/README.CXXMODULES.md)
    to improve the overall memory footprint when being used.

    One source of performance loss is the need for symbol lookups across the
    very large set of CMSSW modules. ROOT needs to be improved to optimize this
    lookup so that it does not pull all modules defining namespace `edm` on
    `edm::X` lookups.
  tasks: |
    The project consists of the following tasks:
      * Develop an extension to the `GlobalModuleIndex` infrastructure in clang
        which keeps track of the `DeclKind` of the identifiers so that we can
        later ignore the identifiers that declare a namespace.
      * Track down the test failures of CMSSW and check if the proposed
        implementation works.
      * Develop tutorials and documentation.
      * Present the work at the relevant meetings and conferences.
  status: completed
  responsible: Jun Zhang

- name: "Add initial integration of Clad with Enzyme"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage. Enzyme is a prominent autodiff framework which
    works on LLVM IR.

    Clad and Enzyme can be considered as a C++ frontend and a backend automatic
    differentiation framework. In many cases, when clad needs to fall back to
    numeric differentiation it can try configuring and using Enzyme to perform
    the automatic differentiation on lower level.
  tasks: |
    Understand how both systems work. Define the Enzyme configuration
    requirements and enable Clad to communicate efficiently with Enzyme. That
    may require several steps: start building and using the optimization pass of
    Enzyme as part of the Clad toolchain; use Enzyme for cross-validation
    derivative results; etc.
  status: completed
  responsible: Manish Kausik H

- name: "Extend clang AST to provide information for the type as written in template instantiations"
  description: |
    When instantiating a template, the template arguments are canonicalized
    before being substituted into the template pattern. Clang does not preserve
    type sugar when subsequently accessing members of the instantiation.

    ```cpp
    std::vector<std::string> vs;
    int n = vs.front(); // bad diagnostic: [...] aka 'std::basic_string<char>' [...]

     template<typename T> struct Id { typedef T type; };
     Id<size_t>::type // just 'unsigned long', 'size_t' sugar has been lost
    ```
    Clang should "re-sugar" the type when performing member access on a class
    template specialization, based on the type sugar of the accessed
    specialization. The type of vs.front() should be std::string, not
    std::basic_string<char, [...]>.

    Suggested design approach: add a new type node to represent template
    argument sugar, and implicitly create an instance of this node whenever a
    member of a class template specialization is accessed. When performing a
    single-step desugar of this node, lazily create the desugared representation
    by propagating the sugared template arguments onto inner type nodes (and in
    particular, replacing Subst*Parm nodes with the corresponding sugar). When
    printing the type for diagnostic purposes, use the annotated type sugar to
    print the type as originally written.

    For good results, template argument deduction will also need to be able to
    deduce type sugar (and reconcile cases where the same type is deduced twice
    with different sugar).
  tasks: |
    Diagnostics preserve type sugar even when accessing members of a template
    specialization. `T<unsigned long>` and `T<size_t>` are still the same type
    and the same template instantiation, but `T<unsigned long>::type` single-step
    desugars to 'unsigned long' and `T<size_t>::type` single-step desugars to
    'size_t'.
  status: completed
  responsible: Matheus Izvekov

- name: "Infrastructure: Improve Cling's packaging system cpt"
  description: |
    Cling has a flexible tool which can build and package binaries. It is
    implemented in python.
  tasks: |
    There are several improvements that can be made to cpt:
    * Fix deb package creation
    * Rewrite parts of cpt
      * Use a `if __name__ == "__main__"` block as program execution starting
        point
      * No mutating global variables
      * Minimize use of `subprocess`
      * Making cpt flake8 compliant (flexible error/violation codes)
      * Revamp argument parser (Examine possibility of dependent arguments)
  status: completed
  responsible: Surya Somayyajula


################################################################################
#                                     2021                                     #
################################################################################

- name: "Implement autocompletion in clang-repl"
  description: |
    The Clang compiler is part of the LLVM compiler infrastructure and supports
    various languages such as C, C++, ObjC and ObjC++. The design of LLVM and
    Clang enables them to be used as libraries, and has led to the creation of
    an entire compiler-assisted ecosystem of tools. The relatively friendly
    codebase of Clang and advancements in the JIT infrastructure in LLVM further
    enable research into different methods for processing C++ by blurring the
    boundary between compile time and runtime. Challenges include incremental
    compilation and fitting compile/link time optimizations into a more dynamic
    environment.

    Incremental compilation pipelines process code chunk-by-chunk by building an
    ever-growing translation unit. Code is then lowered into the LLVM IR and
    subsequently run by the LLVM JIT. Such a pipeline allows creation of
    efficient interpreters. The interpreter enables interactive exploration and
    makes the C++ language more user friendly. The incremental compilation mode
    is used by the interactive C++ interpreter, Cling, initially developed to
    enable interactive high-energy physics analysis in a C++ environment.

    Our group puts efforts to incorporate and possibly redesign parts of Cling
    in Clang mainline through a new tool, clang-repl. The project aims at the
    design and implementation of robust autocompletion when users type C++ at
    the prompt of clang-repl. For example:
    ```cpp
    [clang-repl] class MyLongClassName {};
    [clang-repl] My<tab>
    // list of suggestions.
    ```
  tasks: |
    There are several foreseen tasks:
      * Research the current approaches for autocompletion in clang such as
        `clang -code-completion-at=file:col1:col2`.
      * Implement a version of the autocompletion support using the partial
        translation unit infrastructure in clang's `libInterpreter`.
      * Investigate the requirements for semantic autocompletion which takes into
        account the exact grammar position and semantics of the code. Eg:
        ```cpp
        [clang-repl] struct S {S* operator+(S&) { return nullptr;}};
        [clang-repl] S a, b;
        [clang-repl] v = a + <tab> // shows b as the only acceptable choice here.
        ```
      * Present the work at the relevant meetings and conferences
  status: completed
  responsible: Yuquan (Fred) Fu

- name: "Add numerical differentiation support in clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage. In a number of cases, due different
    limitations, it is either inefficient or impossible to differentiate a
    function.

    Currently, clad cannot differentiate declared-but-not-defined functions.
    In that case it issues an error. Instead, clad should fall back to its future
    numerical differentiation facilities.
  tasks: |
    Implement numerical differentiation support in clad. It should be available
    through a dedicated interface (for example `clad::num_differentiate`).
    The new functionality should be connected to the forward mode automatic
    differentiation. If time permits, a prototype of configurable error
    estimation for the numerical differentiation should be implemented.
  status: completed
  responsible: Garima Singh

- name: "Add support for functor objects in clad"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation. The AD library is able to differentiate
    non-trivial functions, to find a partial derivative for trivial cases and
    has good unit test coverage.

    Many computations are modelled using functor objects. Usually, a functor
    object is a lightweight C++ object which has state stored as members and has
    overridden call operator (`operator()`). For example:

    ```cpp
    struct Functor {
      double x;
      double operator()() { return x * x ;}
    };

    int main () {
      Functor Fn;
      Fn.x = 2;
      double pow2 = Fn();
      auto dpow2_dx = clad::differentiate(Fn, /*wrt*/ 0); // unsupported
      return pow2;
    }
    ```
    The goal of this project is to modify Clad to handle such cases.
  tasks: |
    Implement functor object differentiation in both forward and reverse mode.
    The candidate should be ready to investigate performance bottlenecks, add
    test and benchmarking coverage and improve documentation for various parts
    of clad not only limited to the functor object differentiation support.
  status: completed
  responsible: Parth Aurora

- name: "Utilize second order derivatives from Clad in ROOT"
  description: |
    In mathematics and computer algebra, automatic differentiation (AD) is a set
    of techniques to numerically evaluate the derivative of a function specified
    by a computer program. Automatic differentiation is an alternative technique
    to Symbolic differentiation and Numerical differentiation (the method of
    finite differences). Clad is based on Clang which provides the necessary
    facilities for code transformation.

    ROOT is a framework for data processing, born at CERN, at the heart of the
    research on high-energy physics. Every day, thousands of physicists use ROOT
    applications to analyze their data or to perform simulations. ROOT has a
    clang-based C++ interpreter Cling and integrates with Clad to enable flexible
    automatic differentiation facility.
  tasks: |
    TFormula is a ROOT class which bridges compiled and interpreted code. Teach
    TFormula to use second order derivatives (using `clad::hessian`). The
    implementation should be very similar to what was done in
    [this pull request](https://github.com/root-project/root/pull/2745).
    The produced code should be well tested and documented. If time permits, we
    should pursue converting the C++ gradient function to CUDA device kernels.
    The integration of that feature should be comparable in terms of complexity to
    integrating `clad::hessians`.
  status: completed
  responsible: Baidyanath Kundu

- name: "Implement a shared-memory based JITLinkMemoryManager for out-of-process JITting"
  description: |
    LLVM’s JIT uses the JITLinkMemoryManager interface to allocate both working
    memory (where the JIT fixes up the relocatable objects produced by the
    compiler) and target memory (where the JIT’d code will reside in the target).
    JITLinkMemoryManager instances are also responsible for transporting
    fixed-up code from working memory to target memory. LLVM has an existing
    cross-process allocator that uses remote procedure calls (RPC) to allocate and
    copy bytes to the target process, however a more attractive solution (when
    the JIT and target process share the same physical memory) would be to use
    shared memory pages to avoid copies between processes.
  tasks: |
    Implement a shared-memory based JITLinkMemoryManager:
      * Write generic LLVM APIs for shared memory allocation.
      * Write a JITLinkMemoryManager that uses these generic APIs to allocate
        shared working-and-target memory.
      * Make an extensive performance study of the approach.
  status: completed
  responsible: Anubhab Ghosh
